<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Data Science</title>
  <meta name="description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Data Science" />
  
  <meta name="twitter:description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

<meta name="author" content="Rafael A. Irizarry">


<meta name="date" content="2019-02-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction-to-statistics-with-r.html">
<link rel="next" href="statistical-inference.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.3.1/str_view.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#case-studies"><i class="fa fa-check"></i><b>1.1</b> Case studies</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#who-will-find-this-book-useful"><i class="fa fa-check"></i><b>1.2</b> Who will find this book useful?</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#what-does-this-book-cover"><i class="fa fa-check"></i><b>1.3</b> What does this book cover?</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#what-is-not-covered-by-this-book"><i class="fa fa-check"></i><b>1.4</b> What is not covered by this book?</a></li>
</ul></li>
<li class="part"><span><b>I R</b></span></li>
<li class="chapter" data-level="2" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html"><i class="fa fa-check"></i><b>2</b> Installing R and RStudio</a><ul>
<li class="chapter" data-level="2.1" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html#installing-r"><i class="fa fa-check"></i><b>2.1</b> Installing R</a></li>
<li class="chapter" data-level="2.2" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html#installing-rstudio"><i class="fa fa-check"></i><b>2.2</b> Installing RStudio</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>3</b> Getting Started with R and RStudio</a><ul>
<li class="chapter" data-level="3.1" data-path="getting-started.html"><a href="getting-started.html#why-r"><i class="fa fa-check"></i><b>3.1</b> Why R?</a></li>
<li class="chapter" data-level="3.2" data-path="getting-started.html"><a href="getting-started.html#the-r-console"><i class="fa fa-check"></i><b>3.2</b> The R console</a></li>
<li class="chapter" data-level="3.3" data-path="getting-started.html"><a href="getting-started.html#scripts"><i class="fa fa-check"></i><b>3.3</b> Scripts</a></li>
<li class="chapter" data-level="3.4" data-path="getting-started.html"><a href="getting-started.html#rstudio"><i class="fa fa-check"></i><b>3.4</b> RStudio</a><ul>
<li class="chapter" data-level="3.4.1" data-path="getting-started.html"><a href="getting-started.html#the-panes"><i class="fa fa-check"></i><b>3.4.1</b> The panes</a></li>
<li class="chapter" data-level="3.4.2" data-path="getting-started.html"><a href="getting-started.html#key-bindings"><i class="fa fa-check"></i><b>3.4.2</b> Key bindings</a></li>
<li class="chapter" data-level="3.4.3" data-path="getting-started.html"><a href="getting-started.html#running-commands-while-editing-scripts"><i class="fa fa-check"></i><b>3.4.3</b> Running commands while editing scripts</a></li>
<li class="chapter" data-level="3.4.4" data-path="getting-started.html"><a href="getting-started.html#changing-global-options"><i class="fa fa-check"></i><b>3.4.4</b> Changing global options</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="getting-started.html"><a href="getting-started.html#installing-r-packages"><i class="fa fa-check"></i><b>3.5</b> Installing R packages</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>4</b> R Basics</a><ul>
<li class="chapter" data-level="4.1" data-path="r-basics.html"><a href="r-basics.html#case-study-us-gun-murders"><i class="fa fa-check"></i><b>4.1</b> Case study: US Gun Murders</a></li>
<li class="chapter" data-level="4.2" data-path="r-basics.html"><a href="r-basics.html#the-very-basics"><i class="fa fa-check"></i><b>4.2</b> The very basics</a><ul>
<li class="chapter" data-level="4.2.1" data-path="r-basics.html"><a href="r-basics.html#objects"><i class="fa fa-check"></i><b>4.2.1</b> Objects</a></li>
<li class="chapter" data-level="4.2.2" data-path="r-basics.html"><a href="r-basics.html#the-workspace"><i class="fa fa-check"></i><b>4.2.2</b> The workspace</a></li>
<li class="chapter" data-level="4.2.3" data-path="r-basics.html"><a href="r-basics.html#functions"><i class="fa fa-check"></i><b>4.2.3</b> Functions</a></li>
<li class="chapter" data-level="4.2.4" data-path="r-basics.html"><a href="r-basics.html#other-prebuilt-objects"><i class="fa fa-check"></i><b>4.2.4</b> Other prebuilt objects</a></li>
<li class="chapter" data-level="4.2.5" data-path="r-basics.html"><a href="r-basics.html#variable-names"><i class="fa fa-check"></i><b>4.2.5</b> Variable names</a></li>
<li class="chapter" data-level="4.2.6" data-path="r-basics.html"><a href="r-basics.html#saving-your-workspace"><i class="fa fa-check"></i><b>4.2.6</b> Saving your workspace</a></li>
<li class="chapter" data-level="4.2.7" data-path="r-basics.html"><a href="r-basics.html#motivating-scripts"><i class="fa fa-check"></i><b>4.2.7</b> Motivating scripts</a></li>
<li class="chapter" data-level="4.2.8" data-path="r-basics.html"><a href="r-basics.html#commenting-your-code"><i class="fa fa-check"></i><b>4.2.8</b> Commenting your code</a></li>
<li class="chapter" data-level="4.2.9" data-path="r-basics.html"><a href="r-basics.html#exercises"><i class="fa fa-check"></i><b>4.2.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="r-basics.html"><a href="r-basics.html#data-types"><i class="fa fa-check"></i><b>4.3</b> Data types</a></li>
<li class="chapter" data-level="4.4" data-path="r-basics.html"><a href="r-basics.html#data-frames"><i class="fa fa-check"></i><b>4.4</b> Data frames</a><ul>
<li class="chapter" data-level="4.4.1" data-path="r-basics.html"><a href="r-basics.html#examining-an-object"><i class="fa fa-check"></i><b>4.4.1</b> Examining an object</a></li>
<li class="chapter" data-level="4.4.2" data-path="r-basics.html"><a href="r-basics.html#the-accessor"><i class="fa fa-check"></i><b>4.4.2</b> The accessor: <code>$</code></a></li>
<li class="chapter" data-level="4.4.3" data-path="r-basics.html"><a href="r-basics.html#vectors-numerics-characters-and-logical"><i class="fa fa-check"></i><b>4.4.3</b> Vectors: numerics, characters, and logical</a></li>
<li class="chapter" data-level="4.4.4" data-path="r-basics.html"><a href="r-basics.html#factors"><i class="fa fa-check"></i><b>4.4.4</b> Factors</a></li>
<li class="chapter" data-level="4.4.5" data-path="r-basics.html"><a href="r-basics.html#lists"><i class="fa fa-check"></i><b>4.4.5</b> Lists</a></li>
<li class="chapter" data-level="4.4.6" data-path="r-basics.html"><a href="r-basics.html#matrices"><i class="fa fa-check"></i><b>4.4.6</b> Matrices</a></li>
<li class="chapter" data-level="4.4.7" data-path="r-basics.html"><a href="r-basics.html#exercises-1"><i class="fa fa-check"></i><b>4.4.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="r-basics.html"><a href="r-basics.html#vectors"><i class="fa fa-check"></i><b>4.5</b> Vectors</a><ul>
<li class="chapter" data-level="4.5.1" data-path="r-basics.html"><a href="r-basics.html#creating-vectors"><i class="fa fa-check"></i><b>4.5.1</b> Creating vectors</a></li>
<li class="chapter" data-level="4.5.2" data-path="r-basics.html"><a href="r-basics.html#names"><i class="fa fa-check"></i><b>4.5.2</b> Names</a></li>
<li class="chapter" data-level="4.5.3" data-path="r-basics.html"><a href="r-basics.html#sequences"><i class="fa fa-check"></i><b>4.5.3</b> Sequences</a></li>
<li class="chapter" data-level="4.5.4" data-path="r-basics.html"><a href="r-basics.html#subsetting"><i class="fa fa-check"></i><b>4.5.4</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="r-basics.html"><a href="r-basics.html#coercion"><i class="fa fa-check"></i><b>4.6</b> Coercion</a><ul>
<li class="chapter" data-level="4.6.1" data-path="r-basics.html"><a href="r-basics.html#not-availables-na"><i class="fa fa-check"></i><b>4.6.1</b> Not availables (NA)</a></li>
<li class="chapter" data-level="4.6.2" data-path="r-basics.html"><a href="r-basics.html#exercises-2"><i class="fa fa-check"></i><b>4.6.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="r-basics.html"><a href="r-basics.html#sorting"><i class="fa fa-check"></i><b>4.7</b> Sorting</a><ul>
<li class="chapter" data-level="4.7.1" data-path="r-basics.html"><a href="r-basics.html#sort"><i class="fa fa-check"></i><b>4.7.1</b> <code>sort</code></a></li>
<li class="chapter" data-level="4.7.2" data-path="r-basics.html"><a href="r-basics.html#order"><i class="fa fa-check"></i><b>4.7.2</b> <code>order</code></a></li>
<li class="chapter" data-level="4.7.3" data-path="r-basics.html"><a href="r-basics.html#max-and-which.max"><i class="fa fa-check"></i><b>4.7.3</b> <code>max</code> and <code>which.max</code></a></li>
<li class="chapter" data-level="4.7.4" data-path="r-basics.html"><a href="r-basics.html#rank"><i class="fa fa-check"></i><b>4.7.4</b> <code>rank</code></a></li>
<li class="chapter" data-level="4.7.5" data-path="r-basics.html"><a href="r-basics.html#beware-of-recycling"><i class="fa fa-check"></i><b>4.7.5</b> Beware of recycling</a></li>
<li class="chapter" data-level="4.7.6" data-path="r-basics.html"><a href="r-basics.html#exercise"><i class="fa fa-check"></i><b>4.7.6</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="r-basics.html"><a href="r-basics.html#vector-arithmetics"><i class="fa fa-check"></i><b>4.8</b> Vector arithmetics</a><ul>
<li class="chapter" data-level="4.8.1" data-path="r-basics.html"><a href="r-basics.html#rescaling-a-vector"><i class="fa fa-check"></i><b>4.8.1</b> Rescaling a vector</a></li>
<li class="chapter" data-level="4.8.2" data-path="r-basics.html"><a href="r-basics.html#two-vectors"><i class="fa fa-check"></i><b>4.8.2</b> Two vectors</a></li>
<li class="chapter" data-level="4.8.3" data-path="r-basics.html"><a href="r-basics.html#exercises-3"><i class="fa fa-check"></i><b>4.8.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="r-basics.html"><a href="r-basics.html#indexing"><i class="fa fa-check"></i><b>4.9</b> Indexing</a><ul>
<li class="chapter" data-level="4.9.1" data-path="r-basics.html"><a href="r-basics.html#subsetting-with-logicals"><i class="fa fa-check"></i><b>4.9.1</b> Subsetting with logicals</a></li>
<li class="chapter" data-level="4.9.2" data-path="r-basics.html"><a href="r-basics.html#logical-operators"><i class="fa fa-check"></i><b>4.9.2</b> Logical operators</a></li>
<li class="chapter" data-level="4.9.3" data-path="r-basics.html"><a href="r-basics.html#which"><i class="fa fa-check"></i><b>4.9.3</b> <code>which</code></a></li>
<li class="chapter" data-level="4.9.4" data-path="r-basics.html"><a href="r-basics.html#match"><i class="fa fa-check"></i><b>4.9.4</b> <code>match</code></a></li>
<li class="chapter" data-level="4.9.5" data-path="r-basics.html"><a href="r-basics.html#in"><i class="fa fa-check"></i><b>4.9.5</b> <code>%in%</code></a></li>
<li class="chapter" data-level="4.9.6" data-path="r-basics.html"><a href="r-basics.html#exercises-4"><i class="fa fa-check"></i><b>4.9.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="r-basics.html"><a href="r-basics.html#basic-plots"><i class="fa fa-check"></i><b>4.10</b> Basic plots</a><ul>
<li class="chapter" data-level="4.10.1" data-path="r-basics.html"><a href="r-basics.html#plot"><i class="fa fa-check"></i><b>4.10.1</b> <code>plot</code></a></li>
<li class="chapter" data-level="4.10.2" data-path="r-basics.html"><a href="r-basics.html#hist"><i class="fa fa-check"></i><b>4.10.2</b> <code>hist</code></a></li>
<li class="chapter" data-level="4.10.3" data-path="r-basics.html"><a href="r-basics.html#boxplot"><i class="fa fa-check"></i><b>4.10.3</b> <code>boxplot</code></a></li>
<li class="chapter" data-level="4.10.4" data-path="r-basics.html"><a href="r-basics.html#image"><i class="fa fa-check"></i><b>4.10.4</b> <code>image</code></a></li>
<li class="chapter" data-level="4.10.5" data-path="r-basics.html"><a href="r-basics.html#exercises-5"><i class="fa fa-check"></i><b>4.10.5</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="programming-basics.html"><a href="programming-basics.html"><i class="fa fa-check"></i><b>5</b> Programming basics</a><ul>
<li class="chapter" data-level="5.1" data-path="programming-basics.html"><a href="programming-basics.html#conditionals"><i class="fa fa-check"></i><b>5.1</b> Conditional expressions</a></li>
<li class="chapter" data-level="5.2" data-path="programming-basics.html"><a href="programming-basics.html#defining-functions"><i class="fa fa-check"></i><b>5.2</b> Defining functions</a></li>
<li class="chapter" data-level="5.3" data-path="programming-basics.html"><a href="programming-basics.html#namespaces"><i class="fa fa-check"></i><b>5.3</b> Namespaces</a></li>
<li class="chapter" data-level="5.4" data-path="programming-basics.html"><a href="programming-basics.html#for-loops"><i class="fa fa-check"></i><b>5.4</b> For-loops</a></li>
<li class="chapter" data-level="5.5" data-path="programming-basics.html"><a href="programming-basics.html#vectorization"><i class="fa fa-check"></i><b>5.5</b> Vectorization and functionals</a></li>
<li class="chapter" data-level="5.6" data-path="programming-basics.html"><a href="programming-basics.html#exercises-6"><i class="fa fa-check"></i><b>5.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html"><i class="fa fa-check"></i><b>6</b> Basic data wrangling with dplyr</a><ul>
<li class="chapter" data-level="6.1" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#manipulating-data-frames"><i class="fa fa-check"></i><b>6.1</b> Manipulating data frames</a><ul>
<li class="chapter" data-level="6.1.1" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#adding-a-column-with-mutate"><i class="fa fa-check"></i><b>6.1.1</b> Adding a column with <code>mutate</code></a></li>
<li class="chapter" data-level="6.1.2" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#subsetting-with-filter"><i class="fa fa-check"></i><b>6.1.2</b> Subsetting with <code>filter</code></a></li>
<li class="chapter" data-level="6.1.3" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#selecting-columns-with-select"><i class="fa fa-check"></i><b>6.1.3</b> Selecting columns with <code>select</code></a></li>
<li class="chapter" data-level="6.1.4" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#exercises-7"><i class="fa fa-check"></i><b>6.1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#the-pipe"><i class="fa fa-check"></i><b>6.2</b> The pipe: <code>%&gt;%</code></a><ul>
<li class="chapter" data-level="6.2.1" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#exercises-8"><i class="fa fa-check"></i><b>6.2.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#summarizing-data"><i class="fa fa-check"></i><b>6.3</b> Summarizing data</a><ul>
<li class="chapter" data-level="6.3.1" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#summarize"><i class="fa fa-check"></i><b>6.3.1</b> <code>summarize</code></a></li>
<li class="chapter" data-level="6.3.2" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#pull"><i class="fa fa-check"></i><b>6.3.2</b> <code>pull</code></a></li>
<li class="chapter" data-level="6.3.3" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#group-by"><i class="fa fa-check"></i><b>6.3.3</b> Group then summarize</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#sorting-data-frames"><i class="fa fa-check"></i><b>6.4</b> Sorting data frames</a><ul>
<li class="chapter" data-level="6.4.1" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#nested-sorting"><i class="fa fa-check"></i><b>6.4.1</b> Nested sorting</a></li>
<li class="chapter" data-level="6.4.2" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#the-top-n"><i class="fa fa-check"></i><b>6.4.2</b> The top <span class="math inline">\(n\)</span></a></li>
<li class="chapter" data-level="6.4.3" data-path="basic-data-wrangling-with-dplyr.html"><a href="basic-data-wrangling-with-dplyr.html#exercises-9"><i class="fa fa-check"></i><b>6.4.3</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="importing-data.html"><a href="importing-data.html"><i class="fa fa-check"></i><b>7</b> Importing data</a><ul>
<li class="chapter" data-level="7.1" data-path="importing-data.html"><a href="importing-data.html#paths-and-the-working-directory"><i class="fa fa-check"></i><b>7.1</b> Paths and the working directory</a><ul>
<li class="chapter" data-level="7.1.1" data-path="importing-data.html"><a href="importing-data.html#the-filesystem"><i class="fa fa-check"></i><b>7.1.1</b> The filesystem</a></li>
<li class="chapter" data-level="7.1.2" data-path="importing-data.html"><a href="importing-data.html#relative-and-full-paths"><i class="fa fa-check"></i><b>7.1.2</b> Relative and full paths</a></li>
<li class="chapter" data-level="7.1.3" data-path="importing-data.html"><a href="importing-data.html#the-working-directory"><i class="fa fa-check"></i><b>7.1.3</b> The working directory</a></li>
<li class="chapter" data-level="7.1.4" data-path="importing-data.html"><a href="importing-data.html#generating-path-names"><i class="fa fa-check"></i><b>7.1.4</b> Generating path names</a></li>
<li class="chapter" data-level="7.1.5" data-path="importing-data.html"><a href="importing-data.html#copying-files-using-paths"><i class="fa fa-check"></i><b>7.1.5</b> Copying files using paths</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="importing-data.html"><a href="importing-data.html#the-readr-and-readxl-packages"><i class="fa fa-check"></i><b>7.2</b> The readr and readxl packages</a><ul>
<li class="chapter" data-level="7.2.1" data-path="importing-data.html"><a href="importing-data.html#readr"><i class="fa fa-check"></i><b>7.2.1</b> readr</a></li>
<li class="chapter" data-level="7.2.2" data-path="importing-data.html"><a href="importing-data.html#readxl"><i class="fa fa-check"></i><b>7.2.2</b> readxl</a></li>
<li class="chapter" data-level="7.2.3" data-path="importing-data.html"><a href="importing-data.html#exercises-10"><i class="fa fa-check"></i><b>7.2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="importing-data.html"><a href="importing-data.html#downloading-files"><i class="fa fa-check"></i><b>7.3</b> Downloading files</a></li>
<li class="chapter" data-level="7.4" data-path="importing-data.html"><a href="importing-data.html#r-base-importing-functions"><i class="fa fa-check"></i><b>7.4</b> R-base importing functions</a></li>
<li class="chapter" data-level="7.5" data-path="importing-data.html"><a href="importing-data.html#nuances"><i class="fa fa-check"></i><b>7.5</b> Nuances</a></li>
<li class="chapter" data-level="7.6" data-path="importing-data.html"><a href="importing-data.html#text-versus-binary-files"><i class="fa fa-check"></i><b>7.6</b> Text versus binary files</a></li>
<li class="chapter" data-level="7.7" data-path="importing-data.html"><a href="importing-data.html#unicode-versus-ascii"><i class="fa fa-check"></i><b>7.7</b> Unicode versus ASCII</a></li>
<li class="chapter" data-level="7.8" data-path="importing-data.html"><a href="importing-data.html#organizing-data-with-spreadsheets"><i class="fa fa-check"></i><b>7.8</b> Organizing Data with Spreadsheets</a><ul>
<li class="chapter" data-level="7.8.1" data-path="importing-data.html"><a href="importing-data.html#exercises-11"><i class="fa fa-check"></i><b>7.8.1</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ggplot2.html"><a href="ggplot2.html"><i class="fa fa-check"></i><b>8</b> ggplot2</a><ul>
<li class="chapter" data-level="8.1" data-path="ggplot2.html"><a href="ggplot2.html#the-components-of-a-graph"><i class="fa fa-check"></i><b>8.1</b> The components of a graph</a></li>
<li class="chapter" data-level="8.2" data-path="ggplot2.html"><a href="ggplot2.html#ggplot-objects-a-blank-slate"><i class="fa fa-check"></i><b>8.2</b> <code>ggplot</code> objects: a blank slate</a></li>
<li class="chapter" data-level="8.3" data-path="ggplot2.html"><a href="ggplot2.html#geometries"><i class="fa fa-check"></i><b>8.3</b> Geometries</a></li>
<li class="chapter" data-level="8.4" data-path="ggplot2.html"><a href="ggplot2.html#aesthetic-mappings"><i class="fa fa-check"></i><b>8.4</b> Aesthetic mappings</a></li>
<li class="chapter" data-level="8.5" data-path="ggplot2.html"><a href="ggplot2.html#layers"><i class="fa fa-check"></i><b>8.5</b> Layers</a></li>
<li class="chapter" data-level="8.6" data-path="ggplot2.html"><a href="ggplot2.html#tinkering-with-arguments"><i class="fa fa-check"></i><b>8.6</b> Tinkering with arguments</a></li>
<li class="chapter" data-level="8.7" data-path="ggplot2.html"><a href="ggplot2.html#global-versus-local-aesthetic-mappings"><i class="fa fa-check"></i><b>8.7</b> Global versus local aesthetic mappings</a></li>
<li class="chapter" data-level="8.8" data-path="ggplot2.html"><a href="ggplot2.html#scales"><i class="fa fa-check"></i><b>8.8</b> Scales</a></li>
<li class="chapter" data-level="8.9" data-path="ggplot2.html"><a href="ggplot2.html#labels-and-titles"><i class="fa fa-check"></i><b>8.9</b> Labels and titles</a></li>
<li class="chapter" data-level="8.10" data-path="ggplot2.html"><a href="ggplot2.html#categories-as-colors"><i class="fa fa-check"></i><b>8.10</b> Categories as colors</a></li>
<li class="chapter" data-level="8.11" data-path="ggplot2.html"><a href="ggplot2.html#annotation-shapes-and-adjustments"><i class="fa fa-check"></i><b>8.11</b> Annotation, shapes, and adjustments</a></li>
<li class="chapter" data-level="8.12" data-path="ggplot2.html"><a href="ggplot2.html#add-on-packages"><i class="fa fa-check"></i><b>8.12</b> Add-on packages</a></li>
<li class="chapter" data-level="8.13" data-path="ggplot2.html"><a href="ggplot2.html#putting-it-all-together"><i class="fa fa-check"></i><b>8.13</b> Putting it all together</a></li>
<li class="chapter" data-level="8.14" data-path="ggplot2.html"><a href="ggplot2.html#qplot"><i class="fa fa-check"></i><b>8.14</b> Quick plots with <code>qplot</code></a></li>
<li class="chapter" data-level="8.15" data-path="ggplot2.html"><a href="ggplot2.html#grids-of-plots"><i class="fa fa-check"></i><b>8.15</b> Grids of plots</a></li>
<li class="chapter" data-level="8.16" data-path="ggplot2.html"><a href="ggplot2.html#exercises-12"><i class="fa fa-check"></i><b>8.16</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>9</b> The tidyverse</a><ul>
<li class="chapter" data-level="9.1" data-path="tidyverse.html"><a href="tidyverse.html#tidy-data"><i class="fa fa-check"></i><b>9.1</b> Tidy data</a><ul>
<li class="chapter" data-level="9.1.1" data-path="tidyverse.html"><a href="tidyverse.html#exercises-13"><i class="fa fa-check"></i><b>9.1.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="tidyverse.html"><a href="tidyverse.html#tibbles"><i class="fa fa-check"></i><b>9.2</b> Tibbles</a><ul>
<li class="chapter" data-level="9.2.1" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-display-better"><i class="fa fa-check"></i><b>9.2.1</b> Tibbles display better</a></li>
<li class="chapter" data-level="9.2.2" data-path="tidyverse.html"><a href="tidyverse.html#subsets-of-tibbles-are-tibbles"><i class="fa fa-check"></i><b>9.2.2</b> Subsets of tibbles are tibbles</a></li>
<li class="chapter" data-level="9.2.3" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-can-have-complex-entries"><i class="fa fa-check"></i><b>9.2.3</b> Tibbles can have complex entries</a></li>
<li class="chapter" data-level="9.2.4" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-can-be-grouped"><i class="fa fa-check"></i><b>9.2.4</b> Tibbles can be grouped</a></li>
<li class="chapter" data-level="9.2.5" data-path="tidyverse.html"><a href="tidyverse.html#creating-a-tibble"><i class="fa fa-check"></i><b>9.2.5</b> Creating a tibble</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="tidyverse.html"><a href="tidyverse.html#the-dot-operator"><i class="fa fa-check"></i><b>9.3</b> The dot operator</a></li>
<li class="chapter" data-level="9.4" data-path="tidyverse.html"><a href="tidyverse.html#do"><i class="fa fa-check"></i><b>9.4</b> <code>do</code></a></li>
<li class="chapter" data-level="9.5" data-path="tidyverse.html"><a href="tidyverse.html#the-purrr-package"><i class="fa fa-check"></i><b>9.5</b> The purrr package</a></li>
<li class="chapter" data-level="9.6" data-path="programming-basics.html"><a href="programming-basics.html#conditionals"><i class="fa fa-check"></i><b>9.6</b> Conditionals</a><ul>
<li class="chapter" data-level="9.6.1" data-path="tidyverse.html"><a href="tidyverse.html#case_when"><i class="fa fa-check"></i><b>9.6.1</b> <code>case_when</code></a></li>
<li class="chapter" data-level="9.6.2" data-path="tidyverse.html"><a href="tidyverse.html#between"><i class="fa fa-check"></i><b>9.6.2</b> <code>between</code></a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Data Visualization</b></span></li>
<li class="chapter" data-level="10" data-path="introduction-to-data-visualization.html"><a href="introduction-to-data-visualization.html"><i class="fa fa-check"></i><b>10</b> Introduction to data visualization</a></li>
<li class="chapter" data-level="11" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>11</b> Distributions</a><ul>
<li class="chapter" data-level="11.1" data-path="distributions.html"><a href="distributions.html#variable-types"><i class="fa fa-check"></i><b>11.1</b> Variable types</a></li>
<li class="chapter" data-level="11.2" data-path="distributions.html"><a href="distributions.html#case-study-student-heights"><i class="fa fa-check"></i><b>11.2</b> Case study: Student heights</a></li>
<li class="chapter" data-level="11.3" data-path="distributions.html"><a href="distributions.html#distribution-function"><i class="fa fa-check"></i><b>11.3</b> Distribution function</a></li>
<li class="chapter" data-level="11.4" data-path="distributions.html"><a href="distributions.html#cumulative-distribution-functions"><i class="fa fa-check"></i><b>11.4</b> Cumulative distribution functions</a></li>
<li class="chapter" data-level="11.5" data-path="distributions.html"><a href="distributions.html#histograms"><i class="fa fa-check"></i><b>11.5</b> Histograms</a></li>
<li class="chapter" data-level="11.6" data-path="distributions.html"><a href="distributions.html#smoothed-density"><i class="fa fa-check"></i><b>11.6</b> Smoothed density</a><ul>
<li class="chapter" data-level="11.6.1" data-path="distributions.html"><a href="distributions.html#interpreting-the-y-axis"><i class="fa fa-check"></i><b>11.6.1</b> Interpreting the y-axis</a></li>
<li class="chapter" data-level="11.6.2" data-path="distributions.html"><a href="distributions.html#densities-permit-stratification"><i class="fa fa-check"></i><b>11.6.2</b> Densities permit stratification</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="distributions.html"><a href="distributions.html#exercises-14"><i class="fa fa-check"></i><b>11.7</b> Exercises</a></li>
<li class="chapter" data-level="11.8" data-path="distributions.html"><a href="distributions.html#the-normal-distribution"><i class="fa fa-check"></i><b>11.8</b> The normal distribution</a></li>
<li class="chapter" data-level="11.9" data-path="distributions.html"><a href="distributions.html#standardized-units"><i class="fa fa-check"></i><b>11.9</b> Standardized units</a></li>
<li class="chapter" data-level="11.10" data-path="distributions.html"><a href="distributions.html#quantile-quantile-plots"><i class="fa fa-check"></i><b>11.10</b> Quantile-quantile plots</a></li>
<li class="chapter" data-level="11.11" data-path="distributions.html"><a href="distributions.html#percentiles"><i class="fa fa-check"></i><b>11.11</b> Percentiles</a></li>
<li class="chapter" data-level="11.12" data-path="distributions.html"><a href="distributions.html#case-study-student-heights-continued"><i class="fa fa-check"></i><b>11.12</b> Case study: Student heights (continued)</a></li>
<li class="chapter" data-level="11.13" data-path="distributions.html"><a href="distributions.html#boxplots"><i class="fa fa-check"></i><b>11.13</b> Boxplots</a></li>
<li class="chapter" data-level="11.14" data-path="distributions.html"><a href="distributions.html#student-height-cont"><i class="fa fa-check"></i><b>11.14</b> Case study: Student heights (continued)</a></li>
<li class="chapter" data-level="11.15" data-path="distributions.html"><a href="distributions.html#exercises-15"><i class="fa fa-check"></i><b>11.15</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="other-geometries.html"><a href="other-geometries.html"><i class="fa fa-check"></i><b>12</b> ggplot2 geometries</a><ul>
<li class="chapter" data-level="12.1" data-path="other-geometries.html"><a href="other-geometries.html#barplots"><i class="fa fa-check"></i><b>12.1</b> Barplots</a></li>
<li class="chapter" data-level="12.2" data-path="other-geometries.html"><a href="other-geometries.html#histograms-1"><i class="fa fa-check"></i><b>12.2</b> Histograms</a></li>
<li class="chapter" data-level="12.3" data-path="other-geometries.html"><a href="other-geometries.html#density-plots"><i class="fa fa-check"></i><b>12.3</b> Density plots</a></li>
<li class="chapter" data-level="12.4" data-path="other-geometries.html"><a href="other-geometries.html#boxplot-1"><i class="fa fa-check"></i><b>12.4</b> Boxplot</a></li>
<li class="chapter" data-level="12.5" data-path="other-geometries.html"><a href="other-geometries.html#qq-plots"><i class="fa fa-check"></i><b>12.5</b> QQ-plots</a></li>
<li class="chapter" data-level="12.6" data-path="other-geometries.html"><a href="other-geometries.html#images"><i class="fa fa-check"></i><b>12.6</b> Images</a></li>
<li class="chapter" data-level="12.7" data-path="other-geometries.html"><a href="other-geometries.html#quick-plots"><i class="fa fa-check"></i><b>12.7</b> Quick plots</a><ul>
<li class="chapter" data-level="12.7.1" data-path="other-geometries.html"><a href="other-geometries.html#exercises-16"><i class="fa fa-check"></i><b>12.7.1</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="gapminder.html"><a href="gapminder.html"><i class="fa fa-check"></i><b>13</b> Data visualization in practice</a><ul>
<li class="chapter" data-level="13.1" data-path="gapminder.html"><a href="gapminder.html#gapminder"><i class="fa fa-check"></i><b>13.1</b> Gapminder</a><ul>
<li class="chapter" data-level="13.1.1" data-path="gapminder.html"><a href="gapminder.html#hans-roslings-quiz"><i class="fa fa-check"></i><b>13.1.1</b> Hans Rosling’s quiz</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="gapminder.html"><a href="gapminder.html#scatterplots"><i class="fa fa-check"></i><b>13.2</b> Scatterplots</a></li>
<li class="chapter" data-level="13.3" data-path="gapminder.html"><a href="gapminder.html#faceting"><i class="fa fa-check"></i><b>13.3</b> Faceting</a><ul>
<li class="chapter" data-level="13.3.1" data-path="gapminder.html"><a href="gapminder.html#facet_wrap"><i class="fa fa-check"></i><b>13.3.1</b> <code>facet_wrap</code></a></li>
<li class="chapter" data-level="13.3.2" data-path="gapminder.html"><a href="gapminder.html#fixed-scales-for-better-comparisons"><i class="fa fa-check"></i><b>13.3.2</b> Fixed scales for better comparisons</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="gapminder.html"><a href="gapminder.html#time-series-plots"><i class="fa fa-check"></i><b>13.4</b> Time series plots</a><ul>
<li class="chapter" data-level="13.4.1" data-path="gapminder.html"><a href="gapminder.html#labels-instead-of-legends"><i class="fa fa-check"></i><b>13.4.1</b> Labels instead of legends</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="gapminder.html"><a href="gapminder.html#transformations"><i class="fa fa-check"></i><b>13.5</b> Transformations</a><ul>
<li class="chapter" data-level="13.5.1" data-path="gapminder.html"><a href="gapminder.html#log-transformation"><i class="fa fa-check"></i><b>13.5.1</b> Log transformation</a></li>
<li class="chapter" data-level="13.5.2" data-path="gapminder.html"><a href="gapminder.html#which-base"><i class="fa fa-check"></i><b>13.5.2</b> Which base?</a></li>
<li class="chapter" data-level="13.5.3" data-path="gapminder.html"><a href="gapminder.html#transform-the-values-or-the-scale"><i class="fa fa-check"></i><b>13.5.3</b> Transform the values or the scale?</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="gapminder.html"><a href="gapminder.html#modes"><i class="fa fa-check"></i><b>13.6</b> Modes</a></li>
<li class="chapter" data-level="13.7" data-path="gapminder.html"><a href="gapminder.html#mulitple-distributions-boxplots-and-ridge-plots"><i class="fa fa-check"></i><b>13.7</b> Mulitple distributions: boxplots and ridge plots</a><ul>
<li class="chapter" data-level="13.7.1" data-path="gapminder.html"><a href="gapminder.html#boxplots-1"><i class="fa fa-check"></i><b>13.7.1</b> Boxplots</a></li>
<li class="chapter" data-level="13.7.2" data-path="gapminder.html"><a href="gapminder.html#ridge-plots"><i class="fa fa-check"></i><b>13.7.2</b> Ridge plots</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="gapminder.html"><a href="gapminder.html#example-1970-versus-2010-income-distributions"><i class="fa fa-check"></i><b>13.8</b> Example: 1970 versus 2010 income distributions</a><ul>
<li class="chapter" data-level="13.8.1" data-path="gapminder.html"><a href="gapminder.html#accessing-computed-variables"><i class="fa fa-check"></i><b>13.8.1</b> Accessing computed variables</a></li>
<li class="chapter" data-level="13.8.2" data-path="gapminder.html"><a href="gapminder.html#weighted-densities"><i class="fa fa-check"></i><b>13.8.2</b> Weighted densities</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="gapminder.html"><a href="gapminder.html#ecological-fallacy"><i class="fa fa-check"></i><b>13.9</b> Ecological fallacy</a><ul>
<li class="chapter" data-level="13.9.1" data-path="gapminder.html"><a href="gapminder.html#logit"><i class="fa fa-check"></i><b>13.9.1</b> Logistic transformation</a></li>
<li class="chapter" data-level="13.9.2" data-path="gapminder.html"><a href="gapminder.html#show-the-data"><i class="fa fa-check"></i><b>13.9.2</b> Show the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html"><i class="fa fa-check"></i><b>14</b> Data visualization principles</a><ul>
<li class="chapter" data-level="14.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#encoding-data-using-visual-cues"><i class="fa fa-check"></i><b>14.1</b> Encoding data using visual cues</a></li>
<li class="chapter" data-level="14.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#know-when-to-include-0"><i class="fa fa-check"></i><b>14.2</b> Know when to include 0</a></li>
<li class="chapter" data-level="14.3" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#do-not-distort-quantities"><i class="fa fa-check"></i><b>14.3</b> Do not distort quantities</a></li>
<li class="chapter" data-level="14.4" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#order-by-a-meaningful-value"><i class="fa fa-check"></i><b>14.4</b> Order by a meaningful value</a></li>
<li class="chapter" data-level="14.5" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#show-the-data-1"><i class="fa fa-check"></i><b>14.5</b> Show the data</a></li>
<li class="chapter" data-level="14.6" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparisons-use-common-axes"><i class="fa fa-check"></i><b>14.6</b> Ease comparisons: use common axes</a></li>
<li class="chapter" data-level="14.7" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparisons-align-plots-vertically-to-see-horizontal-changes-and-horizontally-to-see-vertical-changes"><i class="fa fa-check"></i><b>14.7</b> Ease comparisons: align plots vertically to see horizontal changes and horizontally to see vertical changes</a></li>
<li class="chapter" data-level="14.8" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#consider-transformations"><i class="fa fa-check"></i><b>14.8</b> Consider transformations</a></li>
<li class="chapter" data-level="14.9" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#visual-cues-to-be-compared-should-be-adjacent"><i class="fa fa-check"></i><b>14.9</b> Visual cues to be compared should be adjacent</a></li>
<li class="chapter" data-level="14.10" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparison-use-color"><i class="fa fa-check"></i><b>14.10</b> Ease comparison: use color</a></li>
<li class="chapter" data-level="14.11" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#think-of-the-color-blind"><i class="fa fa-check"></i><b>14.11</b> Think of the color blind</a></li>
<li class="chapter" data-level="14.12" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#two-variables"><i class="fa fa-check"></i><b>14.12</b> Two variables</a><ul>
<li class="chapter" data-level="14.12.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#slope-charts"><i class="fa fa-check"></i><b>14.12.1</b> Slope charts</a></li>
<li class="chapter" data-level="14.12.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#bland-altman-plot"><i class="fa fa-check"></i><b>14.12.2</b> Bland-Altman plot</a></li>
</ul></li>
<li class="chapter" data-level="14.13" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#encoding-a-third-variable"><i class="fa fa-check"></i><b>14.13</b> Encoding a third variable</a></li>
<li class="chapter" data-level="14.14" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-pseudo-three-dimensional-plots"><i class="fa fa-check"></i><b>14.14</b> Avoid pseudo three dimensional plots</a></li>
<li class="chapter" data-level="14.15" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-gratuitous-three-dimensional-plots"><i class="fa fa-check"></i><b>14.15</b> Avoid gratuitous three dimensional plots</a></li>
<li class="chapter" data-level="14.16" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-too-many-significant-digits"><i class="fa fa-check"></i><b>14.16</b> Avoid too many significant digits</a></li>
<li class="chapter" data-level="14.17" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#know-your-audience"><i class="fa fa-check"></i><b>14.17</b> Know your audience</a></li>
<li class="chapter" data-level="14.18" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#exercises-17"><i class="fa fa-check"></i><b>14.18</b> Exercises</a></li>
<li class="chapter" data-level="14.19" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#case-study-the-impact-of-vaccines-on-battling-infectious-diseases"><i class="fa fa-check"></i><b>14.19</b> Case study: The impact of vaccines on battling infectious diseases</a><ul>
<li class="chapter" data-level="14.19.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#exercises-18"><i class="fa fa-check"></i><b>14.19.1</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="robust-summaries.html"><a href="robust-summaries.html"><i class="fa fa-check"></i><b>15</b> Robust summaries</a><ul>
<li class="chapter" data-level="15.1" data-path="robust-summaries.html"><a href="robust-summaries.html#outliers"><i class="fa fa-check"></i><b>15.1</b> Outliers</a></li>
<li class="chapter" data-level="15.2" data-path="robust-summaries.html"><a href="robust-summaries.html#median"><i class="fa fa-check"></i><b>15.2</b> Median</a></li>
<li class="chapter" data-level="15.3" data-path="robust-summaries.html"><a href="robust-summaries.html#the-inter-quartile-range-iqr"><i class="fa fa-check"></i><b>15.3</b> The inter quartile range (IQR)</a></li>
<li class="chapter" data-level="15.4" data-path="robust-summaries.html"><a href="robust-summaries.html#tukeys-definition-of-an-outlier"><i class="fa fa-check"></i><b>15.4</b> Tukey’s definition of an outlier</a></li>
<li class="chapter" data-level="15.5" data-path="robust-summaries.html"><a href="robust-summaries.html#median-absolute-deviation"><i class="fa fa-check"></i><b>15.5</b> Median absolute deviation</a></li>
<li class="chapter" data-level="15.6" data-path="robust-summaries.html"><a href="robust-summaries.html#exercises-19"><i class="fa fa-check"></i><b>15.6</b> Exercises</a></li>
<li class="chapter" data-level="15.7" data-path="robust-summaries.html"><a href="robust-summaries.html#case-study-self-reported-student-heights"><i class="fa fa-check"></i><b>15.7</b> Case study: Self-reported student heights</a></li>
</ul></li>
<li class="part"><span><b>III Data Wrangling</b></span></li>
<li class="chapter" data-level="16" data-path="introduction-to-data-wrangling.html"><a href="introduction-to-data-wrangling.html"><i class="fa fa-check"></i><b>16</b> Introduction to Data Wrangling</a></li>
<li class="chapter" data-level="17" data-path="reshaping-data.html"><a href="reshaping-data.html"><i class="fa fa-check"></i><b>17</b> Reshaping data</a><ul>
<li class="chapter" data-level="17.1" data-path="reshaping-data.html"><a href="reshaping-data.html#gather"><i class="fa fa-check"></i><b>17.1</b> <code>gather</code></a></li>
<li class="chapter" data-level="17.2" data-path="reshaping-data.html"><a href="reshaping-data.html#spread"><i class="fa fa-check"></i><b>17.2</b> <code>spread</code></a></li>
<li class="chapter" data-level="17.3" data-path="reshaping-data.html"><a href="reshaping-data.html#separate"><i class="fa fa-check"></i><b>17.3</b> <code>separate</code></a></li>
<li class="chapter" data-level="17.4" data-path="reshaping-data.html"><a href="reshaping-data.html#unite"><i class="fa fa-check"></i><b>17.4</b> <code>unite</code></a></li>
<li class="chapter" data-level="17.5" data-path="reshaping-data.html"><a href="reshaping-data.html#exercises-20"><i class="fa fa-check"></i><b>17.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="joining-tables.html"><a href="joining-tables.html"><i class="fa fa-check"></i><b>18</b> Joining tables</a><ul>
<li class="chapter" data-level="18.1" data-path="joining-tables.html"><a href="joining-tables.html#joins"><i class="fa fa-check"></i><b>18.1</b> Joins</a><ul>
<li class="chapter" data-level="18.1.1" data-path="joining-tables.html"><a href="joining-tables.html#left-join"><i class="fa fa-check"></i><b>18.1.1</b> Left join</a></li>
<li class="chapter" data-level="18.1.2" data-path="joining-tables.html"><a href="joining-tables.html#right-join"><i class="fa fa-check"></i><b>18.1.2</b> Right join</a></li>
<li class="chapter" data-level="18.1.3" data-path="joining-tables.html"><a href="joining-tables.html#inner-join"><i class="fa fa-check"></i><b>18.1.3</b> Inner join</a></li>
<li class="chapter" data-level="18.1.4" data-path="joining-tables.html"><a href="joining-tables.html#full-join"><i class="fa fa-check"></i><b>18.1.4</b> Full join</a></li>
<li class="chapter" data-level="18.1.5" data-path="joining-tables.html"><a href="joining-tables.html#semi-join"><i class="fa fa-check"></i><b>18.1.5</b> Semi join</a></li>
<li class="chapter" data-level="18.1.6" data-path="joining-tables.html"><a href="joining-tables.html#anti-join"><i class="fa fa-check"></i><b>18.1.6</b> Anti join</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="joining-tables.html"><a href="joining-tables.html#binding"><i class="fa fa-check"></i><b>18.2</b> Binding</a><ul>
<li class="chapter" data-level="18.2.1" data-path="joining-tables.html"><a href="joining-tables.html#binding-columns"><i class="fa fa-check"></i><b>18.2.1</b> Binding columns</a></li>
<li class="chapter" data-level="18.2.2" data-path="joining-tables.html"><a href="joining-tables.html#binding-by-rows"><i class="fa fa-check"></i><b>18.2.2</b> Binding by rows</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="joining-tables.html"><a href="joining-tables.html#set-operators"><i class="fa fa-check"></i><b>18.3</b> Set operators</a><ul>
<li class="chapter" data-level="18.3.1" data-path="joining-tables.html"><a href="joining-tables.html#intersect"><i class="fa fa-check"></i><b>18.3.1</b> Intersect</a></li>
<li class="chapter" data-level="18.3.2" data-path="joining-tables.html"><a href="joining-tables.html#union"><i class="fa fa-check"></i><b>18.3.2</b> Union</a></li>
<li class="chapter" data-level="18.3.3" data-path="joining-tables.html"><a href="joining-tables.html#setdiff"><i class="fa fa-check"></i><b>18.3.3</b> <code>setdiff</code></a></li>
<li class="chapter" data-level="18.3.4" data-path="joining-tables.html"><a href="joining-tables.html#setequal"><i class="fa fa-check"></i><b>18.3.4</b> <code>setequal</code></a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="joining-tables.html"><a href="joining-tables.html#exercises-21"><i class="fa fa-check"></i><b>18.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="web-scraping.html"><a href="web-scraping.html"><i class="fa fa-check"></i><b>19</b> Web Scraping</a><ul>
<li class="chapter" data-level="19.1" data-path="web-scraping.html"><a href="web-scraping.html#html"><i class="fa fa-check"></i><b>19.1</b> HTML</a></li>
<li class="chapter" data-level="19.2" data-path="web-scraping.html"><a href="web-scraping.html#the-rvest-package"><i class="fa fa-check"></i><b>19.2</b> The rvest package</a></li>
<li class="chapter" data-level="19.3" data-path="web-scraping.html"><a href="web-scraping.html#css-selectors"><i class="fa fa-check"></i><b>19.3</b> CSS selectors</a></li>
<li class="chapter" data-level="19.4" data-path="web-scraping.html"><a href="web-scraping.html#json"><i class="fa fa-check"></i><b>19.4</b> JSON</a></li>
<li class="chapter" data-level="19.5" data-path="web-scraping.html"><a href="web-scraping.html#exercises-22"><i class="fa fa-check"></i><b>19.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="string-processing.html"><a href="string-processing.html"><i class="fa fa-check"></i><b>20</b> String Processing</a><ul>
<li class="chapter" data-level="20.1" data-path="string-processing.html"><a href="string-processing.html#stringr"><i class="fa fa-check"></i><b>20.1</b> The stringr package</a></li>
<li class="chapter" data-level="20.2" data-path="string-processing.html"><a href="string-processing.html#case-study-1-us-murders-data"><i class="fa fa-check"></i><b>20.2</b> Case study 1: US murders data</a></li>
<li class="chapter" data-level="20.3" data-path="string-processing.html"><a href="string-processing.html#case-study-2-self-reported-heights"><i class="fa fa-check"></i><b>20.3</b> Case study 2: Self reported heights</a></li>
<li class="chapter" data-level="20.4" data-path="string-processing.html"><a href="string-processing.html#how-to-escape-when-defining-strings"><i class="fa fa-check"></i><b>20.4</b> How to <em>escape</em> when defining strings</a></li>
<li class="chapter" data-level="20.5" data-path="string-processing.html"><a href="string-processing.html#regular-expressions"><i class="fa fa-check"></i><b>20.5</b> Regular expressions</a><ul>
<li class="chapter" data-level="20.5.1" data-path="string-processing.html"><a href="string-processing.html#strings-are-a-regexp"><i class="fa fa-check"></i><b>20.5.1</b> Strings are a regexp</a></li>
<li class="chapter" data-level="20.5.2" data-path="string-processing.html"><a href="string-processing.html#special-characters"><i class="fa fa-check"></i><b>20.5.2</b> Special characters</a></li>
<li class="chapter" data-level="20.5.3" data-path="string-processing.html"><a href="string-processing.html#character-classes"><i class="fa fa-check"></i><b>20.5.3</b> Character classes</a></li>
<li class="chapter" data-level="20.5.4" data-path="string-processing.html"><a href="string-processing.html#anchors"><i class="fa fa-check"></i><b>20.5.4</b> Anchors</a></li>
<li class="chapter" data-level="20.5.5" data-path="string-processing.html"><a href="string-processing.html#quantifiers"><i class="fa fa-check"></i><b>20.5.5</b> Quantifiers</a></li>
<li class="chapter" data-level="20.5.6" data-path="string-processing.html"><a href="string-processing.html#white-space-s"><i class="fa fa-check"></i><b>20.5.6</b> White space <code>\s</code></a></li>
<li class="chapter" data-level="20.5.7" data-path="string-processing.html"><a href="string-processing.html#quantifiers-1"><i class="fa fa-check"></i><b>20.5.7</b> Quantifiers: <code>*</code>, <code>?</code>, <code>+</code></a></li>
<li class="chapter" data-level="20.5.8" data-path="string-processing.html"><a href="string-processing.html#not"><i class="fa fa-check"></i><b>20.5.8</b> Not</a></li>
<li class="chapter" data-level="20.5.9" data-path="string-processing.html"><a href="string-processing.html#groups"><i class="fa fa-check"></i><b>20.5.9</b> Groups</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="string-processing.html"><a href="string-processing.html#search-and-replace-with-regex"><i class="fa fa-check"></i><b>20.6</b> Search and replace with regex</a><ul>
<li class="chapter" data-level="20.6.1" data-path="string-processing.html"><a href="string-processing.html#search-and-replace-using-groups"><i class="fa fa-check"></i><b>20.6.1</b> Search and replace using groups</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path="string-processing.html"><a href="string-processing.html#testing-and-improving"><i class="fa fa-check"></i><b>20.7</b> Testing and improving</a></li>
<li class="chapter" data-level="20.8" data-path="string-processing.html"><a href="string-processing.html#trimming"><i class="fa fa-check"></i><b>20.8</b> Trimming</a></li>
<li class="chapter" data-level="20.9" data-path="string-processing.html"><a href="string-processing.html#changing-lettercase"><i class="fa fa-check"></i><b>20.9</b> Changing lettercase</a></li>
<li class="chapter" data-level="20.10" data-path="string-processing.html"><a href="string-processing.html#case-study-2-self-reported-heights-continued"><i class="fa fa-check"></i><b>20.10</b> Case study 2: Self reported heights (continued)</a><ul>
<li class="chapter" data-level="20.10.1" data-path="string-processing.html"><a href="string-processing.html#the-extract-function"><i class="fa fa-check"></i><b>20.10.1</b> The <code>extract</code> function</a></li>
<li class="chapter" data-level="20.10.2" data-path="string-processing.html"><a href="string-processing.html#putting-it-all-together-1"><i class="fa fa-check"></i><b>20.10.2</b> Putting it all together</a></li>
</ul></li>
<li class="chapter" data-level="20.11" data-path="string-processing.html"><a href="string-processing.html#string-splitting"><i class="fa fa-check"></i><b>20.11</b> String splitting</a></li>
<li class="chapter" data-level="20.12" data-path="string-processing.html"><a href="string-processing.html#case-study-3-extracting-tables-from-a-pdf"><i class="fa fa-check"></i><b>20.12</b> Case study 3: Extracting tables from a PDF</a></li>
<li class="chapter" data-level="20.13" data-path="string-processing.html"><a href="string-processing.html#recode"><i class="fa fa-check"></i><b>20.13</b> Re-coding</a></li>
<li class="chapter" data-level="20.14" data-path="string-processing.html"><a href="string-processing.html#exercises-23"><i class="fa fa-check"></i><b>20.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html"><i class="fa fa-check"></i><b>21</b> Parsing Dates and Times</a><ul>
<li class="chapter" data-level="21.1" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#the-date-data-type"><i class="fa fa-check"></i><b>21.1</b> The date data type</a></li>
<li class="chapter" data-level="21.2" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#lubridate"><i class="fa fa-check"></i><b>21.2</b> The lubridate package</a></li>
<li class="chapter" data-level="21.3" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#exercises-24"><i class="fa fa-check"></i><b>21.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>22</b> Text mining</a><ul>
<li class="chapter" data-level="22.1" data-path="text-mining.html"><a href="text-mining.html#case-study-trump-tweets"><i class="fa fa-check"></i><b>22.1</b> Case study: Trump tweets</a></li>
<li class="chapter" data-level="22.2" data-path="text-mining.html"><a href="text-mining.html#text-as-data"><i class="fa fa-check"></i><b>22.2</b> Text as data</a></li>
<li class="chapter" data-level="22.3" data-path="text-mining.html"><a href="text-mining.html#sentiment-analysis"><i class="fa fa-check"></i><b>22.3</b> Sentiment analysis</a></li>
<li class="chapter" data-level="22.4" data-path="text-mining.html"><a href="text-mining.html#exercises-25"><i class="fa fa-check"></i><b>22.4</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Probability, Inference, and Regression with R</b></span></li>
<li class="chapter" data-level="23" data-path="introduction-to-statistics-with-r.html"><a href="introduction-to-statistics-with-r.html"><i class="fa fa-check"></i><b>23</b> Introduction to Statistics with R</a></li>
<li class="chapter" data-level="24" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>24</b> Probability</a><ul>
<li class="chapter" data-level="24.1" data-path="probability.html"><a href="probability.html#discrete-probability"><i class="fa fa-check"></i><b>24.1</b> Discrete probability</a><ul>
<li class="chapter" data-level="24.1.1" data-path="probability.html"><a href="probability.html#relative-frequency"><i class="fa fa-check"></i><b>24.1.1</b> Relative frequency</a></li>
<li class="chapter" data-level="24.1.2" data-path="probability.html"><a href="probability.html#notation"><i class="fa fa-check"></i><b>24.1.2</b> Notation</a></li>
<li class="chapter" data-level="24.1.3" data-path="probability.html"><a href="probability.html#monte-carlo-simulations"><i class="fa fa-check"></i><b>24.1.3</b> Monte Carlo simulations</a></li>
<li class="chapter" data-level="24.1.4" data-path="probability.html"><a href="probability.html#setting-the-random-seed"><i class="fa fa-check"></i><b>24.1.4</b> Setting the random seed</a></li>
<li class="chapter" data-level="" data-path="probability.html"><a href="probability.html#with-and-without-replacement"><i class="fa fa-check"></i>With and without replacement</a></li>
<li class="chapter" data-level="24.1.5" data-path="probability.html"><a href="probability.html#discrete-probability-distributions"><i class="fa fa-check"></i><b>24.1.5</b> Discrete probability distributions</a></li>
<li class="chapter" data-level="24.1.6" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>24.1.6</b> Independence</a></li>
<li class="chapter" data-level="24.1.7" data-path="probability.html"><a href="probability.html#conditional-probabilities"><i class="fa fa-check"></i><b>24.1.7</b> Conditional probabilities</a></li>
<li class="chapter" data-level="24.1.8" data-path="probability.html"><a href="probability.html#multiplication-rule"><i class="fa fa-check"></i><b>24.1.8</b> Multiplication rule</a></li>
<li class="chapter" data-level="24.1.9" data-path="probability.html"><a href="probability.html#multiplication-rule-under-indepedence"><i class="fa fa-check"></i><b>24.1.9</b> Multiplication rule under indepedence</a></li>
<li class="chapter" data-level="24.1.10" data-path="probability.html"><a href="probability.html#addition-rule"><i class="fa fa-check"></i><b>24.1.10</b> Addition rule</a></li>
<li class="chapter" data-level="24.1.11" data-path="probability.html"><a href="probability.html#combinations-and-permutations"><i class="fa fa-check"></i><b>24.1.11</b> Combinations and permutations</a></li>
<li class="chapter" data-level="24.1.12" data-path="probability.html"><a href="probability.html#monte-carlo-example"><i class="fa fa-check"></i><b>24.1.12</b> Monte Carlo example</a></li>
<li class="chapter" data-level="24.1.13" data-path="probability.html"><a href="probability.html#birthday-problem-example"><i class="fa fa-check"></i><b>24.1.13</b> Birthday problem example</a></li>
<li class="chapter" data-level="24.1.14" data-path="probability.html"><a href="probability.html#how-many-monte-carlo-experiments-are-enough"><i class="fa fa-check"></i><b>24.1.14</b> How many Monte Carlo experiments are enough</a></li>
<li class="chapter" data-level="24.1.15" data-path="probability.html"><a href="probability.html#monty-hall-problem-example"><i class="fa fa-check"></i><b>24.1.15</b> Monty Hall problem example</a></li>
<li class="chapter" data-level="24.1.16" data-path="probability.html"><a href="probability.html#exercises-26"><i class="fa fa-check"></i><b>24.1.16</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="probability.html"><a href="probability.html#continuous-probability"><i class="fa fa-check"></i><b>24.2</b> Continuous probability</a><ul>
<li class="chapter" data-level="24.2.1" data-path="probability.html"><a href="probability.html#theoretical-distribution"><i class="fa fa-check"></i><b>24.2.1</b> Theoretical distribution</a></li>
<li class="chapter" data-level="24.2.2" data-path="probability.html"><a href="probability.html#theoretical-distributions-as-approximations"><i class="fa fa-check"></i><b>24.2.2</b> Theoretical distributions as approximations</a></li>
<li class="chapter" data-level="24.2.3" data-path="probability.html"><a href="probability.html#the-probability-density"><i class="fa fa-check"></i><b>24.2.3</b> The probability density</a></li>
<li class="chapter" data-level="24.2.4" data-path="probability.html"><a href="probability.html#monte-carlo-simulations-for-continuous-variables"><i class="fa fa-check"></i><b>24.2.4</b> Monte Carlo simulations for continuous variables</a></li>
<li class="chapter" data-level="24.2.5" data-path="probability.html"><a href="probability.html#other-continuous-distributions"><i class="fa fa-check"></i><b>24.2.5</b> Other continuous distributions</a></li>
<li class="chapter" data-level="24.2.6" data-path="probability.html"><a href="probability.html#exercises-27"><i class="fa fa-check"></i><b>24.2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="probability.html"><a href="probability.html#random-variables"><i class="fa fa-check"></i><b>24.3</b> Random variables</a><ul>
<li class="chapter" data-level="24.3.1" data-path="probability.html"><a href="probability.html#sampling-models"><i class="fa fa-check"></i><b>24.3.1</b> Sampling models</a></li>
<li class="chapter" data-level="24.3.2" data-path="probability.html"><a href="probability.html#the-probability-distribution-of-a-random-variable"><i class="fa fa-check"></i><b>24.3.2</b> The probability distribution of a random variable</a></li>
<li class="chapter" data-level="24.3.3" data-path="probability.html"><a href="probability.html#distributions-versus-probability-distributions"><i class="fa fa-check"></i><b>24.3.3</b> Distributions versus probability distributions</a></li>
<li class="chapter" data-level="24.3.4" data-path="probability.html"><a href="probability.html#notation-for-random-variables"><i class="fa fa-check"></i><b>24.3.4</b> Notation for random variables</a></li>
<li class="chapter" data-level="24.3.5" data-path="probability.html"><a href="probability.html#central-limit-theorem"><i class="fa fa-check"></i><b>24.3.5</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="24.3.6" data-path="probability.html"><a href="probability.html#the-expected-value-and-standard-error"><i class="fa fa-check"></i><b>24.3.6</b> The expected value and standard error</a></li>
<li class="chapter" data-level="24.3.7" data-path="probability.html"><a href="probability.html#central-limit-theorem-approximation"><i class="fa fa-check"></i><b>24.3.7</b> Central Limit Theorem approximation</a></li>
<li class="chapter" data-level="24.3.8" data-path="probability.html"><a href="probability.html#statistical-properties-of-averages"><i class="fa fa-check"></i><b>24.3.8</b> Statistical properties of averages</a></li>
<li class="chapter" data-level="24.3.9" data-path="probability.html"><a href="probability.html#law-of-large-numbers"><i class="fa fa-check"></i><b>24.3.9</b> Law of large numbers</a></li>
<li class="chapter" data-level="24.3.10" data-path="probability.html"><a href="probability.html#misinterpreting-law-of-averages"><i class="fa fa-check"></i><b>24.3.10</b> Misinterpreting law of averages</a></li>
<li class="chapter" data-level="24.3.11" data-path="probability.html"><a href="probability.html#how-large-is-large-in-clt"><i class="fa fa-check"></i><b>24.3.11</b> How large is large in CLT?</a></li>
<li class="chapter" data-level="24.3.12" data-path="probability.html"><a href="probability.html#population-sd-versus-the-sample-sd"><i class="fa fa-check"></i><b>24.3.12</b> Population SD versus the sample SD</a></li>
<li class="chapter" data-level="24.3.13" data-path="probability.html"><a href="probability.html#exercises-28"><i class="fa fa-check"></i><b>24.3.13</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="probability.html"><a href="probability.html#case-study-the-big-short"><i class="fa fa-check"></i><b>24.4</b> Case study: The Big Short</a><ul>
<li class="chapter" data-level="24.4.1" data-path="probability.html"><a href="probability.html#interest-rates-explained-with-chance-model"><i class="fa fa-check"></i><b>24.4.1</b> Interest rates explained with chance model</a></li>
<li class="chapter" data-level="24.4.2" data-path="probability.html"><a href="probability.html#the-big-short"><i class="fa fa-check"></i><b>24.4.2</b> The Big Short</a></li>
<li class="chapter" data-level="24.4.3" data-path="probability.html"><a href="probability.html#exercises-29"><i class="fa fa-check"></i><b>24.4.3</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>25</b> Statistical Inference</a><ul>
<li class="chapter" data-level="25.1" data-path="statistical-inference.html"><a href="statistical-inference.html#polls"><i class="fa fa-check"></i><b>25.1</b> Polls</a><ul>
<li class="chapter" data-level="25.1.1" data-path="statistical-inference.html"><a href="statistical-inference.html#the-sampling-model-for-polls"><i class="fa fa-check"></i><b>25.1.1</b> The sampling model for polls</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="statistical-inference.html"><a href="statistical-inference.html#populations-samples-parameters-and-estimates"><i class="fa fa-check"></i><b>25.2</b> Populations, samples, parameters and estimates</a><ul>
<li class="chapter" data-level="25.2.1" data-path="statistical-inference.html"><a href="statistical-inference.html#the-sample-average"><i class="fa fa-check"></i><b>25.2.1</b> The sample average</a></li>
<li class="chapter" data-level="25.2.2" data-path="statistical-inference.html"><a href="statistical-inference.html#parameters"><i class="fa fa-check"></i><b>25.2.2</b> Parameters</a></li>
<li class="chapter" data-level="25.2.3" data-path="statistical-inference.html"><a href="statistical-inference.html#polling-versus-forecasting"><i class="fa fa-check"></i><b>25.2.3</b> Polling versus forecasting</a></li>
<li class="chapter" data-level="25.2.4" data-path="statistical-inference.html"><a href="statistical-inference.html#properties-of-our-estimate-expected-value-and-standard-error"><i class="fa fa-check"></i><b>25.2.4</b> Properties of our estimate: expected value and standard error</a></li>
<li class="chapter" data-level="25.2.5" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-30"><i class="fa fa-check"></i><b>25.2.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="statistical-inference.html"><a href="statistical-inference.html#clt"><i class="fa fa-check"></i><b>25.3</b> Central Limit Theorem in practice</a><ul>
<li class="chapter" data-level="25.3.1" data-path="statistical-inference.html"><a href="statistical-inference.html#a-monte-carlo-simulation"><i class="fa fa-check"></i><b>25.3.1</b> A Monte Carlo simulation</a></li>
<li class="chapter" data-level="25.3.2" data-path="statistical-inference.html"><a href="statistical-inference.html#the-spread"><i class="fa fa-check"></i><b>25.3.2</b> The spread</a></li>
<li class="chapter" data-level="25.3.3" data-path="statistical-inference.html"><a href="statistical-inference.html#bias-why-not-run-a-very-large-poll"><i class="fa fa-check"></i><b>25.3.3</b> Bias: why not run a very large poll?</a></li>
<li class="chapter" data-level="25.3.4" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-31"><i class="fa fa-check"></i><b>25.3.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>25.4</b> Confidence intervals</a><ul>
<li class="chapter" data-level="25.4.1" data-path="statistical-inference.html"><a href="statistical-inference.html#a-monte-carlo-simulation-1"><i class="fa fa-check"></i><b>25.4.1</b> A Monte Carlo simulation</a></li>
<li class="chapter" data-level="25.4.2" data-path="statistical-inference.html"><a href="statistical-inference.html#the-correct-language"><i class="fa fa-check"></i><b>25.4.2</b> The correct language</a></li>
<li class="chapter" data-level="25.4.3" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-32"><i class="fa fa-check"></i><b>25.4.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="statistical-inference.html"><a href="statistical-inference.html#power"><i class="fa fa-check"></i><b>25.5</b> Power</a></li>
<li class="chapter" data-level="25.6" data-path="statistical-inference.html"><a href="statistical-inference.html#p-values"><i class="fa fa-check"></i><b>25.6</b> p-values</a></li>
<li class="chapter" data-level="25.7" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-models"><i class="fa fa-check"></i><b>25.7</b> Statistical models</a><ul>
<li class="chapter" data-level="25.7.1" data-path="statistical-inference.html"><a href="statistical-inference.html#poll-aggregators"><i class="fa fa-check"></i><b>25.7.1</b> Poll aggregators</a></li>
<li class="chapter" data-level="25.7.2" data-path="statistical-inference.html"><a href="statistical-inference.html#poll-data"><i class="fa fa-check"></i><b>25.7.2</b> Poll data</a></li>
<li class="chapter" data-level="25.7.3" data-path="statistical-inference.html"><a href="statistical-inference.html#pollster-bias"><i class="fa fa-check"></i><b>25.7.3</b> Pollster bias</a></li>
<li class="chapter" data-level="25.7.4" data-path="statistical-inference.html"><a href="statistical-inference.html#data-driven-model"><i class="fa fa-check"></i><b>25.7.4</b> A data driven model</a></li>
<li class="chapter" data-level="25.7.5" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-33"><i class="fa fa-check"></i><b>25.7.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="25.8" data-path="statistical-inference.html"><a href="statistical-inference.html#bayesian-statistics"><i class="fa fa-check"></i><b>25.8</b> Bayesian statistics</a><ul>
<li class="chapter" data-level="25.8.1" data-path="statistical-inference.html"><a href="statistical-inference.html#bayes-theorem"><i class="fa fa-check"></i><b>25.8.1</b> Bayes theorem</a></li>
</ul></li>
<li class="chapter" data-level="25.9" data-path="statistical-inference.html"><a href="statistical-inference.html#bayes-theorem-simulation"><i class="fa fa-check"></i><b>25.9</b> Bayes Theorem simulation</a><ul>
<li class="chapter" data-level="25.9.1" data-path="statistical-inference.html"><a href="statistical-inference.html#bayes-in-practice"><i class="fa fa-check"></i><b>25.9.1</b> Bayes in practice</a></li>
<li class="chapter" data-level="25.9.2" data-path="statistical-inference.html"><a href="statistical-inference.html#the-hierarchical-model"><i class="fa fa-check"></i><b>25.9.2</b> The hierarchical model</a></li>
<li class="chapter" data-level="25.9.3" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-34"><i class="fa fa-check"></i><b>25.9.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="25.10" data-path="statistical-inference.html"><a href="statistical-inference.html#election-forecasting"><i class="fa fa-check"></i><b>25.10</b> Case study: Election forecasting</a><ul>
<li class="chapter" data-level="25.10.1" data-path="statistical-inference.html"><a href="statistical-inference.html#bayesian-approach"><i class="fa fa-check"></i><b>25.10.1</b> Bayesian approach</a></li>
<li class="chapter" data-level="25.10.2" data-path="statistical-inference.html"><a href="statistical-inference.html#the-general-bias"><i class="fa fa-check"></i><b>25.10.2</b> The general bias</a></li>
<li class="chapter" data-level="25.10.3" data-path="statistical-inference.html"><a href="statistical-inference.html#mathematical-representations-of-models"><i class="fa fa-check"></i><b>25.10.3</b> Mathematical representations of models</a></li>
<li class="chapter" data-level="25.10.4" data-path="statistical-inference.html"><a href="statistical-inference.html#predicting-the-electoral-college"><i class="fa fa-check"></i><b>25.10.4</b> Predicting the electoral college</a></li>
<li class="chapter" data-level="25.10.5" data-path="statistical-inference.html"><a href="statistical-inference.html#forecasting"><i class="fa fa-check"></i><b>25.10.5</b> Forecasting</a></li>
<li class="chapter" data-level="25.10.6" data-path="statistical-inference.html"><a href="statistical-inference.html#exercise-1"><i class="fa fa-check"></i><b>25.10.6</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="25.11" data-path="statistical-inference.html"><a href="statistical-inference.html#t-dist"><i class="fa fa-check"></i><b>25.11</b> The t-distribution</a></li>
<li class="chapter" data-level="25.12" data-path="statistical-inference.html"><a href="statistical-inference.html#association-tests"><i class="fa fa-check"></i><b>25.12</b> Association Tests</a><ul>
<li class="chapter" data-level="25.12.1" data-path="statistical-inference.html"><a href="statistical-inference.html#lady-tasting-tea"><i class="fa fa-check"></i><b>25.12.1</b> Lady Tasting Tea</a></li>
<li class="chapter" data-level="25.12.2" data-path="statistical-inference.html"><a href="statistical-inference.html#two-by-two-tables"><i class="fa fa-check"></i><b>25.12.2</b> Two-by-two tables</a></li>
<li class="chapter" data-level="25.12.3" data-path="statistical-inference.html"><a href="statistical-inference.html#chi-square-test"><i class="fa fa-check"></i><b>25.12.3</b> Chi-square Test</a></li>
<li class="chapter" data-level="25.12.4" data-path="statistical-inference.html"><a href="statistical-inference.html#the-odds-ratio-odds-ratio"><i class="fa fa-check"></i><b>25.12.4</b> The Odds Ratio {odds-ratio}</a></li>
<li class="chapter" data-level="25.12.5" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-intervals-for-the-odds-ratio"><i class="fa fa-check"></i><b>25.12.5</b> Confidence intervals for the odds ratio</a></li>
<li class="chapter" data-level="25.12.6" data-path="statistical-inference.html"><a href="statistical-inference.html#small-count-correction"><i class="fa fa-check"></i><b>25.12.6</b> Small count correction</a></li>
<li class="chapter" data-level="25.12.7" data-path="statistical-inference.html"><a href="statistical-inference.html#large-samples-small-p-values"><i class="fa fa-check"></i><b>25.12.7</b> Large samples, small p-values</a></li>
<li class="chapter" data-level="25.12.8" data-path="statistical-inference.html"><a href="statistical-inference.html#exercises-35"><i class="fa fa-check"></i><b>25.12.8</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>26</b> Regression</a><ul>
<li class="chapter" data-level="26.1" data-path="regression.html"><a href="regression.html#case-study-is-height-hereditary"><i class="fa fa-check"></i><b>26.1</b> Case study: Is height hereditary?</a></li>
<li class="chapter" data-level="26.2" data-path="regression.html"><a href="regression.html#the-correlation-coefficient"><i class="fa fa-check"></i><b>26.2</b> The correlation coefficient</a><ul>
<li class="chapter" data-level="26.2.1" data-path="regression.html"><a href="regression.html#sample-correlation-is-a-random-variable"><i class="fa fa-check"></i><b>26.2.1</b> Sample correlation is a random variable</a></li>
<li class="chapter" data-level="26.2.2" data-path="regression.html"><a href="regression.html#correlation-is-not-always-a-useful-summary"><i class="fa fa-check"></i><b>26.2.2</b> Correlation is not always a useful summary</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="regression.html"><a href="regression.html#conditional-expectation"><i class="fa fa-check"></i><b>26.3</b> Conditional Expectations</a></li>
<li class="chapter" data-level="26.4" data-path="regression.html"><a href="regression.html#the-regression-line"><i class="fa fa-check"></i><b>26.4</b> The regression line</a><ul>
<li class="chapter" data-level="26.4.1" data-path="regression.html"><a href="regression.html#regression-improves-precision"><i class="fa fa-check"></i><b>26.4.1</b> Regression improves precision</a></li>
<li class="chapter" data-level="26.4.2" data-path="regression.html"><a href="regression.html#bivariate-normal-distribution-advanced"><i class="fa fa-check"></i><b>26.4.2</b> Bivariate normal distribution (advanced)</a></li>
<li class="chapter" data-level="26.4.3" data-path="regression.html"><a href="regression.html#variance-explained"><i class="fa fa-check"></i><b>26.4.3</b> Variance explained</a></li>
<li class="chapter" data-level="26.4.4" data-path="regression.html"><a href="regression.html#warning-there-are-two-regression-lines"><i class="fa fa-check"></i><b>26.4.4</b> Warning: there are two regression lines</a></li>
<li class="chapter" data-level="26.4.5" data-path="regression.html"><a href="regression.html#exercises-36"><i class="fa fa-check"></i><b>26.4.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="regression.html"><a href="regression.html#case-study-moneyball"><i class="fa fa-check"></i><b>26.5</b> Case Study: Moneyball</a><ul>
<li class="chapter" data-level="26.5.1" data-path="regression.html"><a href="regression.html#sabermetics"><i class="fa fa-check"></i><b>26.5.1</b> Sabermetics</a></li>
<li class="chapter" data-level="26.5.2" data-path="regression.html"><a href="regression.html#baseball-basics"><i class="fa fa-check"></i><b>26.5.2</b> Baseball basics</a></li>
</ul></li>
<li class="chapter" data-level="26.6" data-path="regression.html"><a href="regression.html#no-awards-for-bb"><i class="fa fa-check"></i><b>26.6</b> No awards for BB</a><ul>
<li class="chapter" data-level="26.6.1" data-path="regression.html"><a href="regression.html#base-on-ball-or-stolen-bases"><i class="fa fa-check"></i><b>26.6.1</b> Base on Ball or Stolen Bases?</a></li>
<li class="chapter" data-level="26.6.2" data-path="regression.html"><a href="regression.html#regression-applied-to-baseball-statistics"><i class="fa fa-check"></i><b>26.6.2</b> Regression applied to baseball statistics</a></li>
</ul></li>
<li class="chapter" data-level="26.7" data-path="regression.html"><a href="regression.html#confounding"><i class="fa fa-check"></i><b>26.7</b> Confounding</a><ul>
<li class="chapter" data-level="26.7.1" data-path="regression.html"><a href="regression.html#understanding-confounding-through-stratification"><i class="fa fa-check"></i><b>26.7.1</b> Understanding confounding through stratification</a></li>
<li class="chapter" data-level="26.7.2" data-path="regression.html"><a href="regression.html#multivariate-regression"><i class="fa fa-check"></i><b>26.7.2</b> Multivariate regression</a></li>
</ul></li>
<li class="chapter" data-level="26.8" data-path="regression.html"><a href="regression.html#lse"><i class="fa fa-check"></i><b>26.8</b> Linear Models and Least Squared Estimates</a><ul>
<li class="chapter" data-level="26.8.1" data-path="regression.html"><a href="regression.html#interpreting-linear-models"><i class="fa fa-check"></i><b>26.8.1</b> Interpreting linear models</a></li>
<li class="chapter" data-level="26.8.2" data-path="regression.html"><a href="regression.html#least-squares-estimates-lse"><i class="fa fa-check"></i><b>26.8.2</b> Least Squares Estimates (LSE)</a></li>
<li class="chapter" data-level="26.8.3" data-path="regression.html"><a href="regression.html#the-lm-function"><i class="fa fa-check"></i><b>26.8.3</b> The <code>lm</code> function</a></li>
<li class="chapter" data-level="26.8.4" data-path="regression.html"><a href="regression.html#lse-are-random-variables"><i class="fa fa-check"></i><b>26.8.4</b> LSE are random variables</a></li>
<li class="chapter" data-level="26.8.5" data-path="regression.html"><a href="regression.html#predicted-values-are-random-variables"><i class="fa fa-check"></i><b>26.8.5</b> Predicted values are random variables</a></li>
<li class="chapter" data-level="26.8.6" data-path="regression.html"><a href="regression.html#exercises-37"><i class="fa fa-check"></i><b>26.8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="26.9" data-path="regression.html"><a href="regression.html#linear-regression-in-the-tidyverse"><i class="fa fa-check"></i><b>26.9</b> Linear regression in the tidyverse</a><ul>
<li class="chapter" data-level="26.9.1" data-path="regression.html"><a href="regression.html#the-broom-package"><i class="fa fa-check"></i><b>26.9.1</b> The broom package</a></li>
<li class="chapter" data-level="26.9.2" data-path="regression.html"><a href="regression.html#exercises-38"><i class="fa fa-check"></i><b>26.9.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="26.10" data-path="regression.html"><a href="regression.html#case-study-moneyball-continued"><i class="fa fa-check"></i><b>26.10</b> Case study: Moneyball continued</a><ul>
<li class="chapter" data-level="26.10.1" data-path="regression.html"><a href="regression.html#adding-salary-and-position-information"><i class="fa fa-check"></i><b>26.10.1</b> Adding salary and position information</a></li>
<li class="chapter" data-level="26.10.2" data-path="regression.html"><a href="regression.html#picking-9-players"><i class="fa fa-check"></i><b>26.10.2</b> Picking 9 players</a></li>
<li class="chapter" data-level="26.10.3" data-path="regression.html"><a href="regression.html#exercises-39"><i class="fa fa-check"></i><b>26.10.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="26.11" data-path="regression.html"><a href="regression.html#regression-fallacy"><i class="fa fa-check"></i><b>26.11</b> Regression fallacy</a></li>
<li class="chapter" data-level="26.12" data-path="regression.html"><a href="regression.html#measurement-error-models"><i class="fa fa-check"></i><b>26.12</b> Measurement error models</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html"><i class="fa fa-check"></i><b>27</b> Association is not causation</a><ul>
<li class="chapter" data-level="27.1" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#spurious-correlation"><i class="fa fa-check"></i><b>27.1</b> Spurious correlation</a></li>
<li class="chapter" data-level="27.2" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#outliers-1"><i class="fa fa-check"></i><b>27.2</b> Outliers</a></li>
<li class="chapter" data-level="27.3" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#reversing-cause-and-effect"><i class="fa fa-check"></i><b>27.3</b> Reversing cause and effect</a></li>
<li class="chapter" data-level="27.4" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#confounders"><i class="fa fa-check"></i><b>27.4</b> Confounders</a><ul>
<li class="chapter" data-level="27.4.1" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#example-uc-berkeley-admissions"><i class="fa fa-check"></i><b>27.4.1</b> Example: UC Berkeley admissions</a></li>
<li class="chapter" data-level="27.4.2" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#confounding-explained-graphically"><i class="fa fa-check"></i><b>27.4.2</b> Confounding explained graphically</a></li>
<li class="chapter" data-level="27.4.3" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#average-after-stratifying"><i class="fa fa-check"></i><b>27.4.3</b> Average after stratifying</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#simpsons-paradox"><i class="fa fa-check"></i><b>27.5</b> Simpson’s Paradox</a></li>
<li class="chapter" data-level="27.6" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#exercises-40"><i class="fa fa-check"></i><b>27.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Machine Learning</b></span></li>
<li class="chapter" data-level="28" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html"><i class="fa fa-check"></i><b>28</b> Introduction to Machine Learning</a><ul>
<li class="chapter" data-level="28.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#notation-1"><i class="fa fa-check"></i><b>28.1</b> Notation</a></li>
<li class="chapter" data-level="28.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#an-example"><i class="fa fa-check"></i><b>28.2</b> An example</a><ul>
<li class="chapter" data-level="28.2.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-41"><i class="fa fa-check"></i><b>28.2.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#evaluation-metrics"><i class="fa fa-check"></i><b>28.3</b> Evaluation Metrics</a><ul>
<li class="chapter" data-level="28.3.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#training-and-test-sets"><i class="fa fa-check"></i><b>28.3.1</b> Training and test sets</a></li>
<li class="chapter" data-level="28.3.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#overall-accuracy"><i class="fa fa-check"></i><b>28.3.2</b> Overall accuracy</a></li>
<li class="chapter" data-level="28.3.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#the-confusion-matrix"><i class="fa fa-check"></i><b>28.3.3</b> The confusion matrix</a></li>
<li class="chapter" data-level="28.3.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>28.3.4</b> Sensitivity and specificity</a></li>
<li class="chapter" data-level="28.3.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#balanced-accuracy-and-f_1-score"><i class="fa fa-check"></i><b>28.3.5</b> Balanced accuracy and <span class="math inline">\(F_1\)</span> score</a></li>
<li class="chapter" data-level="28.3.6" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#prevalence-matters-in-practice"><i class="fa fa-check"></i><b>28.3.6</b> Prevalence matters in practice</a></li>
<li class="chapter" data-level="28.3.7" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#roc-and-precision-recall-curves"><i class="fa fa-check"></i><b>28.3.7</b> ROC and precision-recall curves</a></li>
<li class="chapter" data-level="28.3.8" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-42"><i class="fa fa-check"></i><b>28.3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-probabilities-and-expectations"><i class="fa fa-check"></i><b>28.4</b> Conditional probabilities and expectations</a><ul>
<li class="chapter" data-level="28.4.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-probabilities-1"><i class="fa fa-check"></i><b>28.4.1</b> Conditional probabilities</a></li>
<li class="chapter" data-level="28.4.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-expectations"><i class="fa fa-check"></i><b>28.4.2</b> Conditional expectations</a></li>
<li class="chapter" data-level="28.4.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#the-loss-function"><i class="fa fa-check"></i><b>28.4.3</b> The loss function</a></li>
<li class="chapter" data-level="28.4.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-expectation-minimizes-squared-loss-function"><i class="fa fa-check"></i><b>28.4.4</b> Conditional expectation minimizes squared loss function</a></li>
<li class="chapter" data-level="28.4.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-43"><i class="fa fa-check"></i><b>28.4.5</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="case-study-is-it-a-2-or-a-7.html"><a href="case-study-is-it-a-2-or-a-7.html"><i class="fa fa-check"></i><b>29</b> Case study: is it a 2 or a 7?</a></li>
<li class="chapter" data-level="30" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>30</b> Smoothing</a><ul>
<li class="chapter" data-level="30.1" data-path="smoothing.html"><a href="smoothing.html#bin-smoothing"><i class="fa fa-check"></i><b>30.1</b> Bin smoothing</a></li>
<li class="chapter" data-level="30.2" data-path="smoothing.html"><a href="smoothing.html#kernels"><i class="fa fa-check"></i><b>30.2</b> Kernels</a></li>
<li class="chapter" data-level="30.3" data-path="smoothing.html"><a href="smoothing.html#local-weighted-regression-loess"><i class="fa fa-check"></i><b>30.3</b> Local weighted regression (loess)</a></li>
<li class="chapter" data-level="30.4" data-path="smoothing.html"><a href="smoothing.html#fitting-parabolas"><i class="fa fa-check"></i><b>30.4</b> Fitting parabolas</a></li>
<li class="chapter" data-level="30.5" data-path="smoothing.html"><a href="smoothing.html#beware-of-ggplot-defaults"><i class="fa fa-check"></i><b>30.5</b> Beware of <code>ggplot</code> defaults</a></li>
<li class="chapter" data-level="30.6" data-path="smoothing.html"><a href="smoothing.html#exercises-44"><i class="fa fa-check"></i><b>30.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html"><i class="fa fa-check"></i><b>31</b> Examples of algorithms</a><ul>
<li class="chapter" data-level="31.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#linear-regression"><i class="fa fa-check"></i><b>31.1</b> Linear regression</a><ul>
<li class="chapter" data-level="31.1.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#the-predict-function"><i class="fa fa-check"></i><b>31.1.1</b> The <code>predict</code> function</a></li>
<li class="chapter" data-level="31.1.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-45"><i class="fa fa-check"></i><b>31.1.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#logistic-regression"><i class="fa fa-check"></i><b>31.2</b> Logistic regression</a><ul>
<li class="chapter" data-level="31.2.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#generalized-linear-models"><i class="fa fa-check"></i><b>31.2.1</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="31.2.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-46"><i class="fa fa-check"></i><b>31.2.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="31.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>31.3</b> K-nearest neighbors</a><ul>
<li class="chapter" data-level="31.3.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#over-training"><i class="fa fa-check"></i><b>31.3.1</b> Over training</a></li>
<li class="chapter" data-level="31.3.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#over-smoothing"><i class="fa fa-check"></i><b>31.3.2</b> Over-smoothing</a></li>
<li class="chapter" data-level="31.3.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#picking-the-k-in-knn"><i class="fa fa-check"></i><b>31.3.3</b> Picking the <span class="math inline">\(k\)</span> in kNN</a></li>
<li class="chapter" data-level="31.3.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-47"><i class="fa fa-check"></i><b>31.3.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="31.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#generative-models"><i class="fa fa-check"></i><b>31.4</b> Generative models</a><ul>
<li class="chapter" data-level="31.4.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#naive-bayes"><i class="fa fa-check"></i><b>31.4.1</b> Naive Bayes</a></li>
<li class="chapter" data-level="31.4.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#controlling-prevalence"><i class="fa fa-check"></i><b>31.4.2</b> Controlling prevalence</a></li>
<li class="chapter" data-level="31.4.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>31.4.3</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="31.4.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>31.4.4</b> Linear discriminant analysis</a></li>
<li class="chapter" data-level="31.4.5" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#connection-to-distance"><i class="fa fa-check"></i><b>31.4.5</b> Connection to distance</a></li>
<li class="chapter" data-level="31.4.6" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#case-study-more-than-three-classes"><i class="fa fa-check"></i><b>31.4.6</b> Case study: more than three classes</a></li>
<li class="chapter" data-level="31.4.7" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-48"><i class="fa fa-check"></i><b>31.4.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>31.5</b> Classification and Regression Trees (CART)</a><ul>
<li class="chapter" data-level="31.5.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#the-curse-of-dimensionality"><i class="fa fa-check"></i><b>31.5.1</b> The curse of dimensionality</a></li>
<li class="chapter" data-level="31.5.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#cart-motivation"><i class="fa fa-check"></i><b>31.5.2</b> CART motivation</a></li>
<li class="chapter" data-level="31.5.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#regression-trees"><i class="fa fa-check"></i><b>31.5.3</b> Regression trees</a></li>
<li class="chapter" data-level="31.5.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#classification-decision-trees"><i class="fa fa-check"></i><b>31.5.4</b> Classification (decision) trees</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#random-forests"><i class="fa fa-check"></i><b>31.6</b> Random Forests</a><ul>
<li class="chapter" data-level="31.6.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-49"><i class="fa fa-check"></i><b>31.6.1</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="32" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>32</b> Cross validation</a><ul>
<li class="chapter" data-level="32.1" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>32.1</b> K-fold cross validation</a></li>
<li class="chapter" data-level="32.2" data-path="cross-validation.html"><a href="cross-validation.html#exercises-50"><i class="fa fa-check"></i><b>32.2</b> Exercises</a></li>
<li class="chapter" data-level="32.3" data-path="cross-validation.html"><a href="cross-validation.html#bootstrap"><i class="fa fa-check"></i><b>32.3</b> Bootstrap</a></li>
<li class="chapter" data-level="32.4" data-path="cross-validation.html"><a href="cross-validation.html#exercises-51"><i class="fa fa-check"></i><b>32.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>33</b> The caret package</a><ul>
<li class="chapter" data-level="33.1" data-path="caret.html"><a href="caret.html#the-caret-train-functon"><i class="fa fa-check"></i><b>33.1</b> The caret <code>train</code> functon</a></li>
<li class="chapter" data-level="33.2" data-path="cross-validation.html"><a href="cross-validation.html#cross-validation"><i class="fa fa-check"></i><b>33.2</b> Cross validation</a></li>
<li class="chapter" data-level="33.3" data-path="caret.html"><a href="caret.html#example-fitting-with-loess"><i class="fa fa-check"></i><b>33.3</b> Example: fitting with loess</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html"><i class="fa fa-check"></i><b>34</b> Machine Learning in practice</a><ul>
<li class="chapter" data-level="34.1" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#preprocessing"><i class="fa fa-check"></i><b>34.1</b> Preprocessing</a></li>
<li class="chapter" data-level="34.2" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>34.2</b> k-Nearest Neighbor</a></li>
<li class="chapter" data-level="34.3" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#variable-importance"><i class="fa fa-check"></i><b>34.3</b> Variable importance</a></li>
<li class="chapter" data-level="34.4" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#visual-assessments"><i class="fa fa-check"></i><b>34.4</b> Visual assessments</a></li>
<li class="chapter" data-level="34.5" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#ensembles"><i class="fa fa-check"></i><b>34.5</b> Ensembles</a></li>
<li class="chapter" data-level="34.6" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#exercises-52"><i class="fa fa-check"></i><b>34.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="large-datasets.html"><a href="large-datasets.html"><i class="fa fa-check"></i><b>35</b> Large datasets</a><ul>
<li class="chapter" data-level="35.1" data-path="large-datasets.html"><a href="large-datasets.html#matrix-algebra"><i class="fa fa-check"></i><b>35.1</b> Matrix algebra</a><ul>
<li class="chapter" data-level="35.1.1" data-path="large-datasets.html"><a href="large-datasets.html#notation-2"><i class="fa fa-check"></i><b>35.1.1</b> Notation</a></li>
<li class="chapter" data-level="35.1.2" data-path="large-datasets.html"><a href="large-datasets.html#converting-a-vector-to-a-matrix"><i class="fa fa-check"></i><b>35.1.2</b> Converting a vector to a matrix</a></li>
<li class="chapter" data-level="35.1.3" data-path="large-datasets.html"><a href="large-datasets.html#row-and-column-summaries"><i class="fa fa-check"></i><b>35.1.3</b> Row and column summaries</a></li>
<li class="chapter" data-level="35.1.4" data-path="large-datasets.html"><a href="large-datasets.html#apply"><i class="fa fa-check"></i><b>35.1.4</b> <code>apply</code></a></li>
<li class="chapter" data-level="35.1.5" data-path="large-datasets.html"><a href="large-datasets.html#filtering-columns-based-on-summaries"><i class="fa fa-check"></i><b>35.1.5</b> Filtering columns based on summaries</a></li>
<li class="chapter" data-level="35.1.6" data-path="large-datasets.html"><a href="large-datasets.html#indexing-with-matrices"><i class="fa fa-check"></i><b>35.1.6</b> Indexing with matrices</a></li>
<li class="chapter" data-level="35.1.7" data-path="large-datasets.html"><a href="large-datasets.html#binarizing-the-data"><i class="fa fa-check"></i><b>35.1.7</b> Binarizing the data</a></li>
<li class="chapter" data-level="35.1.8" data-path="large-datasets.html"><a href="large-datasets.html#vectorization-for-matrices"><i class="fa fa-check"></i><b>35.1.8</b> Vectorization for matrices</a></li>
<li class="chapter" data-level="35.1.9" data-path="large-datasets.html"><a href="large-datasets.html#matrix-algebra-operations"><i class="fa fa-check"></i><b>35.1.9</b> Matrix algebra operations</a></li>
<li class="chapter" data-level="35.1.10" data-path="large-datasets.html"><a href="large-datasets.html#exercises-53"><i class="fa fa-check"></i><b>35.1.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="35.2" data-path="large-datasets.html"><a href="large-datasets.html#distance"><i class="fa fa-check"></i><b>35.2</b> Distance</a><ul>
<li class="chapter" data-level="35.2.1" data-path="large-datasets.html"><a href="large-datasets.html#euclidean-distance"><i class="fa fa-check"></i><b>35.2.1</b> Euclidean distance</a></li>
<li class="chapter" data-level="35.2.2" data-path="large-datasets.html"><a href="large-datasets.html#distance-in-higher-dimensions"><i class="fa fa-check"></i><b>35.2.2</b> Distance in higher dimensions</a></li>
<li class="chapter" data-level="35.2.3" data-path="large-datasets.html"><a href="large-datasets.html#example"><i class="fa fa-check"></i><b>35.2.3</b> Example</a></li>
<li class="chapter" data-level="35.2.4" data-path="large-datasets.html"><a href="large-datasets.html#predictor-space"><i class="fa fa-check"></i><b>35.2.4</b> Predictor Space</a></li>
<li class="chapter" data-level="35.2.5" data-path="large-datasets.html"><a href="large-datasets.html#distance-between-predictors"><i class="fa fa-check"></i><b>35.2.5</b> Distance between predictors</a></li>
<li class="chapter" data-level="35.2.6" data-path="large-datasets.html"><a href="large-datasets.html#exercises-54"><i class="fa fa-check"></i><b>35.2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="35.3" data-path="large-datasets.html"><a href="large-datasets.html#dimension-reduction"><i class="fa fa-check"></i><b>35.3</b> Dimension Reduction</a><ul>
<li class="chapter" data-level="35.3.1" data-path="large-datasets.html"><a href="large-datasets.html#preserving-distance"><i class="fa fa-check"></i><b>35.3.1</b> Preserving distance</a></li>
<li class="chapter" data-level="35.3.2" data-path="large-datasets.html"><a href="large-datasets.html#linear-transformations-advnced"><i class="fa fa-check"></i><b>35.3.2</b> Linear transformations (advnced)</a></li>
<li class="chapter" data-level="35.3.3" data-path="large-datasets.html"><a href="large-datasets.html#orthogogal-transformations-advaced"><i class="fa fa-check"></i><b>35.3.3</b> Orthogogal transformations (advaced)</a></li>
<li class="chapter" data-level="35.3.4" data-path="large-datasets.html"><a href="large-datasets.html#principal-component-analysis"><i class="fa fa-check"></i><b>35.3.4</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="35.3.5" data-path="large-datasets.html"><a href="large-datasets.html#iris-example"><i class="fa fa-check"></i><b>35.3.5</b> Iris Example</a></li>
<li class="chapter" data-level="35.3.6" data-path="large-datasets.html"><a href="large-datasets.html#mnist-example"><i class="fa fa-check"></i><b>35.3.6</b> MNIST Example</a></li>
<li class="chapter" data-level="35.3.7" data-path="large-datasets.html"><a href="large-datasets.html#exercises-55"><i class="fa fa-check"></i><b>35.3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="35.4" data-path="large-datasets.html"><a href="large-datasets.html#recommendation-systems"><i class="fa fa-check"></i><b>35.4</b> Recommendation systems</a><ul>
<li class="chapter" data-level="35.4.1" data-path="large-datasets.html"><a href="large-datasets.html#movielens-data"><i class="fa fa-check"></i><b>35.4.1</b> Movielens data</a></li>
<li class="chapter" data-level="35.4.2" data-path="large-datasets.html"><a href="large-datasets.html#recommendation-systems-as-a-machine-learning-challenge"><i class="fa fa-check"></i><b>35.4.2</b> Recommendation systems as a machine learning challenge</a></li>
<li class="chapter" data-level="35.4.3" data-path="large-datasets.html"><a href="large-datasets.html#loss-function"><i class="fa fa-check"></i><b>35.4.3</b> Loss function</a></li>
<li class="chapter" data-level="35.4.4" data-path="large-datasets.html"><a href="large-datasets.html#a-first-model"><i class="fa fa-check"></i><b>35.4.4</b> A first model</a></li>
<li class="chapter" data-level="35.4.5" data-path="large-datasets.html"><a href="large-datasets.html#modeling-movie-effects"><i class="fa fa-check"></i><b>35.4.5</b> Modeling movie effects</a></li>
<li class="chapter" data-level="35.4.6" data-path="large-datasets.html"><a href="large-datasets.html#user-effects"><i class="fa fa-check"></i><b>35.4.6</b> User effects</a></li>
<li class="chapter" data-level="35.4.7" data-path="large-datasets.html"><a href="large-datasets.html#exercises-56"><i class="fa fa-check"></i><b>35.4.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="35.5" data-path="large-datasets.html"><a href="large-datasets.html#regularization"><i class="fa fa-check"></i><b>35.5</b> Regularization</a><ul>
<li class="chapter" data-level="35.5.1" data-path="large-datasets.html"><a href="large-datasets.html#motivation"><i class="fa fa-check"></i><b>35.5.1</b> Motivation</a></li>
<li class="chapter" data-level="35.5.2" data-path="large-datasets.html"><a href="large-datasets.html#penalized-least-squares"><i class="fa fa-check"></i><b>35.5.2</b> Penalized Least Squares</a></li>
<li class="chapter" data-level="35.5.3" data-path="large-datasets.html"><a href="large-datasets.html#choosing-the-penalty-terms"><i class="fa fa-check"></i><b>35.5.3</b> Choosing the penalty terms</a></li>
<li class="chapter" data-level="35.5.4" data-path="large-datasets.html"><a href="large-datasets.html#exercises-57"><i class="fa fa-check"></i><b>35.5.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="35.6" data-path="large-datasets.html"><a href="large-datasets.html#matrix-factorization"><i class="fa fa-check"></i><b>35.6</b> Matrix factorization</a><ul>
<li class="chapter" data-level="35.6.1" data-path="r-basics.html"><a href="r-basics.html#factors"><i class="fa fa-check"></i><b>35.6.1</b> Factors</a></li>
<li class="chapter" data-level="35.6.2" data-path="large-datasets.html"><a href="large-datasets.html#connection-to-svd-and-pca"><i class="fa fa-check"></i><b>35.6.2</b> Connection to SVD and PCA</a></li>
<li class="chapter" data-level="35.6.3" data-path="large-datasets.html"><a href="large-datasets.html#exercises-58"><i class="fa fa-check"></i><b>35.6.3</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="36" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>36</b> Clustering</a><ul>
<li class="chapter" data-level="36.1" data-path="clustering.html"><a href="clustering.html#hierarchical-clustering"><i class="fa fa-check"></i><b>36.1</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="36.2" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>36.2</b> k-means</a></li>
<li class="chapter" data-level="36.3" data-path="clustering.html"><a href="clustering.html#heatmaps"><i class="fa fa-check"></i><b>36.3</b> Heatmaps</a></li>
<li class="chapter" data-level="36.4" data-path="clustering.html"><a href="clustering.html#filtering-features"><i class="fa fa-check"></i><b>36.4</b> Filtering features</a></li>
<li class="chapter" data-level="36.5" data-path="clustering.html"><a href="clustering.html#exercises-59"><i class="fa fa-check"></i><b>36.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Productivity tools</b></span></li>
<li class="chapter" data-level="37" data-path="introduction-to-productivity-tools.html"><a href="introduction-to-productivity-tools.html"><i class="fa fa-check"></i><b>37</b> Introduction to productivity tools</a></li>
<li class="chapter" data-level="38" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>38</b> GitHub</a><ul>
<li class="chapter" data-level="38.1" data-path="github.html"><a href="github.html#installing-git"><i class="fa fa-check"></i><b>38.1</b> Installing Git</a><ul>
<li class="chapter" data-level="38.1.1" data-path="github.html"><a href="github.html#installing-git-and-git-bash-on-windows"><i class="fa fa-check"></i><b>38.1.1</b> Installing Git and Git Bash on Windows</a></li>
<li class="chapter" data-level="38.1.2" data-path="github.html"><a href="github.html#installing-git-on-the-mac"><i class="fa fa-check"></i><b>38.1.2</b> Installing Git on the Mac</a></li>
</ul></li>
<li class="chapter" data-level="38.2" data-path="github.html"><a href="github.html#github-accounts"><i class="fa fa-check"></i><b>38.2</b> GitHub Accounts</a></li>
<li class="chapter" data-level="38.3" data-path="github.html"><a href="github.html#github-repositories"><i class="fa fa-check"></i><b>38.3</b> GitHub repositories</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="getting-started.html"><a href="getting-started.html#rstudio"><i class="fa fa-check"></i><b>39</b> RStudio</a><ul>
<li class="chapter" data-level="39.1" data-path="rstudio.html"><a href="rstudio.html"><i class="fa fa-check"></i><b>39.1</b> The panes</a></li>
<li class="chapter" data-level="39.2" data-path="rstudio.html"><a href="rstudio.html#key-bindings-1"><i class="fa fa-check"></i><b>39.2</b> Key bindings</a></li>
<li class="chapter" data-level="39.3" data-path="rstudio.html"><a href="rstudio.html#installing-r-packages-1"><i class="fa fa-check"></i><b>39.3</b> Installing R packages</a></li>
<li class="chapter" data-level="39.4" data-path="rstudio.html"><a href="rstudio.html#running-commands-while-editing-scripts-1"><i class="fa fa-check"></i><b>39.4</b> Running commands while editing scripts</a></li>
<li class="chapter" data-level="39.5" data-path="rstudio.html"><a href="rstudio.html#global-options"><i class="fa fa-check"></i><b>39.5</b> Global options</a></li>
<li class="chapter" data-level="39.6" data-path="rstudio.html"><a href="rstudio.html#keeping-organized-with-rstudio-projects"><i class="fa fa-check"></i><b>39.6</b> Keeping organized with RStudio projects</a></li>
<li class="chapter" data-level="39.7" data-path="rstudio.html"><a href="rstudio.html#using-git-and-github-in-rstudio"><i class="fa fa-check"></i><b>39.7</b> Using Git and GitHub in RStudio</a></li>
<li class="chapter" data-level="39.8" data-path="rstudio.html"><a href="rstudio.html#running-r-without-rstudio"><i class="fa fa-check"></i><b>39.8</b> Running R without RStudio</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="unix.html"><a href="unix.html"><i class="fa fa-check"></i><b>40</b> Organizing with Unix</a><ul>
<li class="chapter" data-level="40.1" data-path="unix.html"><a href="unix.html#the-terminal"><i class="fa fa-check"></i><b>40.1</b> The terminal</a></li>
<li class="chapter" data-level="40.2" data-path="unix.html"><a href="unix.html#filesystem"><i class="fa fa-check"></i><b>40.2</b> The filesystem</a><ul>
<li class="chapter" data-level="40.2.1" data-path="unix.html"><a href="unix.html#directories-and-subdirectories"><i class="fa fa-check"></i><b>40.2.1</b> Directories and subdirectories</a></li>
<li class="chapter" data-level="40.2.2" data-path="unix.html"><a href="unix.html#the-home-directory"><i class="fa fa-check"></i><b>40.2.2</b> The home directory</a></li>
<li class="chapter" data-level="40.2.3" data-path="unix.html"><a href="unix.html#working-directory"><i class="fa fa-check"></i><b>40.2.3</b> Working directory</a></li>
<li class="chapter" data-level="40.2.4" data-path="unix.html"><a href="unix.html#paths"><i class="fa fa-check"></i><b>40.2.4</b> Paths</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="unix.html"><a href="unix.html#unix-commands"><i class="fa fa-check"></i><b>40.3</b> Unix commands</a><ul>
<li class="chapter" data-level="40.3.1" data-path="unix.html"><a href="unix.html#ls-listing-directory-content"><i class="fa fa-check"></i><b>40.3.1</b> <code>ls</code>: Listing directory content</a></li>
<li class="chapter" data-level="40.3.2" data-path="unix.html"><a href="unix.html#mkdir-and-rmdir-make-and-remove-a-directory"><i class="fa fa-check"></i><b>40.3.2</b> <code>mkdir</code> and <code>rmdir</code>: make and remove a directory</a></li>
<li class="chapter" data-level="40.3.3" data-path="unix.html"><a href="unix.html#cd-navigating-the-filesystem-by-changing-directories"><i class="fa fa-check"></i><b>40.3.3</b> <code>cd</code>: Navigating the filesystem by changing directories</a></li>
</ul></li>
<li class="chapter" data-level="40.4" data-path="unix.html"><a href="unix.html#some-examples"><i class="fa fa-check"></i><b>40.4</b> Some examples</a></li>
<li class="chapter" data-level="40.5" data-path="unix.html"><a href="unix.html#more-unix-commands"><i class="fa fa-check"></i><b>40.5</b> More Unix commands</a><ul>
<li class="chapter" data-level="40.5.1" data-path="unix.html"><a href="unix.html#mv-moving-files"><i class="fa fa-check"></i><b>40.5.1</b> <code>mv</code>: moving files</a></li>
<li class="chapter" data-level="40.5.2" data-path="unix.html"><a href="unix.html#cp-copying-files"><i class="fa fa-check"></i><b>40.5.2</b> <code>cp</code>: copying files</a></li>
<li class="chapter" data-level="40.5.3" data-path="unix.html"><a href="unix.html#rm-removing-files"><i class="fa fa-check"></i><b>40.5.3</b> <code>rm</code>: removing files</a></li>
<li class="chapter" data-level="40.5.4" data-path="unix.html"><a href="unix.html#less-looking-at-a-file"><i class="fa fa-check"></i><b>40.5.4</b> <code>less</code>: looking at a file</a></li>
</ul></li>
<li class="chapter" data-level="40.6" data-path="unix.html"><a href="unix.html#preparing-for-a-data-science-project"><i class="fa fa-check"></i><b>40.6</b> Preparing for a data science project</a></li>
<li class="chapter" data-level="40.7" data-path="unix.html"><a href="unix.html#advanced-unix"><i class="fa fa-check"></i><b>40.7</b> Advanced Unix</a><ul>
<li class="chapter" data-level="40.7.1" data-path="unix.html"><a href="unix.html#arguments"><i class="fa fa-check"></i><b>40.7.1</b> Arguments</a></li>
<li class="chapter" data-level="40.7.2" data-path="unix.html"><a href="unix.html#getting-help"><i class="fa fa-check"></i><b>40.7.2</b> Getting help</a></li>
<li class="chapter" data-level="40.7.3" data-path="unix.html"><a href="unix.html#pipes"><i class="fa fa-check"></i><b>40.7.3</b> Pipes</a></li>
<li class="chapter" data-level="40.7.4" data-path="unix.html"><a href="unix.html#wild-cards"><i class="fa fa-check"></i><b>40.7.4</b> Wild cards</a></li>
<li class="chapter" data-level="40.7.5" data-path="unix.html"><a href="unix.html#environment-variables"><i class="fa fa-check"></i><b>40.7.5</b> Environment variables</a></li>
<li class="chapter" data-level="40.7.6" data-path="unix.html"><a href="unix.html#shells"><i class="fa fa-check"></i><b>40.7.6</b> Shells</a></li>
<li class="chapter" data-level="40.7.7" data-path="unix.html"><a href="unix.html#executables"><i class="fa fa-check"></i><b>40.7.7</b> Executables</a></li>
<li class="chapter" data-level="40.7.8" data-path="unix.html"><a href="unix.html#permissions-and-file-types"><i class="fa fa-check"></i><b>40.7.8</b> Permissions and file types</a></li>
<li class="chapter" data-level="40.7.9" data-path="unix.html"><a href="unix.html#commands-you-should-learn"><i class="fa fa-check"></i><b>40.7.9</b> Commands you should learn</a></li>
<li class="chapter" data-level="40.7.10" data-path="unix.html"><a href="unix.html#file-manipulation-in-r"><i class="fa fa-check"></i><b>40.7.10</b> File manipulation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="41" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>41</b> Git</a><ul>
<li class="chapter" data-level="41.1" data-path="git.html"><a href="git.html#why-use-git-and-github"><i class="fa fa-check"></i><b>41.1</b> Why use Git and GitHub?</a></li>
<li class="chapter" data-level="41.2" data-path="git.html"><a href="git.html#overview-of-git"><i class="fa fa-check"></i><b>41.2</b> Overview of Git</a><ul>
<li class="chapter" data-level="41.2.1" data-path="git.html"><a href="git.html#clone"><i class="fa fa-check"></i><b>41.2.1</b> Clone</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="git.html"><a href="git.html#initilazing-a-git-directory"><i class="fa fa-check"></i><b>41.3</b> Initilazing a Git directory</a></li>
</ul></li>
<li class="chapter" data-level="42" data-path="reproducible-reports-with-r-markdown.html"><a href="reproducible-reports-with-r-markdown.html"><i class="fa fa-check"></i><b>42</b> Reproducible reports with R Markdown</a><ul>
<li class="chapter" data-level="42.1" data-path="reproducible-reports-with-r-markdown.html"><a href="reproducible-reports-with-r-markdown.html#r-markdown"><i class="fa fa-check"></i><b>42.1</b> R Markdown</a><ul>
<li class="chapter" data-level="42.1.1" data-path="reproducible-reports-with-r-markdown.html"><a href="reproducible-reports-with-r-markdown.html#the-header"><i class="fa fa-check"></i><b>42.1.1</b> The header</a></li>
<li class="chapter" data-level="42.1.2" data-path="reproducible-reports-with-r-markdown.html"><a href="reproducible-reports-with-r-markdown.html#r-code-chunks"><i class="fa fa-check"></i><b>42.1.2</b> R code chunks</a></li>
<li class="chapter" data-level="42.1.3" data-path="reproducible-reports-with-r-markdown.html"><a href="reproducible-reports-with-r-markdown.html#global-options-1"><i class="fa fa-check"></i><b>42.1.3</b> Global options</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="reproducible-reports-with-r-markdown.html"><a href="reproducible-reports-with-r-markdown.html#knitr"><i class="fa fa-check"></i><b>42.2</b> knitR</a></li>
<li class="chapter" data-level="42.3" data-path="reproducible-reports-with-r-markdown.html"><a href="reproducible-reports-with-r-markdown.html#more-on-r-markdown"><i class="fa fa-check"></i><b>42.3</b> More on R markdown</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability" class="section level1">
<h1><span class="header-section-number">Chapter 24</span> Probability</h1>
<p>Because knowing how to compute probabilities gives you an edge in games of chance, throughout history, many smart individuals, including famous mathematicians such as Cardano, Fermat and Pascal, spent time and energy thinking through the math of these games. As a result, Probability Theory was born. Probabilitycontinues to be highly useful in modern games of chance. For example, in poker, we can compute the probability of winning a hand based on the cards on the table. Also, casinos rely on probability theory to develop games that almost certainly guarantee a profit.</p>
<p>Probability theory is useful in many other contexts and, in particular, in areas that depend on data affected by chance in some way. Knowledge of probability is therefore indispensable for data science.</p>
<p>In games of chance, probability has a very intuitive definition. For instance, we know what it means that the chance of a pair of dice coming up seven is 1 in 6. However, this is not the case in other contexts. Today probability theory is being used much more broadly with the word <em>probability</em> commonly used in everyday language. Google’s auto-complete of “What are the chances of” give us: “having twins”, “rain today”, “getting struck by lightning”, and “getting cancer”.</p>
<p>One of the motivating examples for this chapter are the circumstances surrounding the <a href="https://en.wikipedia.org/wiki/Financial_crisis_of_2007%E2%80%9308">financial crisis of 2007-2008</a>. This financial crisis was in part caused by underestimating the risk of certain <a href="https://en.wikipedia.org/wiki/Security_(finance)">securities</a> sold by financial institutions. Specifically, the risk of mortgage-backed securities (MBS) and collateralized debt obligations (CDO) were grossly underestimated. These MBS and CDO were sold at prices that assumed most homeowners would make their monthly payments, and the probability of this not occurring was calculated as being low. A combination of factors resulted in many more defaults than were expected, which led to a price crash of these securities. As a consequence, banks lost so much money that they needed government bailouts to avoid closing down completely.</p>
<p>To begin to comprehend this very complicated event, we need to understand the basics of probability. We will introduce important concepts such as random variables, independence, Monte Carlo simulations, expected values, standard errors, and the Central Limit Theorem. Before using probability concepts to understand our motivating example, we will use several examples related to games of chance since these are simple and illustrative.</p>

<div id="discrete-probability" class="section level2">
<h2><span class="header-section-number">24.1</span> Discrete probability</h2>
<p>We start by covering some basic principles related to categorical data. The subset of probability is referred to as <em>discrete probability</em>. It will help us understand the probability theory we will later introduce for numeric and continuous data, which is much more common in data science applications. Discrete probability is more useful in card games and therefore we use these as examples.</p>
<div id="relative-frequency" class="section level3">
<h3><span class="header-section-number">24.1.1</span> Relative frequency</h3>
<p>The word probability is used in everyday language. Answering questions about probability is often hard, if not impossible. Here we discuss a mathematical definition of <em>probability</em> that does permit us to give precise answers to certain questions.</p>
<p>For example, if I have 2 red beads and 3 blue beads inside an <a href="https://en.wikipedia.org/wiki/Urn_problem">urn</a> (most probability books use this archaic term, so we do too) and I pick one at random, what is the probability of picking a red one? Our intuition tells us that the answer is 2/5 or 40%. A precise definition can be given by noting that there are five possible outcomes of which two satisfy the condition necessary for the event “pick a red bead”. Since each of the five outcomes has the same chance of occurring, we conclude that the probability is .4 for red and .6 for blue.</p>
<p>A more tangible way to think about the probability of an event is as the proportion of times the event occurs when we repeat the experiment over and over, independently, and under the same conditions.</p>
</div>
<div id="notation" class="section level3">
<h3><span class="header-section-number">24.1.2</span> Notation</h3>
<p>We use the notation <span class="math inline">\(\mbox{Pr}(A)\)</span> to denote the probability of event <span class="math inline">\(A\)</span> happening. We use the very general term <em>event</em> to refer to things that can happen when something occurs by chance. In our previous example, the event was “picking a red bead”. In a political poll in which we call 100 likely voters at random, an example of an event is “calling 48 Democrats and 52 Republicans”.</p>
<p>In data science applications, we will often deal with continuous variables. These events will often be things like “is this person taller than 6 feet”. In this case, we write events in a more mathematical form: <span class="math inline">\(X \geq 6\)</span>. We will see more of these examples later. Here we focus on categorical data.</p>
</div>
<div id="monte-carlo-simulations" class="section level3">
<h3><span class="header-section-number">24.1.3</span> Monte Carlo simulations</h3>
<p>Computers provide a way to actually perform the simple random experiment described above: pick a bead at random from a bag that contains three blue beads and two red ones. Random number generators permit us to mimic the process of picking at random.</p>
<p>An example is the <code>sample</code> function in R. We demonstrate its use in the code below. First, we use the function <code>rep</code> to generate the urn:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beads &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))
beads
<span class="co">#&gt; [1] &quot;red&quot;  &quot;red&quot;  &quot;blue&quot; &quot;blue&quot; &quot;blue&quot;</span></code></pre></div>
<p>and then use <code>sample</code> to pick a bead at random:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sample</span>(beads, <span class="dv">1</span>)
<span class="co">#&gt; [1] &quot;blue&quot;</span></code></pre></div>
<p>This line of code produces one random outcome. We want to repeat this experiment “over and over”, but it is impossible to repeat forever. Instead, we repeat the experiment a large enough number of times to make the results practically equivalent to repeating for ever. <strong>This is an example of a <em>Monte Carlo</em> simulation</strong>.</p>
<p>Much of what mathematical and theoretical statisticians study, which we do not cover in this book, relates to providing rigorous definitions of “practically equivalent” as well as studying how close a large number of experiments gets us to what happens in the limit. Later in this section, we provide a practical approach to deciding what is “large enough”.</p>
<p>To perform our first Monte Carlo simulation, we use the <code>replicate</code> function, which permits us to repeat the same task any number of times. Here, we repeat the random event <span class="math inline">\(B =\)</span> 10,000 times:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10000</span>
events &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">sample</span>(beads, <span class="dv">1</span>))</code></pre></div>
<p>We can now see if our definition actually is in agreement with this Monte Carlo simulation approximation. We can use <code>table</code> to see the distribution:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tab &lt;-<span class="st"> </span><span class="kw">table</span>(events)
tab
<span class="co">#&gt; events</span>
<span class="co">#&gt; blue  red </span>
<span class="co">#&gt; 6101 3899</span></code></pre></div>
<p>and <code>prop.table</code> gives us the proportions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prop.table</span>(tab)
<span class="co">#&gt; events</span>
<span class="co">#&gt; blue  red </span>
<span class="co">#&gt; 0.61 0.39</span></code></pre></div>
<p>The numbers above are the estimated probabilities provided by this Monte Carlo simulation. Statistical theory, not covered here, tells us that <span class="math inline">\(B\)</span> gets larger as the estimates get closer to 3/5=.6 and 2/5=.4.</p>
<p>Although this is a simple and not very useful example, we will use Monte Carlo simulations to estimate probabilities in cases in which it is harder to compute the exact ones. Before delving into more complex examples, we use simple ones to demonstrate the computing tools available in R.</p>
</div>
<div id="setting-the-random-seed" class="section level3">
<h3><span class="header-section-number">24.1.4</span> Setting the random seed</h3>
<p>Before we continue, we will briefly explain the following important line of code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1986</span>) </code></pre></div>
<p>Throughout this book, we use random number generators. This implies that many of the results presented can actually change by chance, which then suggests that a frozen version of the book may show a different result than what you obtain when you try to code as shown in the book. This is actually fine since the results are random and change from time to time. However, if you want to to ensure that results are exactly the same every time you run them, you can set R’s random number generation seed to a specific number. Above we set it to 1986. We want to avoid using the same seed everytime. A popular way to pick the seed is the year - month - day. For exmaple, we picked 1986 on December 20, 2018: <span class="math inline">\(2018 - 12 - 20 = 1986\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?set.seed</code></pre></div>
<p>In the exercises, we may ask you to set the seed to assure that the results you obtain are exactly what we expect them to be.</p>
</div>
<div id="with-and-without-replacement" class="section level3 unnumbered">
<h3>With and without replacement</h3>
<p>The function <code>sample</code> has an argument that permits us to pick more than one element from the urn. However, by default, this selection occurs <em>without replacement</em>: after a bead is selected, it is not put back in the bag. Notice what happens when we ask to randomly select five beads:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sample</span>(beads, <span class="dv">5</span>)
<span class="co">#&gt; [1] &quot;blue&quot; &quot;red&quot;  &quot;red&quot;  &quot;blue&quot; &quot;blue&quot;</span>
<span class="kw">sample</span>(beads, <span class="dv">5</span>)
<span class="co">#&gt; [1] &quot;blue&quot; &quot;red&quot;  &quot;blue&quot; &quot;red&quot;  &quot;blue&quot;</span>
<span class="kw">sample</span>(beads, <span class="dv">5</span>)
<span class="co">#&gt; [1] &quot;red&quot;  &quot;blue&quot; &quot;blue&quot; &quot;blue&quot; &quot;red&quot;</span></code></pre></div>
<p>This results in rearrangements that always have three blue and two red beads. If we ask that six beads be selected, we get an error:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sample</span>(beads, <span class="dv">6</span>)</code></pre></div>
<p><code>Error in sample.int(length(x), size, replace, prob) :    cannot take a sample larger than the population when 'replace = FALSE'</code></p>
<p>However, the <code>sample</code> function can be used directly, without the use of <code>replicate</code>, to repeat the same experiment of picking 1 out of the 5 beads, continually, under the same conditions. To do this, we sample <em>with replacement</em>: return the bead back to the urn after selecting it. We can tell <code>sample</code> to do this changing the <code>replace</code> argument, which defaults to <code>FALSE</code>, to <code>replace = TRUE</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">events &lt;-<span class="st"> </span><span class="kw">sample</span>(beads, B, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
<span class="kw">prop.table</span>(<span class="kw">table</span>(events))
<span class="co">#&gt; events</span>
<span class="co">#&gt;  blue   red </span>
<span class="co">#&gt; 0.600 0.401</span></code></pre></div>
<p>Not surprisingly, we get results very similar to those previously obtained with <code>replicate</code>.</p>
</div>
<div id="discrete-probability-distributions" class="section level3">
<h3><span class="header-section-number">24.1.5</span> Discrete probability distributions</h3>
<p>Defining a distribution for categorical outcomes is relatively straightforward. We simply assign a probability to each category. In cases that can be thought of as beads in an urn, for each bead type, their proportion defines the distribution.</p>
<p>If we are randomly calling likely voters from a population that is 44% Democrat, 44% Republican, 10% undecided and 2% Green Party, these proportions define the probability for each group. The probability distribution is:</p>
<p>$$ ()=0.44\</p>
<p>()=0.44\</p>
<p>()=0.10\</p>
<p>()=0.02 $$</p>
</div>
<div id="independence" class="section level3">
<h3><span class="header-section-number">24.1.6</span> Independence</h3>
<p>We say two events are independent if the outcome of one does not affect the other. The classic example are coin tosses. Every time we toss a fair coin, the probability of seeing heads is 1/2 regardless of what previous tosses have revealed. The same is true when we pick beads from an urn with replacement. In the example above, the probability of red is 0.40 regardless of previous draws.</p>
<p>Many examples of events that are not independent come from card games. When we deal the first card, the probability of getting a King is 1/13 since there are thirteen possibilities: Ace, Deuce, Three, <span class="math inline">\(\dots\)</span>, Ten, Jack, Queen, King, and Ace. Now if we deal a King for the first card, and don’t replace it into the deck, the probabilities of a second card being a King is less because there are only three Kings left: the probability is 3 out of 51. These events are therefore <strong>not independent</strong>: the first outcome affected the next one.</p>
<p>To see an extreme case of non-independent events, consider our example of drawing five beads at random <strong>without</strong> replacement:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">sample</span>(beads, <span class="dv">5</span>)</code></pre></div>
<p>If you have to guess the color of the first bead, you will predict blue since blue has a 60% chance. But if I show you the result of the last four outcomes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x[<span class="dv">2</span><span class="op">:</span><span class="dv">5</span>]
<span class="co">#&gt; [1] &quot;blue&quot; &quot;blue&quot; &quot;blue&quot; &quot;red&quot;</span></code></pre></div>
<p>would you still guess blue? Of course not. Now you know that the probability of red is 1 since the only beed left is red. The events are not independent so the probabilities change.</p>
</div>
<div id="conditional-probabilities" class="section level3">
<h3><span class="header-section-number">24.1.7</span> Conditional probabilities</h3>
<p>When events are not independent, <em>conditional probabilities</em> are useful. We already saw an example of a conditional probability: we computed the probability that a second dealt card is a King given that the first was a King. In probability, we use the following notation:</p>
<p><span class="math display">\[
\mbox{Pr}(\mbox{Card 2 is a king} \mid \mbox{Card 1 is a king}) = 3/51
\]</span></p>
<p>We use the <span class="math inline">\(\mid\)</span> as shorthand for “given that” or “conditional on”.</p>
<p>When two events, say <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, are independent, we have:</p>
<p><span class="math display">\[
\mbox{Pr}(A \mid B) = \mbox{Pr}(A) 
\]</span></p>
<p>This is the mathematical way of saying: the fact that <span class="math inline">\(B\)</span> happened does not affect the probability of <span class="math inline">\(A\)</span> happening. In fact, this can be considered the mathematical definition of independence.</p>
</div>
<div id="multiplication-rule" class="section level3">
<h3><span class="header-section-number">24.1.8</span> Multiplication rule</h3>
<p>If we want to know the probability of two events, say <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, occurring, we can use the multiplication rule:</p>
<p><span class="math display">\[ 
\mbox{Pr}(A \mbox{ and } B) = \mbox{Pr}(A)\mbox{Pr}(B \mid A)
\]</span> Let’s use Blackjack as an example. In Blackjack, you are assigned two random cards. After you see what you have, you can ask for more. The goal is to get closer to 21 than the dealer, without going over. Face cards are worth 10 points and Aces are worth 11 or 1 (you choose).</p>
<p>So, in a Blackjack game, to calculate the chances of getting a 21 by drawing an Ace and then a face card, we compute the probability of the first being an Ace and multiply by the probability of drawing a face card given that the first was an Ace: <span class="math inline">\(1/13 \times 12/52 \approx 0.02\)</span></p>
<p>The multiplicative rule also applies to more than two events. We can use induction to expand for more events:</p>
<p><span class="math display">\[ 
\mbox{Pr}(A \mbox{ and } B \mbox{ and } C) = \mbox{Pr}(A)\mbox{Pr}(B \mid A)\mbox{Pr}(C \mid A \mbox{ and } B)
\]</span></p>
</div>
<div id="multiplication-rule-under-indepedence" class="section level3">
<h3><span class="header-section-number">24.1.9</span> Multiplication rule under indepedence</h3>
<p>When we have independent events, then the multiplication rule becomes simpler:</p>
<p><span class="math display">\[ 
\mbox{Pr}(A \mbox{ and } B \mbox{ and } C) = \mbox{Pr}(A)\mbox{Pr}(B)\mbox{Pr}(C)
\]</span></p>
<p>But we have to be very careful before using this since assuming independence can result in very different and incorrect probability calculations when we don’t actually have independence.</p>
<p>As an example, imagine a court case in which the suspect was described as having a mustache and a beard. The defendant has a mustache and a beard and the prosecution brings in an “expert” to testify that 1/10 men have beards and 1/5 have mustaches so using the multiplication rule we conclude that only <span class="math inline">\(1/10 \times 1/5\)</span> or 0.02 have both.</p>
<p>But to multiply like this we need to assume independence! The conditional probability of a man having a mustache conditional on him having a beard is .95. So the correct calculation probability is much higher: <span class="math inline">\(1/10 \times 95/100 = 0.095\)</span>.</p>
<p>The multiplication rule also gives us a general formula for computing conditional probabilities:</p>
<p><span class="math display">\[ 
\mbox{Pr}(B \mid A) = \frac{\mbox{Pr}(A \mbox{ and } B)}{ \mbox{Pr}(A)}
\]</span></p>
<p>To illustrate how we use these formulas and concepts in practice, we will use several examples related to card games.</p>
</div>
<div id="addition-rule" class="section level3">
<h3><span class="header-section-number">24.1.10</span> Addition rule</h3>
<p>The addition rule tells us that:</p>
<p><span class="math display">\[
\mbox{Pr}(A \mbox{ or } B) = \mbox{Pr}(A) + \mbox{Pr}(B) - \mbox{Pr}(A \mbox{ and } B)
\]</span></p>
<p>This rule is intuitive: think of a Venn diagram. If we simply add the probabilities, we count the intersection twice so we need to substract one instance.</p>
<p><img src="book_files/figure-html/venn-diagram-addition-rule-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="combinations-and-permutations" class="section level3">
<h3><span class="header-section-number">24.1.11</span> Combinations and permutations</h3>
<p>In our very first example we imagined an urn with five beads. As a reminder, to compute the probability distribution of one draw, we simply listed out all the possibilities. There were 5 and so then, for each event, we counted how many of these possibilities were associated with the event. The resulting probability of choosing a blue bead is 3/5 because out of the five possible outcomes, three were blue.</p>
<p>For more complicated cases, the computations are not as straightforward. For instance, what is the probability that if I draw five cards without replacement, I get all cards of the same suit, what is known as a “flush” in Poker? In a Discrete Probability course you learn theory on how to make these computations. Here we focus on how to use R code to compute the answers.</p>
<p>First, let’s construct a deck of cards. For this, we will use the <code>expand.grid</code> and <code>paste</code> functions. We use <code>paste</code> to create strings by joining smaller strings. To do this, we take the number and suit of a card and create the card name like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">number &lt;-<span class="st"> &quot;Three&quot;</span>
suit &lt;-<span class="st"> &quot;Hearts&quot;</span>
<span class="kw">paste</span>(number, suit)
<span class="co">#&gt; [1] &quot;Three Hearts&quot;</span></code></pre></div>
<p><code>paste</code> also works on pairs of vectors performing the operation element-wise:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">paste</span>(letters[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>], <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>))
<span class="co">#&gt; [1] &quot;a 1&quot; &quot;b 2&quot; &quot;c 3&quot; &quot;d 4&quot; &quot;e 5&quot;</span></code></pre></div>
<p>The function <code>expand.grid</code> gives us all the combinations of entries of two vectors. For example, if you have blue and black pants and white, grey and plaid shirts, all your combinations are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">expand.grid</span>(<span class="dt">pants =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;black&quot;</span>), <span class="dt">shirt =</span> <span class="kw">c</span>(<span class="st">&quot;white&quot;</span>, <span class="st">&quot;grey&quot;</span>, <span class="st">&quot;plaid&quot;</span>))
<span class="co">#&gt;   pants shirt</span>
<span class="co">#&gt; 1  blue white</span>
<span class="co">#&gt; 2 black white</span>
<span class="co">#&gt; 3  blue  grey</span>
<span class="co">#&gt; 4 black  grey</span>
<span class="co">#&gt; 5  blue plaid</span>
<span class="co">#&gt; 6 black plaid</span></code></pre></div>
<p>Here is how we generate a deck of cards:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">suits &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Diamonds&quot;</span>, <span class="st">&quot;Clubs&quot;</span>, <span class="st">&quot;Hearts&quot;</span>, <span class="st">&quot;Spades&quot;</span>)
numbers &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Ace&quot;</span>, <span class="st">&quot;Deuce&quot;</span>, <span class="st">&quot;Three&quot;</span>, <span class="st">&quot;Four&quot;</span>, <span class="st">&quot;Five&quot;</span>, 
             <span class="st">&quot;Six&quot;</span>, <span class="st">&quot;Seven&quot;</span>, <span class="st">&quot;Eight&quot;</span>, <span class="st">&quot;Nine&quot;</span>, <span class="st">&quot;Ten&quot;</span>, 
             <span class="st">&quot;Jack&quot;</span>, <span class="st">&quot;Queen&quot;</span>, <span class="st">&quot;King&quot;</span>)
deck &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">number=</span>numbers, <span class="dt">suit=</span>suits)
deck &lt;-<span class="st"> </span><span class="kw">paste</span>(deck<span class="op">$</span>number, deck<span class="op">$</span>suit)</code></pre></div>
<p>With the deck constructed, we can now double check that the probability of a King in the first card is 1/13. We simply compute the proportion of possible outcomes that satisfy our condition:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kings &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;King&quot;</span>, suits)
<span class="kw">mean</span>(deck <span class="op">%in%</span><span class="st"> </span>kings)
<span class="co">#&gt; [1] 0.0769</span></code></pre></div>
<p>which is 1/13.</p>
<p>Now, how about the conditional probability of the second card being a King given that the first was a King? Earlier, we deduced that if one King is already out of the deck and there are 51 left, then this probability is 3/51. Let’s confirm by listing out all possible outcomes.</p>
<p>To do this, we can use the <code>permutations</code> function from the <strong>gtools</strong> package. For any list of size <code>n</code>, this function computes all the different combinations we can get when we select <code>r</code> items. Here are all the ways we can choose two numbers from a list consisting of <code>1,2,3</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gtools)
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;gtools&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:futile.logger&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     scat</span>
<span class="kw">permutations</span>(<span class="dv">3</span>, <span class="dv">2</span>)
<span class="co">#&gt;      [,1] [,2]</span>
<span class="co">#&gt; [1,]    1    2</span>
<span class="co">#&gt; [2,]    1    3</span>
<span class="co">#&gt; [3,]    2    1</span>
<span class="co">#&gt; [4,]    2    3</span>
<span class="co">#&gt; [5,]    3    1</span>
<span class="co">#&gt; [6,]    3    2</span></code></pre></div>
<p>Notice that the order matters here: 3,1 is different than 1,3. Also, note that (1,1), (2,2) and (3,3) do not appear because once we pick a number, it can’t appear again.</p>
<p>Optionally, we can add a vector. If you want to see five random seven digit phone numbers out of all possible phone numbers, you can type:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_phone_numbers &lt;-<span class="st"> </span><span class="kw">permutations</span>(<span class="dv">10</span>, <span class="dv">7</span>, <span class="dt">v =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">9</span>)
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(all_phone_numbers)
index &lt;-<span class="st"> </span><span class="kw">sample</span>(n, <span class="dv">5</span>)
all_phone_numbers[index,]
<span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7]</span>
<span class="co">#&gt; [1,]    8    9    6    5    7    1    3</span>
<span class="co">#&gt; [2,]    9    4    0    2    1    8    6</span>
<span class="co">#&gt; [3,]    6    5    3    8    2    4    1</span>
<span class="co">#&gt; [4,]    6    2    5    9    7    1    4</span>
<span class="co">#&gt; [5,]    0    6    5    4    3    7    1</span></code></pre></div>
<p>Instead of using the numbers 1 through 10, the default, it uses what we provided through <code>v</code>: the digits 0 through 9.</p>
<p>To compute all possible ways we can choose two cards when the order matters, we type:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hands &lt;-<span class="st"> </span><span class="kw">permutations</span>(<span class="dv">52</span>, <span class="dv">2</span>, <span class="dt">v =</span> deck)</code></pre></div>
<p>This is a matrix with two columns and 2652 rows. With a matrix we can get the first and second cards like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">first_card &lt;-<span class="st"> </span>hands[,<span class="dv">1</span>]
second_card &lt;-<span class="st"> </span>hands[,<span class="dv">2</span>]</code></pre></div>
<p>Now the cases for which the first hand was a King can be computed like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kings &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;King&quot;</span>, suits)
<span class="kw">sum</span>(first_card <span class="op">%in%</span><span class="st"> </span>kings)
<span class="co">#&gt; [1] 204</span></code></pre></div>
<p>To get the conditional probability, we compute what fraction of these have a King in the second card:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(first_card <span class="op">%in%</span><span class="st"> </span>kings <span class="op">&amp;</span><span class="st"> </span>second_card <span class="op">%in%</span><span class="st"> </span>kings) <span class="op">/</span>
<span class="st">  </span><span class="kw">sum</span>(first_card <span class="op">%in%</span><span class="st"> </span>kings)
<span class="co">#&gt; [1] 0.0588</span></code></pre></div>
<p>which is exactly 3/51, as we had already deduced. Notice that the code above is equivalent to:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(first_card <span class="op">%in%</span><span class="st"> </span>kings <span class="op">&amp;</span><span class="st"> </span>second_card <span class="op">%in%</span><span class="st"> </span>kings) <span class="op">/</span>
<span class="st">  </span><span class="kw">mean</span>(first_card <span class="op">%in%</span><span class="st"> </span>kings)
<span class="co">#&gt; [1] 0.0588</span></code></pre></div>
<p>which uses <code>mean</code> instead of <code>sum</code> and is an R version of:</p>
<p><span class="math display">\[
\frac{\mbox{Pr}(A \mbox{ and } B)}{ \mbox{Pr}(A)}
\]</span></p>
<p>How about if the order doesn’t matter? For example, in Blackjack if you get an Ace and a face card in the first draw, it is called a <em>Natural 21</em> and you win automatically. If we wanted to compute the probability of this happening, we would enumerate the <em>combinations</em>, not the permutations, since the order does not matter. Below are the differences:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">permutations</span>(<span class="dv">3</span>,<span class="dv">2</span>)
<span class="co">#&gt;      [,1] [,2]</span>
<span class="co">#&gt; [1,]    1    2</span>
<span class="co">#&gt; [2,]    1    3</span>
<span class="co">#&gt; [3,]    2    1</span>
<span class="co">#&gt; [4,]    2    3</span>
<span class="co">#&gt; [5,]    3    1</span>
<span class="co">#&gt; [6,]    3    2</span>
<span class="kw">combinations</span>(<span class="dv">3</span>,<span class="dv">2</span>)
<span class="co">#&gt;      [,1] [,2]</span>
<span class="co">#&gt; [1,]    1    2</span>
<span class="co">#&gt; [2,]    1    3</span>
<span class="co">#&gt; [3,]    2    3</span></code></pre></div>
<p>In the second line, the outcome does not include (2,1) because (1,2) already was enumerated. The same applies to (3,1) and (3,2).</p>
<p>So to compute the probability of a <em>Natural 21</em> in Blackjack, we can do this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aces &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;Ace&quot;</span>, suits)

facecard &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;King&quot;</span>, <span class="st">&quot;Queen&quot;</span>, <span class="st">&quot;Jack&quot;</span>, <span class="st">&quot;Ten&quot;</span>)
facecard &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">number =</span> facecard, <span class="dt">suit =</span> suits)
facecard &lt;-<span class="st"> </span><span class="kw">paste</span>(facecard<span class="op">$</span>number, facecard<span class="op">$</span>suit)

hands &lt;-<span class="st"> </span><span class="kw">combinations</span>(<span class="dv">52</span>, <span class="dv">2</span>, <span class="dt">v =</span> deck)
<span class="kw">mean</span>(hands[,<span class="dv">1</span>] <span class="op">%in%</span><span class="st"> </span>aces <span class="op">&amp;</span><span class="st"> </span>hands[,<span class="dv">2</span>] <span class="op">%in%</span><span class="st"> </span>facecard)
<span class="co">#&gt; [1] 0.0483</span></code></pre></div>
<p>In the last line, we assume the Ace comes first. This is only because we know the way <code>combination</code> generates enumerates possibilities and it will list this case first. But to be safe, we could have written this and produced the same answer:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>((hands[,<span class="dv">1</span>] <span class="op">%in%</span><span class="st"> </span>aces <span class="op">&amp;</span><span class="st"> </span>hands[,<span class="dv">2</span>] <span class="op">%in%</span><span class="st"> </span>facecard) <span class="op">|</span>
<span class="st">       </span>(hands[,<span class="dv">2</span>] <span class="op">%in%</span><span class="st"> </span>aces <span class="op">&amp;</span><span class="st"> </span>hands[,<span class="dv">1</span>] <span class="op">%in%</span><span class="st"> </span>facecard))
<span class="co">#&gt; [1] 0.0483</span></code></pre></div>
</div>
<div id="monte-carlo-example" class="section level3">
<h3><span class="header-section-number">24.1.12</span> Monte Carlo example</h3>
<p>Instead of using <code>combinations</code> to deduce the exact probability of a Natural 21, we can use a Monte Carlo to estimate this probability. In this case, we draw two cards over and over and keep track of how many 21s we get. We can use the function sample to draw two cards without replacements:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hand &lt;-<span class="st"> </span><span class="kw">sample</span>(deck, <span class="dv">2</span>)
hand
<span class="co">#&gt; [1] &quot;Jack Diamonds&quot; &quot;Ten Diamonds&quot;</span></code></pre></div>
<p>And then check if one card is an Ace and the other a face card or a 10. Going forward, we include 10 when we say <em>face card</em>. Now we need to check both possibilities:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(hands[<span class="dv">1</span>] <span class="op">%in%</span><span class="st"> </span>aces <span class="op">&amp;</span><span class="st"> </span>hands[<span class="dv">2</span>] <span class="op">%in%</span><span class="st"> </span>facecard) <span class="op">|</span><span class="st"> </span>
<span class="st">  </span>(hands[<span class="dv">2</span>] <span class="op">%in%</span><span class="st"> </span>aces <span class="op">&amp;</span><span class="st"> </span>hands[<span class="dv">1</span>] <span class="op">%in%</span><span class="st"> </span>facecard)
<span class="co">#&gt; [1] FALSE</span></code></pre></div>
<p>If we repeat this 10,000 times, we get a very good approximation of the probability of a Natural 21.</p>
<p>Let’s start by writing a function that draws a hand and returns TRUE if we get a 21. The function does not need any arguments because it uses objects defined in the global environment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">blackjack &lt;-<span class="st"> </span><span class="cf">function</span>(){
   hand &lt;-<span class="st"> </span><span class="kw">sample</span>(deck, <span class="dv">2</span>)
  (hand[<span class="dv">1</span>] <span class="op">%in%</span><span class="st"> </span>aces <span class="op">&amp;</span><span class="st"> </span>hand[<span class="dv">2</span>] <span class="op">%in%</span><span class="st"> </span>facecard) <span class="op">|</span><span class="st"> </span>
<span class="st">    </span>(hand[<span class="dv">2</span>] <span class="op">%in%</span><span class="st"> </span>aces <span class="op">&amp;</span><span class="st"> </span>hand[<span class="dv">1</span>] <span class="op">%in%</span><span class="st"> </span>facecard)
}</code></pre></div>
<p>Here we do have to check both possibilities: Ace first or Ace second because we are not using the <code>combinations</code> function. The function returns <code>TRUE</code> if we get a 21 and <code>FALSE</code> otherwise:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">blackjack</span>()
<span class="co">#&gt; [1] FALSE</span></code></pre></div>
<p>Now we can play this game, say, 10,000 times:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10000</span>
results &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">blackjack</span>())
<span class="kw">mean</span>(results)
<span class="co">#&gt; [1] 0.0519</span></code></pre></div>
</div>
<div id="birthday-problem-example" class="section level3">
<h3><span class="header-section-number">24.1.13</span> Birthday problem example</h3>
<p>Suppose you are in a classroom with 50 people. If we assume this is a randomly selected group of 50 people, what is the chance that at least two people have the same birthday? Although it is somewhat advanced, we can deduce this mathematically. We will do this later. Here we use a Monte Carlo simulation. For simplicity, we assume nobody was born on February 29. This actually doesn’t change the answer much.</p>
<p>First, note that birthdays can be represented as numbers between 1 and 365, so a sample of 50 birthdays can be obtained like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">50</span>
bdays &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">365</span>, n, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>To check if in this particular set of 50 people we have at least two with the same birthday, we can use the function <code>duplicated</code> which returns <code>TRUE</code> whenever an element of a vector is a duplicate. Here is an example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">duplicated</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">5</span>))
<span class="co">#&gt; [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE</span></code></pre></div>
<p>The second time 1 and 3 appear, we get a <code>TRUE</code>. So to check if two birthdays were the same, we simply use the <code>any</code> and <code>duplicated</code> functions like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">any</span>(<span class="kw">duplicated</span>(bdays))
<span class="co">#&gt; [1] TRUE</span></code></pre></div>
<p>In this case, we see that it did happen. At least two people had the same birthday.</p>
<p>To estimate the probability, we repeat this experiment by sampling sets of 50 birthdays over and over:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">same_birthday &lt;-<span class="st"> </span><span class="cf">function</span>(n){
  bdays &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">365</span>, n, <span class="dt">replace=</span><span class="ot">TRUE</span>)
  <span class="kw">any</span>(<span class="kw">duplicated</span>(bdays))
}

B &lt;-<span class="st"> </span><span class="dv">10000</span>
results &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">same_birthday</span>(<span class="dv">50</span>))
<span class="kw">mean</span>(results)
<span class="co">#&gt; [1] 0.97</span></code></pre></div>
<p>Where you expecting the probability to be this high?</p>
<p>People tend to underestimate these probabilities. To get an intuition as to why it is so high, think about what happens when the group size is close to 365. At this stage, we run out of days and the probability is one.</p>
<p>Say we want to use this knowledge to bet with friends about two people having the same birthday in a group of people. When are the chances larger than 50%? Larger than 75%?</p>
<p>Let’s create a look-up table. We can quickly create a function to compute this for any group size:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">compute_prob &lt;-<span class="st"> </span><span class="cf">function</span>(n, <span class="dt">B=</span><span class="dv">10000</span>){
  results &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">same_birthday</span>(n))
  <span class="kw">mean</span>(results)
}</code></pre></div>
<p>Using the function <code>sapply</code>, we can perform element-wise operations on any function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">60</span>)
prob &lt;-<span class="st"> </span><span class="kw">sapply</span>(n, compute_prob)</code></pre></div>
<p>We can now make a plot of the estimated probabilities of two people having the same birthday in a group of size <span class="math inline">\(n\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
prob &lt;-<span class="st"> </span><span class="kw">sapply</span>(n, compute_prob)
<span class="kw">qplot</span>(n, prob)</code></pre></div>
<p><img src="book_files/figure-html/birthday-problem-mc-probabilities-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Now let’s compute the exact probabilities rather than use Monte Carlo approximations. Not only do we get the exact answer using math, but the computations are much faster since we don’t have to generate experiments.</p>
<p>To make the math simpler, instead of computing the probability of it happening, we will compute the probability of it not happening. For this, we use the multiplication rule.</p>
<p>Let’s start with the first person. The probability that person 1 has a unique birthday is 1. The probability that person 2 has a unique birthday, given that person 1 already took one, is 364/365. Then, given that the first two people have unique birthdays, person 3 is left with 363 days to choose from. We continue this way and find the chances of all 50 people having a unique birthday is:</p>
<p><span class="math display">\[
1 \times \frac{364}{365}\times\frac{363}{365} \dots \frac{365-n + 1}{365}
\]</span></p>
<p>We can write a function that does this for any number:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">exact_prob &lt;-<span class="st"> </span><span class="cf">function</span>(n){
  prob_unique &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">365</span>,<span class="dv">365</span><span class="op">-</span>n<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">365</span> 
  <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">prod</span>( prob_unique)
}
eprob &lt;-<span class="st"> </span><span class="kw">sapply</span>(n, exact_prob)

<span class="kw">qplot</span>(n, prob) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(n, eprob), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="book_files/figure-html/birthday-problem-exact-probabilities-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>This plot shows that the Monte Carlo simulation provided a very good estimate of the exact probability. Had it not been possible to compute the exact probabilities, we would have still been able to accurately estimate the probabilities.</p>
</div>
<div id="how-many-monte-carlo-experiments-are-enough" class="section level3">
<h3><span class="header-section-number">24.1.14</span> How many Monte Carlo experiments are enough</h3>
<p>In the examples above, we used <span class="math inline">\(B=10,000\)</span> Monte Carlo experiments. It turns out that this provided very accurate estimates. But in more complex calculations, 10,000 may not nearly enough. Also, for some calculations, 10,000 experiments might not be computationally feasible. In practice, we won’t know what the answer is so we won’t know if our Monte Carlo estimate is accurate. We know that the larger <span class="math inline">\(B\)</span>, the better the approximation. But how big do we need it to be? This is actually a challenging question and answering it often requires advanced theoretical statistics training.</p>
<p>One practical approach we will describe here is to check for the stability of the estimate. The following is an example with the birthday problem for a group of 22 people.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dt">len =</span> <span class="dv">100</span>)
compute_prob &lt;-<span class="st"> </span><span class="cf">function</span>(B, <span class="dt">n=</span><span class="dv">25</span>){
  same_day &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">same_birthday</span>(n))
  <span class="kw">mean</span>(same_day)
}
prob &lt;-<span class="st"> </span><span class="kw">sapply</span>(B, compute_prob)
<span class="kw">qplot</span>(<span class="kw">log10</span>(B), prob, <span class="dt">geom =</span> <span class="st">&quot;line&quot;</span>)</code></pre></div>
<p><img src="book_files/figure-html/monte-carlo-convergence-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>In this plot, we can see that the values start to stabilize; that is, they vary less than .01, around 1000. Note that the exact probability, which we know in this case, is 0.569.</p>
</div>
<div id="monty-hall-problem-example" class="section level3">
<h3><span class="header-section-number">24.1.15</span> Monty Hall problem example</h3>
<p>In the 1970s, there was a game show called “Let’s Make a Deal” and Monty Hall was the host. At some point in the game, contestants were asked to pick one of three doors. Behind one door there was a prize. The other doors had a goat behind them to show the contestant they had lost. If the contestant did not pick the prize door on his or her first try, Monty Hall would open one of the two remaining doors and show the contestant there was no prize. Then he would ask “Do you want to switch doors?” What would you do?</p>
<p>We can use probability to show that if you stick with the original door choice, your chances of winning a prize remain 1 in 3. However, if you switch to the other door, your chances of winning double to 2 in 3! This seems counterintuitive. Many people incorrectly think both chances are 1 in 2 since you are choosing between 2 options. You can watch a detailed mathematical explanation of why this is <a href="https://www.khanacademy.org/math/precalculus/prob-comb/dependent-events-precalc/v/monty-hall-problem">here</a> or read one <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">here</a>. Below we use a Monte Carlo simulation to see which strategy is better. Note that this code is written longer than it should be for pedagogical purposes.</p>
<p>Let’s start with the stick strategy:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10000</span>
stick &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
  doors &lt;-<span class="st"> </span><span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)
  prize &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;car&quot;</span>, <span class="st">&quot;goat&quot;</span>, <span class="st">&quot;goat&quot;</span>))
  prize_door &lt;-<span class="st"> </span>doors[prize <span class="op">==</span><span class="st"> &quot;car&quot;</span>]
  my_pick  &lt;-<span class="st"> </span><span class="kw">sample</span>(doors, <span class="dv">1</span>)
  show &lt;-<span class="st"> </span><span class="kw">sample</span>(doors[<span class="op">!</span>doors <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(my_pick, prize_door)],<span class="dv">1</span>)
  stick &lt;-<span class="st"> </span>my_pick
  stick <span class="op">==</span><span class="st"> </span>prize_door
})
<span class="kw">mean</span>(stick)
<span class="co">#&gt; [1] 0.336</span></code></pre></div>
<p>As we write the code, we note that the lines starting with <code>my_pick</code> and <code>show</code> have no influence on the last logical operation since we stick to our original choice anyway. From this we should realize that the chance is 1 in 3, what we began with.</p>
<p>Now let’s repeat the exercise, but consider the switch strategy:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">switch</span> &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
  doors &lt;-<span class="st"> </span><span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)
  prize &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;car&quot;</span>, <span class="st">&quot;goat&quot;</span>, <span class="st">&quot;goat&quot;</span>))
  prize_door &lt;-<span class="st"> </span>doors[prize <span class="op">==</span><span class="st"> &quot;car&quot;</span>]
  my_pick  &lt;-<span class="st"> </span><span class="kw">sample</span>(doors, <span class="dv">1</span>)
  show &lt;-<span class="st"> </span><span class="kw">sample</span>(doors[<span class="op">!</span>doors <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(my_pick, prize_door)], <span class="dv">1</span>)
  stick &lt;-<span class="st"> </span>my_pick
  <span class="cf">switch</span> &lt;-<span class="st"> </span>doors[<span class="op">!</span>doors<span class="op">%in%</span><span class="kw">c</span>(my_pick, show)]
  <span class="cf">switch</span> <span class="op">==</span><span class="st"> </span>prize_door
})
<span class="kw">mean</span>(<span class="cf">switch</span>)
<span class="co">#&gt; [1] 0.672</span></code></pre></div>
<p>The Monte Carlo estimate confirms the 2/3 calculation. This helps us gain some insight by showing that we are removing a door, <code>show</code>, that is definitely not a winner from our choices. We also see that unless we get it right when we first pick, you win: 1 - 1/3 = 2/3.</p>
</div>
<div id="exercises-26" class="section level3">
<h3><span class="header-section-number">24.1.16</span> Exercises</h3>
<ol style="list-style-type: decimal">
<li><p>One ball will be drawn at random from a box containing: 3 cyan balls, 5 magenta balls, and 7 yellow balls. What is the probability that the ball will be cyan?</p></li>
<li><p>What is the probability that the ball will not be cyan?</p></li>
<li><p>Instead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling <strong>without</strong> replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?</p></li>
<li><p>Now repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling <strong>with</strong> replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?</p></li>
<li><p>Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if <span class="math inline">\(\mbox{Pr}(A \mbox{ and } B) = \mbox{Pr}(A) P(B)\)</span>. Under which situation are the draws independent?</p>
<p>A. You don’t replace the draw.</p>
<p>B. You replace the draw.</p>
<p>C. Neither</p>
<p>D. Both</p></li>
<li><p>Say you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?</p></li>
<li><p>If you roll a 6-sided die six times, what is the probability of not seeing a 6?</p></li>
<li><p>Two teams, say the Celtics and the Cavs, are playing a seven game series. The Cavs are a better team and have a 60% chance of winning each game. What is the probability that the Celtics win <strong>at least</strong> one game?</p></li>
<li><p>Create a Monte Carlo simulation to confirm your answer to the previous problem. Use <code>B &lt;- 10000</code> simulations. Hint: Use the following code to generate the results of the first four games:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">celtic_wins &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dv">4</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.6</span>, <span class="fl">0.4</span>))</code></pre></div>
<p>The Celtics must win one of these 4 games.</p></li>
<li><p>Two teams, say the Cavs and the Warriors, are playing a seven game championship series. The first to win four games, therefore, wins the series. The teams are equally good so they each have a 50-50 chance of winning each game. If the Cavs lose the first game, what is the probability that they win the series?</p></li>
<li><p>Confirm the results of the previous question with a Monte Carlo simulation.</p></li>
<li><p>Two teams, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, are playing a seven game series. Team <span class="math inline">\(A\)</span> is better than team <span class="math inline">\(B\)</span> and has a <span class="math inline">\(p&gt;0.5\)</span> chance of winning each game. Given a value <span class="math inline">\(p\)</span>, the probability of winning the series for the underdog team <span class="math inline">\(B\)</span> can be computed with the following function based on a Monte Carlo simulation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prob_win &lt;-<span class="st"> </span><span class="cf">function</span>(p){
  B &lt;-<span class="st"> </span><span class="dv">10000</span>
  result &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    b_win &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>), <span class="dv">7</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p))
    <span class="kw">sum</span>(b_win)<span class="op">&gt;=</span><span class="dv">4</span>
  })
  <span class="kw">mean</span>(result)
}</code></pre></div>
<p>Use the function <code>sapply</code> to compute the probability, call it <code>Pr</code>, of winning for <code>p &lt;- seq(0.5, 0.95, 0.025)</code>. Then plot the result.</p></li>
<li><p>Repeat the exercise above, but now keep the probability fixed at <code>p &lt;- 0.75</code> and compute the probability for different series lengths: best of 1 game, 3 games, 5 games,… Specifically, <code>N &lt;- seq(1, 25, 2)</code>. Hint: use this function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prob_win &lt;-<span class="st"> </span><span class="cf">function</span>(N, <span class="dt">p=</span><span class="fl">0.75</span>){
  B &lt;-<span class="st"> </span><span class="dv">10000</span>
  result &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    b_win &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>), N, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p))
    <span class="kw">sum</span>(b_win)<span class="op">&gt;=</span>(N<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>
  })
  <span class="kw">mean</span>(result)
}</code></pre></div></li>
</ol>

</div>
</div>
<div id="continuous-probability" class="section level2">
<h2><span class="header-section-number">24.2</span> Continuous probability</h2>
<p>Earlier, we explained why when summarizing a list of numeric values, such as heights, it is not useful to construct a distribution that defines a proportion to each possible outcome. For example, if we measure every single person in a very large population of size <span class="math inline">\(n\)</span> with extremely high precision, since no two people are exactly the same height, we need to assign the proportion <span class="math inline">\(1/n\)</span> to each observed value and attain no useful summary at all. Similarly, when defining probability distributions, it is not useful to assign a very small probability to every single height.</p>
<p>Just as when using distributions to summarize numeric data, it is much more practical to define a function that operates on intervals rather than single values. The standard way of doing this is using the <em>cumulative distribution function</em> (CDF).</p>
<p>We previously described empirical cumulative distribution function (eCDF) as a basic summary of a list of numeric values. As an example, we earlier defined the height distribution for adult male students. Here, we define the vector <span class="math inline">\(x\)</span> to contain these heights:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(dslabs)
<span class="kw">data</span>(heights)
x &lt;-<span class="st"> </span>heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(sex<span class="op">==</span><span class="st">&quot;Male&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(height)</code></pre></div>
<p>We defined the empirical distribution function as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">F &lt;-<span class="st"> </span><span class="cf">function</span>(a) <span class="kw">mean</span>(x<span class="op">&lt;=</span>a)</code></pre></div>
<p>which, for any value <code>a</code>, gives the proportion of values in the list <code>x</code> that are smaller or equal than <code>a</code>.</p>
<p>Keep in mind that we have not yet introduced probability. Let’s do this by asking the following: if I pick one of the male students at random, what is the chance that he is taller than 70.5 inches? Because every student has the same chance of being picked, the answer to this is equivalent to the proportion of students that are taller than 70.5 inches. Using the CDF we obtain an answer by typing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">F</span>(<span class="dv">70</span>)
<span class="co">#&gt; [1] 0.377</span></code></pre></div>
<p>Once a CDF is defined, we can use this to compute the probability of any subset. For instance, the probability of a student being between height <code>a</code> and height <code>b</code> is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">F</span>(b)<span class="op">-</span><span class="kw">F</span>(a)</code></pre></div>
<p>Because we can compute the probability for any possible event this way, the cumulative probability function defines the probability distribution for picking a height at random from our vector of heights <code>x</code>.</p>
<div id="theoretical-distribution" class="section level3">
<h3><span class="header-section-number">24.2.1</span> Theoretical distribution</h3>
<p>In the data visualization chapter, we introduced the normal distribution as a useful approximation to many naturally occurring distributions, including that of height. The cumulative distribution for the normal distribution is defined by a mathematical formula which in R can be obtained with the function <code>pnorm</code>. We say that a random quantity is normally distributed with average <code>m</code> and standard deviation <code>s</code>, if its probability distribution is defined by:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">F</span>(a) =<span class="st"> </span><span class="kw">rnorm</span>(a, m, s)</code></pre></div>
<p>This is useful because if we are willing to use the normal approximation for, say, height, we don’t need the entire dataset to answer questions such as: what is the probability that a randomly selected student is taller then 70 inches? We just need the average height and standard deviation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">mean</span>(x)
s &lt;-<span class="st"> </span><span class="kw">sd</span>(x)
<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">70.5</span>, m, s)
<span class="co">#&gt; [1] 0.371</span></code></pre></div>
</div>
<div id="theoretical-distributions-as-approximations" class="section level3">
<h3><span class="header-section-number">24.2.2</span> Theoretical distributions as approximations</h3>
<p>The normal distribution is derived mathematically: we do not need data to define it. For practicing data scientists, almost everything we do involves data. Data is always, technically speaking, discrete. For example, we could consider our height data categorical with each specific height a unique category. The probability distribution is defined by the proportion of students reporting each height. Here is a plot of that probability distribution:</p>
<p><img src="book_files/figure-html/plot-of-height-frequencies-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>While most students rounded up their heights to the nearest inch, others reported values with more precision. One student reported his height to be 69.6850393700787 which is 177 centimeters. The probability assigned to this height is 0.001 or 1 in 812. The probability for 70 inches is much higher 0.106, but does it really make sense to think of the probability of being exactly 70 inches as being the same as 69.6850393700787? Clearly it is much more useful for data analytic purposes to treat this outcome as a continuous numeric variable, keeping in mind that very few people, or perhaps none, are exactly 70 inches, and that the reason we get more values at 70 is because people round to the nearest inch.</p>
<p>With continuous distributions, the probability of a singular value is not even defined. For example, it does not make sense to ask what is the probability that a normally distributed value is 70. Instead, we define probabilities for intervals. We thus could ask what is the probability that someone is between 69.5 and 70.5.</p>
<p>In cases like height, in which the data is rounded, the normal approximation is particularly useful if we deal with intervals that include exactly one round number. For example, the normal distribution is useful for approximating the proportion of students reporting values in intervals like the following three:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(x <span class="op">&lt;=</span><span class="st"> </span><span class="fl">68.5</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x <span class="op">&lt;=</span><span class="st"> </span><span class="fl">67.5</span>)
<span class="co">#&gt; [1] 0.115</span>
<span class="kw">mean</span>(x <span class="op">&lt;=</span><span class="st"> </span><span class="fl">69.5</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x <span class="op">&lt;=</span><span class="st"> </span><span class="fl">68.5</span>)
<span class="co">#&gt; [1] 0.119</span>
<span class="kw">mean</span>(x <span class="op">&lt;=</span><span class="st"> </span><span class="fl">70.5</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x <span class="op">&lt;=</span><span class="st"> </span><span class="fl">69.5</span>)
<span class="co">#&gt; [1] 0.122</span></code></pre></div>
<p>Note how close we get with the normal approximation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="fl">68.5</span>, m, s) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">67.5</span>, m, s) 
<span class="co">#&gt; [1] 0.103</span>
<span class="kw">pnorm</span>(<span class="fl">69.5</span>, m, s) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">68.5</span>, m, s) 
<span class="co">#&gt; [1] 0.11</span>
<span class="kw">pnorm</span>(<span class="fl">70.5</span>, m, s) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">69.5</span>, m, s) 
<span class="co">#&gt; [1] 0.108</span></code></pre></div>
<p>However, the approximation is not as useful for other intervals. For instance, notice how the approximation breaks down when we try to estimate:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(x <span class="op">&lt;=</span><span class="st"> </span><span class="fl">70.9</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x<span class="op">&lt;=</span><span class="fl">70.1</span>)
<span class="co">#&gt; [1] 0.0222</span></code></pre></div>
<p>with</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="fl">70.9</span>, m, s) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">70.1</span>, m, s)
<span class="co">#&gt; [1] 0.0836</span></code></pre></div>
<p>In general, we call this situation <em>discretization</em>. Although the true height distribution is continuous, the reported heights tend to be more common at discrete values, in this case, due to rounding. As long as we are aware of how to deal with this reality, the normal approximation can still be a very useful tool.</p>
</div>
<div id="the-probability-density" class="section level3">
<h3><span class="header-section-number">24.2.3</span> The probability density</h3>
<p>For categorical distributions, we can define the probability of a category. For example, a roll of a die, let’s call it <span class="math inline">\(X\)</span>, can be 1,2,3,4,5 or 6. The probability of 4 is defined as:</p>
<p><span class="math display">\[
\mbox{Pr}(X=4) = 1/6
\]</span></p>
<p>The CFD can then easily be defined: <span class="math display">\[
F(4) = \mbox{Pr}(X\leq 4) =  \mbox{Pr}(X = 4) +  \mbox{Pr}(X = 3) +  \mbox{Pr}(X = 2) +  \mbox{Pr}(X = 1) 
\]</span></p>
<p>Although for continuous distributions the probability of a single value <span class="math inline">\(\mbox{Pr}(X=x)\)</span> is not defined, there is a theoretical definition that has a similar interpretation. The probability density at <span class="math inline">\(x\)</span> is defined as the function <span class="math inline">\(f(a)\)</span> such that:</p>
<p><span class="math display">\[
F(a) = \mbox{Pr}(X\leq a) = \int_{-\infty}^a f(x)\, dx
\]</span></p>
<p>For those that know calculus, remember that the integral is related to a sum: it is the sum of bars with widths approximating 0. If you don’t know calculus, you can think of <span class="math inline">\(f(x)\)</span> as a curve for which the area under that curve up to the value <span class="math inline">\(a\)</span>, gives you the probability <span class="math inline">\(\mbox{Pr}(X\leq a)\)</span>.</p>
<p>For example, to use the normal approximation to estimate the probability of someone being taller than 76 inches, we use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">76</span>, m, s)
<span class="co">#&gt; [1] 0.0321</span></code></pre></div>
<p>which mathematically is the grey area below:</p>
<p><img src="book_files/figure-html/intergrals-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The curve you see is the probability density for the normal distribution. In R, we get this using the function <code>dnorm</code>.</p>
<p>Although it may not be immediately obvious why knowing about probability densities is useful, understanding this concept will be essential to those wanting to fit models to data for which predefined functions are not available.</p>
</div>
<div id="monte-carlo-simulations-for-continuous-variables" class="section level3">
<h3><span class="header-section-number">24.2.4</span> Monte Carlo simulations for continuous variables</h3>
<p>R provides functions to generate normally distributed outcomes. Specifically, the <code>rnorm</code> function takes three arguments: size, average (defaults to 0), and standard deviation (defaults to 1) and produces random numbers. Here is an example of how we could generate data that looks like our reported heights:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
m &lt;-<span class="st"> </span><span class="kw">mean</span>(x)
s &lt;-<span class="st"> </span><span class="kw">sd</span>(x)
simulated_heights &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, m, s)</code></pre></div>
<p>Not surprisingly, the distribution looks normal:</p>
<p><img src="book_files/figure-html/simulated-heights-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>This is one of the most useful functions in R as it will permit us to generate data that mimics natural events and answers questions related to what could happen by chance by running Monte Carlo simulations.</p>
<p>If, for example, we pick 800 males at random, what is the distribution of the tallest person? How rare is a seven footer in a group of 800 males? The following Monte Carlo simulation helps us answer that question:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10000</span>
tallest &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
  simulated_data &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">800</span>, m, s)
  <span class="kw">max</span>(simulated_data)
})</code></pre></div>
<p>Having a seven footer is quite rare:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(tallest <span class="op">&gt;=</span><span class="st"> </span><span class="dv">7</span><span class="op">*</span><span class="dv">12</span>)
<span class="co">#&gt; [1] 0.0184</span></code></pre></div>
<p>Here is the resulting distribution:</p>
<p><img src="book_files/figure-html/simulated-tallest-height-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Note that it does not look normal.</p>
</div>
<div id="other-continuous-distributions" class="section level3">
<h3><span class="header-section-number">24.2.5</span> Other continuous distributions</h3>
<p>The normal distribution is not the only useful theoretical distribution. Other continuous distributions that we may encounter are the student-t, chi-squared, exponential, gamma, beta, and beta-binomial. R provides functions to compute the density, the quantiles, the cumulative distribution functions and to generate Monte Carlo simulations. R uses a convention that lets us remember the names, namely using the letters <code>d</code>, <code>q</code>, <code>p</code> and <code>r</code> in front of a shorthand for the distribution. We have already seen the functions <code>dnorm</code>, <code>pnorm</code> and <code>rnorm</code> for the normal distribution. The functions <code>qnorm</code> gives us the quantiles. We can therefore draw a distribution like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)
<span class="kw">data.frame</span>(x, <span class="dt">f =</span> <span class="kw">dnorm</span>(x)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x, f)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>()</code></pre></div>
<p><img src="book_files/figure-html/normal-density-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>For the student-t, the shorthand <code>t</code> is used so the functions are <code>dt</code> for the density, <code>qt</code> for the quantiles, <code>pt</code> for the cumulative distribution function, and <code>rt</code> for Monte Carlo simulation.</p>
</div>
<div id="exercises-27" class="section level3">
<h3><span class="header-section-number">24.2.6</span> Exercises</h3>
<ol style="list-style-type: decimal">
<li><p>Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random, what is the probability that she is 5 feet or shorter?</p></li>
<li><p>Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random, what is the probability that she is 6 feet or taller?</p></li>
<li><p>Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random what is the probability that she is between 61 and 67 inches.</p></li>
<li><p>Repeat the exercise above, but convert everything to centimeters. That is, multiply every height, including the standard deviation, by 2.54. What is the answer now?</p></li>
<li><p>Notice that the answer to the question does not change when you change units. This makes sense since the answer to the question should not be affected by what units we use. In fact, if you look closely, you notice that 61 and 64 are both 1 SD away from the average. Compute the probability that a randomly picked, normally distributed random variable is within 1 SD from the average.</p></li>
<li><p>To see the math that explains why the answers to questions 3, 4, and 5 are the same, suppose we have a random variable with average <span class="math inline">\(m\)</span> and standard error <span class="math inline">\(s\)</span>. Suppose we ask the probability of <span class="math inline">\(X\)</span> being smaller or equal to <span class="math inline">\(a\)</span>. Remember that, by definition, <span class="math inline">\(a\)</span> is <span class="math inline">\((a - m)/s\)</span> standard deviations <span class="math inline">\(s\)</span> away from the average <span class="math inline">\(m\)</span>. The probability is:</p>
<p><span class="math display">\[
\mbox{Pr}(X \leq a)
\]</span></p>
<p>Now we subtract <span class="math inline">\(\mu\)</span> to both sides and then divide both sides by <span class="math inline">\(\sigma\)</span>:</p>
<p><span class="math display">\[
\mbox{Pr}\left(\frac{X-m}{s} \leq \frac{a-m}{s} \right)
\]</span></p>
<p>The quantity on the right is a standard normal random variable. It has an average of 0 and a standard error of 1. We will call it <span class="math inline">\(Z\)</span>:</p>
<p><span class="math display">\[
\mbox{Pr}\left(Z \leq \frac{a-m}{s} \right)
\]</span></p>
<p>So, no matter the units, the probability of <span class="math inline">\(X\leq a\)</span> is the same as the probability of a standard normal variable being less than <span class="math inline">\((a - m)/s\)</span>. If <code>mu</code> is the average and <code>sigma</code> the standard error, which of the following R code would give us the right answer in every situation:</p>
<p>A. <code>mean(X&lt;=a)</code></p>
<p>B. <code>pnorm((a - m)/s)</code></p>
<p>C. <code>pnorm((a - m)/s, m, s)</code></p>
<p>D. <code>pnorm(a)</code></p></li>
<li><p>Imagine the distribution of male adults is approximately normal with an expected value of 69 and a standard deviation of 3. How tall is the male in the 99th percentile? Hint: use <code>qnorm</code>.</p></li>
<li><p>The distribution of IQ scores is approximately normally distributed. The average is 100 and the standard deviation is 15. Suppose you want to know the distribution of the highest IQ across all graduating classes if 10,000 people are born each in your school district. Run a Monte Carlo simulation with <code>B=1000</code> generating 10,000 IQ scores and keeping the highest. Make a histogram.</p></li>
</ol>

</div>
</div>
<div id="random-variables" class="section level2">
<h2><span class="header-section-number">24.3</span> Random variables</h2>
<p>Random variables are numeric outcomes resulting from random processes. We can easily generate random variables using some of the simple examples we have shown. For example, define <code>X</code> to be 1, if a bead is blue and red otherwise.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beads &lt;-<span class="st"> </span><span class="kw">rep</span>( <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))
X &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">sample</span>(beads, <span class="dv">1</span>) <span class="op">==</span><span class="st"> &quot;blue&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</code></pre></div>
<p>Here <code>X</code> is a random variable: every time we select a new bead the outcome changes randomly. See below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ifelse</span>(<span class="kw">sample</span>(beads, <span class="dv">1</span>) <span class="op">==</span><span class="st"> &quot;blue&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)
<span class="co">#&gt; [1] 0</span>
<span class="kw">ifelse</span>(<span class="kw">sample</span>(beads, <span class="dv">1</span>) <span class="op">==</span><span class="st"> &quot;blue&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)
<span class="co">#&gt; [1] 1</span>
<span class="kw">ifelse</span>(<span class="kw">sample</span>(beads, <span class="dv">1</span>) <span class="op">==</span><span class="st"> &quot;blue&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)
<span class="co">#&gt; [1] 1</span></code></pre></div>
<p>Sometimes it’s 1 and sometimes it’s 0.</p>
<p>In data science, we often deal with data that is affected by chance in some way: the data comes from a random sample, the data is affected by measurement error or the data measures some outcome that is random in nature. Being able to quantify the uncertainty introduced by randomness is one of the most important jobs of a data analysts. Statistical inference offers a framework, as well as several practical tools, for doing this. The first step is to learn how to mathematically describe random variables. We start with games of chance.</p>
<div id="sampling-models" class="section level3">
<h3><span class="header-section-number">24.3.1</span> Sampling models</h3>
<p>Many data generation procedures, those that produce the data we study, can be modeled quite well as draws from a urn. For instance, we can model the process of polling likely voters as drawing 0s (Republicans) and 1s (Democrats) from an urn containing the 0 and 1 code for all likely voters. In epidemiological studies, we often assume that the subjects in our study are a random sample from the population of interest. The data related to a specific outcome can be modeled as a random sample from an urn containing the outcome for the entire population of interest. Similarly, in experimental research, we often assume that the individual organisms we are studying, for example worms, flies, or mice, are a random sample from a larger population. Randomized experiments can also be modeled by draws from an urn given the way individuals are assigned into groups: when getting assigned, you draw your group at random. Sampling models are therefore ubiquitous in data science. Casino games offer a plethora of examples of real world situations in which sampling models are used to answer specific questions. We will therefore start with such examples.</p>
<p>Suppose a very small casino hires you to consult on whether they should set up roulette wheels. To keep the example simple, we will assume that 1,000 people will play and that the only game you can play on the roulette wheel is to bet on red or black. The casino wants you to predict how much money they will make or lose. They want a range of values and, in particular, they want to know what’s the chance of losing money. If this probability is too high, they will pass on installing roulette wheels.</p>
<p>We are going to define a random variable <span class="math inline">\(S\)</span> that will represent the casino’s total winnings. Let’s start by constructing the urn. A roulette wheel has 18 red pockets, 18 black pockets and 2 green ones. So playing a color in one game of roulette is equivalent to drawing from this urn:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;Red&quot;</span>, <span class="st">&quot;Green&quot;</span>), <span class="kw">c</span>(<span class="dv">18</span>, <span class="dv">18</span>, <span class="dv">2</span>))</code></pre></div>
<p>The 1,000 outcomes from 1,000 people playing are independent draws from this urn. If red comes up, the gambler wins and the casino loses a dollar, so we draw a -$1. Otherwise, the casino wins a dollar and we draw a $1. To construct our random variable <span class="math inline">\(S\)</span>, we can use this code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">ifelse</span>(color <span class="op">==</span><span class="st"> &quot;Red&quot;</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>),  n, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
X[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]
<span class="co">#&gt;  [1]  1 -1 -1 -1 -1  1  1  1 -1  1</span></code></pre></div>
<p>Because we know the proportions of 1s and -1s, we can generate the draws with one line of code, without defining <code>color</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))</code></pre></div>
<p>We call this a <strong>sampling model</strong> since we are modeling the random behavior of roulette with the sampling of draws from an urn. The total winnings <span class="math inline">\(S\)</span> is simply the sum of these 1,000 independent draws:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))
S &lt;-<span class="st"> </span><span class="kw">sum</span>(X)
S
<span class="co">#&gt; [1] 78</span></code></pre></div>
</div>
<div id="the-probability-distribution-of-a-random-variable" class="section level3">
<h3><span class="header-section-number">24.3.2</span> The probability distribution of a random variable</h3>
<p>If you run the code above, you see that <span class="math inline">\(S\)</span> changes every time. This is, of course, because <span class="math inline">\(S\)</span> is a <strong>random variable</strong>. The probability distribution of a random variable tells us the probability of the observed value falling at any given interval. So, for example, if we want to know the probability that we lose money, we are asking the probability that <span class="math inline">\(S\)</span> is in the interval <span class="math inline">\(S&lt;0\)</span>.</p>
<p>Note that if we can define a cumulative distribution function <span class="math inline">\(F(a) = \mbox{Pr}(S\leq a)\)</span>, then we will be able to answer any question related to the probability of events defined by our random variable <span class="math inline">\(S\)</span>, including the event <span class="math inline">\(S&lt;0\)</span>. We call this <span class="math inline">\(F\)</span> the random variable’s <em>distribution function</em>.</p>
<p>We can estimate the distribution function for the random variable <span class="math inline">\(S\)</span> by using a Monte Carlo simulation to generate many realizations of the random variable. With this code, we run the experiment of having 1,000 people play roulette, over and over, specifically <span class="math inline">\(B = 10,000\)</span> times:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
B &lt;-<span class="st"> </span><span class="dv">10000</span>
roulette_winnings &lt;-<span class="st"> </span><span class="cf">function</span>(n){
  X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))
  <span class="kw">sum</span>(X)
}
S &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">roulette_winnings</span>(n))</code></pre></div>
<p>Now we can ask the following: in our simulations, how often did we get sums less than or equal to <code>a</code>?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S <span class="op">&lt;=</span><span class="st"> </span>a)</code></pre></div>
<p>This will be a very good approximation of <span class="math inline">\(F(a)\)</span>. In fact, we can visualize the distribution by creating a histogram showing the probability <span class="math inline">\(F(b)-F(a)\)</span> for several intervals <span class="math inline">\((a,b]\)</span>:</p>
<p><img src="book_files/figure-html/sum-density-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Now we can easily answer the casino’s question: how likely is it that we will lose money?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S<span class="op">&lt;</span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.0459</span></code></pre></div>
<p>We can see it is quite low.</p>
<p>In the histogram above, we see that the distribution appears to be approximately normal. A qq-plot will confirm that the normal approximation is close to perfect. If, in fact, the distribution is normal, then all we need to define the distribution is the average and the standard deviation. Because we have the original values from which the distribution is created, we can easily compute these:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S)
<span class="co">#&gt; [1] 52.5</span>
<span class="kw">sd</span>(S)
<span class="co">#&gt; [1] 31.8</span></code></pre></div>
<p>If we add a normal density with this average and standard deviation to the histogram above, we see that it matches very well:</p>
<p><img src="book_files/figure-html/normal-approximates-distribution-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>This average and this standard deviation have special names. They are referred to as the <em>expected value</em> and <em>standard error</em> of the random variable <span class="math inline">\(S\)</span>. We will say more about these in the next section.</p>
<p>It turns out that statistical theory provides a way to derive the distribution of random variables defined as independent random draws from an urn. Specifically, in our example above, we can show that <span class="math inline">\((S+n)/2\)</span> follows a binomial distribution. We therefore do not need to run for Monte Carlo simulations to know the probability distribution of <span class="math inline">\(S\)</span>. We did this for illustrative purposes.</p>
<p>We can use the function <code>dbinom</code> and <code>pbinom</code> to compute the probabilities exactly. For example, to compute <span class="math inline">\(\mbox{Pr}(S &lt; 0)\)</span> we note that:</p>
<p><span class="math display">\[\mbox{Pr}(S &lt; 0) = \mbox{Pr}((S+n)/2 &lt; (0+n)/2)\]</span></p>
<p>and we can use the <code>pbinom</code> to compute <span class="math display">\[\mbox{Pr}(S \leq 0)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
<span class="kw">pbinom</span>(n<span class="op">/</span><span class="dv">2</span>, <span class="dt">size =</span> n, <span class="dt">prob =</span> <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>)
<span class="co">#&gt; [1] 0.0511</span></code></pre></div>
<p>Because this is a discrete probability function, to get <span class="math inline">\(\mbox{Pr}(S &lt; 0)\)</span> rather than <span class="math inline">\(\mbox{Pr}(S \leq 0)\)</span>, we write:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pbinom</span>(n<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="dv">1</span>, <span class="dt">size =</span> n, <span class="dt">prob =</span> <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>)
<span class="co">#&gt; [1] 0.0448</span></code></pre></div>
<p>For the details of the binomial distribution, you can consult any basic probability book or even <a href="https://en.wikipedia.org/wiki/Binomial_distribution">Wikipedia</a>.</p>
<p>Here we do not cover these details. Instead, we will discuss an incredibly useful approximation provided by mathematical theory that applies generally to sums and averages of draws from any urn: the Central Limit Theorem (CLT).</p>
</div>
<div id="distributions-versus-probability-distributions" class="section level3">
<h3><span class="header-section-number">24.3.3</span> Distributions versus probability distributions</h3>
<p>Before we continue, let’s make an important distinction and connection between the distribution of a list of numbers and a probability distribution. In the visualization chapter, we described how any list of numbers <span class="math inline">\(x_1,\dots,x_n\)</span> has a distribution. The definition is quite straightforward. We define <span class="math inline">\(F(a)\)</span> as the function that tells us what proportion of the list is less than or equal to <span class="math inline">\(a\)</span>. Because they are useful summaries when the distribution is approximately normal, we define the average and standard deviation. These are defined with a straightforward operation of the vector containing the list of numbers <code>x</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">sum</span>(x)<span class="op">/</span><span class="kw">length</span>(x)
s &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span>m)<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x))</code></pre></div>
<p>A random variable <span class="math inline">\(X\)</span> has a distribution function. To define this, we do not need a list of numbers. It is a theoretical concept. In this case, we define the distribution as the <span class="math inline">\(F(a)\)</span> that answers the question: what is the probability that <span class="math inline">\(X\)</span> is less than or equal to <span class="math inline">\(a\)</span>? There is no list of numbers.</p>
<p>However, if <span class="math inline">\(X\)</span> is defined by drawing from an urn with numbers in it, then there is a list: the list of numbers inside the urn. In this case, the distribution of that list is the probability distribution of <span class="math inline">\(X\)</span> and the average and standard deviation of that list are the expected value and standard error of the random variable.</p>
<p>Another way to think about it that does not involve an urn is to run a Monte Carlo simulation and generate a very large list of outcomes of <span class="math inline">\(X\)</span>. These outcomes are a list of numbers. The distribution of this list will be a very good approximation of the probability distribution of <span class="math inline">\(X\)</span>. The longer the list, the better the approximation. The average and standard deviation of this list will approximate the expected value and standard error of the random variable.</p>
</div>
<div id="notation-for-random-variables" class="section level3">
<h3><span class="header-section-number">24.3.4</span> Notation for random variables</h3>
<p>In statistical textbooks, upper case letters are used to denote random variables and we follow this convention here. Lower case letters are used for observed values. You will see some notation that includes both. For example, you will see events defined as <span class="math inline">\(X \leq x\)</span>. Here <span class="math inline">\(X\)</span> is a random variable, making it a random event, and <span class="math inline">\(x\)</span> is an arbitrary value and not random. So, for example, <span class="math inline">\(X\)</span> might represent the number on a die roll and <span class="math inline">\(x\)</span> will represent an actual value we see 1, 2, 3, 4, 5 or 6. So in this case, the probability of <span class="math inline">\(X=x\)</span> is 1/6 regardless of the observed value <span class="math inline">\(x\)</span>. This notation is a bit strange because, when we ask questions about probability, <span class="math inline">\(X\)</span> is not an observed quantity. Instead, it’s a random quantity that we will see in the future. We can talk about what we expect it to be, what values are probable, but not what it is. But once we have data, we do see a realization of <span class="math inline">\(X\)</span>. So data scientists talk of what could have been after we see what actually happened.</p>
</div>
<div id="central-limit-theorem" class="section level3">
<h3><span class="header-section-number">24.3.5</span> Central Limit Theorem</h3>
<p>The Central Limit Theorem (CLT) tells us that when the number of draws, also called the <em>sample size</em>, is large, the probability distribution of the sum of the independent draws is approximately normal. Because sampling models are used for so many data generation processes, the CLT is considered one of the most important mathematical insights in history.</p>
<p>Previously, we discussed that if we know that the distribution of a list of numbers is approximated by the normal distribution, all we need to describe the list are the average and standard deviation. We also know that the same applies to probability distributions. If a random variable has a probability distribution that is approximated with the normal distribution, then all we need to describe the probability distribution are the average and standard deviation, referred to as the expected value and standard error.</p>
</div>
<div id="the-expected-value-and-standard-error" class="section level3">
<h3><span class="header-section-number">24.3.6</span> The expected value and standard error</h3>
<p>We have described sampling models for draws. We will now go over the mathematical theory that lets us approximate the probability distributions for the sum of draws. Once we do this, we will be able to help the casino predict how much money they will make. The same approach we use for the sum of draws will be useful for describing the distribution of averages and proportion which we will need to understand how polls work.</p>
<p>The first important concept to learn is the <em>expected value</em>. In statistics books, it is common to use letter <span class="math inline">\(\mbox{E}\)</span> like this:</p>
<p><span class="math display">\[\mbox{E}[X]\]</span></p>
<p>to denote the expected value of the random variable <span class="math inline">\(X\)</span>.</p>
<p>A random variable will vary around its expected value in a way that if you take the average of many, many draws, the average of the draws will approximate the expected value, getting closer and closer the more draws you take.</p>
<p>Theoretical statistics provides techniques that facilitate the calculation of expected values in different circumstances. For example, a useful formula tells us that the expected value of a random variable defined by one draw is the average of the numbers in the urn. In the urn used to model betting on red in roulette, we have 20 one dollars and 18 negative one dollars. The expected value is thus:</p>
<p><span class="math display">\[
\mbox{E}[X] = (20 + -18)/38
\]</span></p>
<p>which is about 5 cents. It is a bit counterintuitive to say that <span class="math inline">\(X\)</span> varies around 0.05, when the only values it takes is 1 and -1. One way to make sense of the expected value in this context is by realizing that if we play the game over and over, the casino wins, on average, 5 cents per game. A Monte Carlo simulation confirms this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>
x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), B, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))
<span class="kw">mean</span>(x)
<span class="co">#&gt; [1] 0.0517</span></code></pre></div>
<p>In general, if the urn has two possible outcomes, say <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, with proportions <span class="math inline">\(p\)</span> and <span class="math inline">\(1-p\)</span> respectively, the average is:</p>
<p><span class="math display">\[ap + b(1-p).\]</span></p>
<p>To see this, notice that if there are <span class="math inline">\(n\)</span> beads in the urn, then we have <span class="math inline">\(np\)</span> <span class="math inline">\(a\)</span>s and <span class="math inline">\(n(1-p)\)</span> <span class="math inline">\(b\)</span>s and because the average is the sum, <span class="math inline">\(n\times a \times p + n\times b \times (1-p)\)</span>, divided by the total <span class="math inline">\(n\)</span>, we get that the average is <span class="math inline">\(ap + b(1-p)\)</span>.</p>
<p>Now the reason we define the expected value is because this mathematical definition turns out to be useful for approximating the probability distributions of sum, which then is useful for describing the distribution of averages and proportions. The first useful fact is that the expected value of the sum of the draws is:</p>
<p><span class="math display">\[
\mbox{number of draws } \times \mbox{ average of the numbers in the urn}
\]</span></p>
<p>So if 1,000 people play roulette, the casino expects to win, on average, about 1,000 <span class="math inline">\(\times\)</span> $0.05 = $50. But this is an expected value. How different can one observation be from the expected value? The casino really needs to know this. What is the range of possibilities? If negative numbers are too likely, they will not install roulette wheels. Statistical theory once again answers this question. The <em>standard error</em> (SE) gives us an idea of the size of the variation around the expected value. In statistics books, it’s common to use:</p>
<p><span class="math display">\[\mbox{SE}[X]\]</span></p>
<p>to denote the standard error of a random variable.</p>
<p><strong>If our draws are independent</strong>, then the standard error of the sum is given by the equation:</p>
<p><span class="math display">\[
\sqrt{\mbox{number of draws }} \times \mbox{ standard deviation of the numbers in the urn}
\]</span></p>
<p>Using the definition of standard deviation, we can derive, with a bit of math, that if an urn contains two values <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> with proportions <span class="math inline">\(p\)</span> and <span class="math inline">\((1-p)\)</span> respectively, the standard deviation is:</p>
<p><span class="math display">\[\mid b - a \mid \sqrt{p(1-p)}.\]</span></p>
<p>So in our roulette example, the standard deviation of the values inside the urn is: <span class="math inline">\(\mid 1 - (-1) \mid \sqrt{10/19 \times 9/19}\)</span> or:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">90</span>)<span class="op">/</span><span class="dv">19</span>
<span class="co">#&gt; [1] 0.999</span></code></pre></div>
<p>The standard error tells us the typical difference between a random variable and its expectation. Since one draw is obviously the sum of just one draw, we can use the formula above to calculate that the random variable defined by one draw has an expected value of 0.05 and a standard error of about 1. This makes sense since we either get 1 or -1, with 1 slightly favored over -1.</p>
<p>Using the formula above, the sum of 1,000 people playing has standard error of about $32:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
<span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">90</span>)<span class="op">/</span><span class="dv">19</span>
<span class="co">#&gt; [1] 31.6</span></code></pre></div>
<p>As a result, when 1,000 people bet on red, the casino is expected to win $50 with a standard error of $32. It therefore seems like a safe bet. But we still haven’t answered the question: how likely is it to lose money? Here the CLT will help.</p>
<p><strong>Advanced note</strong>: Before continuing we should point out that exact probability calculations for the casino winnings can be performed with the binomial distribution. However, here we focus on the CLT which can be generally applied to sums of random variables in a way that the binomial distribution can’t.</p>
</div>
<div id="central-limit-theorem-approximation" class="section level3">
<h3><span class="header-section-number">24.3.7</span> Central Limit Theorem approximation</h3>
<p>We previously ran this Monte Carlo simulation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
B &lt;-<span class="st"> </span><span class="dv">10000</span>
roulette_winnings &lt;-<span class="st"> </span><span class="cf">function</span>(n){
  X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))
  <span class="kw">sum</span>(X)
}
S &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">roulette_winnings</span>(n))</code></pre></div>
<p>The Central Limit Theorem (CLT) tells us that the sum <span class="math inline">\(S\)</span> is approximated by a normal distribution. Using the formulas above, we know that the expected value and standard error are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n <span class="op">*</span><span class="st"> </span>(<span class="dv">20</span><span class="op">-</span><span class="dv">18</span>)<span class="op">/</span><span class="dv">38</span> 
<span class="co">#&gt; [1] 52.6</span>
<span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">90</span>)<span class="op">/</span><span class="dv">19</span> 
<span class="co">#&gt; [1] 31.6</span></code></pre></div>
<p>The theoretical values above match those obtained with the Monte Carlo simulation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S)
<span class="co">#&gt; [1] 52.5</span>
<span class="kw">sd</span>(S)
<span class="co">#&gt; [1] 31.8</span></code></pre></div>
<p>Using the CLT, we can skip the Monte Carlo simulation and instead compute the probability of the casino losing money using this approximation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span>n <span class="op">*</span><span class="st"> </span>(<span class="dv">20</span><span class="op">-</span><span class="dv">18</span>)<span class="op">/</span><span class="dv">38</span>
se &lt;-<span class="st">  </span><span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">90</span>)<span class="op">/</span><span class="dv">19</span> 
<span class="kw">pnorm</span>(<span class="dv">0</span>, mu, se)
<span class="co">#&gt; [1] 0.0478</span></code></pre></div>
<p>which is also in very good agreement with our Monte Carlo result:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.0459</span></code></pre></div>
</div>
<div id="statistical-properties-of-averages" class="section level3">
<h3><span class="header-section-number">24.3.8</span> Statistical properties of averages</h3>
<p>There are serveal useful mathematical results that we used above and often employ when working with data. We list them below.</p>
<ol style="list-style-type: decimal">
<li><p>The expected value of the sum of random variables is the sum of each random variable’s expected value. We can write it like this:</p>
<p><span class="math display">\[ 
\mbox{E}[X_1+X_2+\dots+X_n] =  \mbox{E}[X_1] + \mbox{E}[X_2]+\dots+\mbox{E}[X_n]
\]</span></p>
<p>If the <span class="math inline">\(X\)</span> are independent draws from the urn, then they all have the same expected value. Let’s call it <span class="math inline">\(\mu\)</span> and thus:</p>
<p><span class="math display">\[ 
\mbox{E}[X_1+X_2+\dots+X_n]=  n\mu
\]</span></p>
<p>which is another way of writing the result we show above for the sum of draws.</p></li>
<li><p>The expected value of a non-random constant times a random variable is the non-random constant times the expected value of a random variable. This is easier to explain with symbols: <span class="math display">\[
\mbox{E}[aX] =  a\times\mbox{E}[X]
\]</span></p>
<p>To see why this is intuitive, consider change of units. If we change the units of a random variable, say from dollars to cents, the expectation should change in the same way. A consequence of the above two facts is that the expected value of the average of independent draws from the same urn is the expected value of the urn, call it <span class="math inline">\(\mu\)</span> again:</p>
<p><span class="math display">\[
\mbox{E}[(X_1+X_2+\dots+X_n) / n]=   \mbox{E}[X_1+X_2+\dots+X_n] / n = n\mu/n = \mu 
\]</span></p></li>
<li><p>The square of the standard error of the sum of <strong>independent</strong> random variables is the sum of the square of the standard error of each random variable. This one is easier to understand in math form: <span class="math display">\[ 
\mbox{SE}[X_1+X_2+\dots+X_n] = \sqrt{\mbox{SE}[X_1]^2 + \mbox{SE}[X_2]^2+\dots+\mbox{SE}[X_n]^2  }
\]</span></p>
<p>The square of the standard error is referred to as the <em>variance</em> in statistical textbooks.</p></li>
<li><p>The standard error of a non-random constant times a random variable is the non-random constant times the random variable’s standard error. As with the expectation: <span class="math display">\[
\mbox{SE}[aX] =  a \times \mbox{SE}[X]
\]</span></p>
<p>To see why this is intuitive, again think of units.</p>
<p>A consequence of 3 and 4 is that the standard error of the average of independent draws from the same urn is the standard deviation of the urn divided by the square root of <span class="math inline">\(n\)</span> (the number of draws), call it <span class="math inline">\(\sigma\)</span>:</p></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\mbox{SE}[(X_1+X_2+\dots+X_n) / n] &amp;=   \mbox{SE}[X_1+X_2+\dots+X_n]/n \\
&amp;= \sqrt{\mbox{SE}[X_1]^2+\mbox{SE}[X_2]^2+\dots+\mbox{SE}[X_n]^2}/n \\
&amp;= \sqrt{\sigma^2+\sigma^2+\dots+\sigma^2}/n\\
&amp;= \sqrt{n\sigma^2}/n\\
&amp;= \sigma / \sqrt{n}    
\end{aligned}
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>If <span class="math inline">\(X\)</span> is a normally distributed random variable, then if <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are non-random constants, <span class="math inline">\(aX + b\)</span> is also a normally distributed random variable. All we are doing is changing the units of the random variable by multiplying by <span class="math inline">\(a\)</span>, then shifting the center by <span class="math inline">\(b\)</span>.</li>
</ol>
<p>Note that statistical textbooks use the Greek letters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> to denote the expected value and standard error respectively. This is because <span class="math inline">\(\mu\)</span> is the Greek letter for <span class="math inline">\(m\)</span>, the first letter of <em>mean</em>, which is another term used for expected value. Similarly, <span class="math inline">\(\sigma\)</span> is the Greek letter for <span class="math inline">\(s\)</span>, the first letter of standard error.</p>
</div>
<div id="law-of-large-numbers" class="section level3">
<h3><span class="header-section-number">24.3.9</span> Law of large numbers</h3>
<p>An important implication of the final result is that the standard error of the average becomes smaller and smaller as <span class="math inline">\(n\)</span> grows larger. When <span class="math inline">\(n\)</span> is very large, then the standard error is practically 0 and the average of the draws converges to the average of the urn. This is known in statistical textbooks as the law of large numbers or the law of averages.</p>
</div>
<div id="misinterpreting-law-of-averages" class="section level3">
<h3><span class="header-section-number">24.3.10</span> Misinterpreting law of averages</h3>
<p>The law of averages is sometimes misinterpreted. For example, if you toss a coin 5 times and see a head each time, you might hear someone argue that the next toss is probably a tail because of the law of averages: on average we should see 50% heads and 50% tails. A similar argument would be to say that red “is due” on the roulette wheel after seeing black come up five times in a row. These events are independent so the chance of a coin landing heads is 50% regardless of the previous 5. This is also the case for the roulette outcome. The law of averages applies only when the number of draws is very large and not in small samples. After a million tosses, you will definitely see about 50% heads regardless of the outcome of the first five tosses.</p>
<p>Another funny misuse of the law of averages is in sports when TV sportscasters predict a player is about to succeed because they have failed a few times in a row.</p>
</div>
<div id="how-large-is-large-in-clt" class="section level3">
<h3><span class="header-section-number">24.3.11</span> How large is large in CLT?</h3>
<p>The CLT works when the number of draws is large. But large is a relative term. In many circumstances as few as 30 draws is enough to make the CLT useful. In some specific instances, as few as 10 is enough. However, these should not be considered general rules. Note, for example, that when the probability of success is very small, we need larger sample sizes.</p>
<p>By way of illustration, let’s consider the lottery. In the lottery, the chances of winning are less than 1 in a million. Thousands of people play so the number of draws is very large. Yet the number of winners, the sum of the draws, range between 0 and 4. This sum is certainly not well approximated by a normal distribution so the CLT does not apply, even with the very large sample size. This is generally true when the probability of a success is very low. In these cases, the Poisson distribution is more appropriate.</p>
<p>You can examine the properties of the Poisson distribution using <code>dpois</code> and <code>ppois</code>. You can generate random variables following this distribution with <code>rpois</code>. However, we do not cover the theory here. You can learn about the Poisson distribution in any probability textbook and even <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Wikipedia</a>.</p>
</div>
<div id="population-sd-versus-the-sample-sd" class="section level3">
<h3><span class="header-section-number">24.3.12</span> Population SD versus the sample SD</h3>
<p>The standard deviation of a list <code>x</code> (we use heights as an example) is defined as the square root of the average of the squared differences:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dslabs)
x &lt;-<span class="st"> </span>heights<span class="op">$</span>height
m &lt;-<span class="st"> </span><span class="kw">mean</span>(x)
s &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((x<span class="op">-</span>m)<span class="op">^</span><span class="dv">2</span>))</code></pre></div>
<p>Using mathematical notation we write:</p>
<p><span class="math display">\[
\mu = \frac{1}{n} \sum_{i=1}^n x_i \\
\sigma =  \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \mu)^2}
\]</span></p>
<p>However, be aware that the <code>sd</code> function returns a slightly different result:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">identical</span>(s, <span class="kw">sd</span>(x))
<span class="co">#&gt; [1] FALSE</span>
s<span class="op">-</span><span class="kw">sd</span>(x)
<span class="co">#&gt; [1] -0.00194</span></code></pre></div>
<p>This is because the <code>sd</code> function R does not return the <code>sd</code> of the list, but rather uses a formula that estimates standard deviations of a population from a random sample <span class="math inline">\(X_1, \dots, X_N\)</span> which, for reasons not discussed here, divide the sum of squares by the <span class="math inline">\(N-1\)</span>.</p>
<p><span class="math display">\[
\bar{X} = \frac{1}{N} \sum_{i=1}^N X_i, \,\,\,\,
s =  \sqrt{\frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2}
\]</span></p>
<p>You can see that this is the case by typing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
s<span class="op">-</span><span class="kw">sd</span>(x)<span class="op">*</span><span class="kw">sqrt</span>((n<span class="op">-</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>n)
<span class="co">#&gt; [1] 0</span></code></pre></div>
<p>For all the theory discussed here, you need to compute the actual standard deviation as defined:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>(<span class="kw">mean</span>((x<span class="op">-</span>m)<span class="op">^</span><span class="dv">2</span>))</code></pre></div>
<p>So be careful when using the <code>sd</code> function in R. However, keep in mind that throughout the book we sometimes use the <code>sd</code> function when we really want the actual SD. This is because when the list size is big, these two are practically equivalent since <span class="math inline">\(\sqrt{(N-1)/N}\)</span> is close to 1.</p>
</div>
<div id="exercises-28" class="section level3">
<h3><span class="header-section-number">24.3.13</span> Exercises</h3>
<ol style="list-style-type: decimal">
<li><p>In American Roulette you can also bet on green. There are 18 reds, 18 blacks and 2 greens (0 and 00). What are the chances the green comes out?</p></li>
<li><p>The payout for winning on green is $17 dollars. This means that if you bet a dollar and it lands on green, you get $17. Create a sampling model using sample to simulate the random variable <span class="math inline">\(X\)</span> for your winnings. Hint: see the example below for how it should look like when betting on red.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>), <span class="dv">1</span>, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))</code></pre></div></li>
<li><p>Compute the expected value of <span class="math inline">\(X\)</span>.</p></li>
<li><p>Compute the standard error of <span class="math inline">\(X\)</span>.</p></li>
<li><p>Now create a random variable <span class="math inline">\(S\)</span> that is the sum of your winnings after betting on green 1000 times. Hint: change the argument <code>size</code> and <code>replace</code> in your answer to question 2. Start your code by setting the seed to 1 with <code>set.seed(1)</code>.</p></li>
<li><p>What is the expected value of <span class="math inline">\(S\)</span>?</p></li>
<li><p>What is the standard error of <span class="math inline">\(S\)</span>?</p></li>
<li><p>What is the probability that you end up winning money? Hint: use the CLT.</p></li>
<li><p>Create a Monte Carlo simulation that generates 1,000 outcomes of <span class="math inline">\(S\)</span>. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with <code>set.seed(1)</code>.</p></li>
<li><p>Now check your answer to 8 using the Monte Carlo result.</p></li>
<li><p>The Monte Carlo result and the CLT approximation are close, but not that close. What could account for this?</p>
<p>A. 1,000 simulations is not enough. If we do more, they match.</p>
<p>B. The CLT does not work as well when the probability of success is small. In this case, it was 1/19. If we make the number of roulette plays bigger, they will match better.</p>
<p>C. The difference is within rounding error.</p>
<p>D. The CLT only works for averages.</p></li>
<li><p>Now create a random variable <span class="math inline">\(Y\)</span> that is your average winnings per bet after playing off your winnings after betting on green 1,000 times.</p></li>
<li><p>What is the expected value of <span class="math inline">\(Y\)</span>?</p></li>
<li><p>What is the standard error of <span class="math inline">\(S\)</span>?</p></li>
<li><p>What is the probability that you end up with winnings per game that are positive? Hint: use the CLT.</p></li>
<li><p>Create a Monte Carlo simulation that generates 2,500 outcomes of <span class="math inline">\(S\)</span>. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with <code>set.seed(1)</code>.</p></li>
<li><p>Now check your answer to 8 using the Monte Carlo result.</p></li>
<li><p>The Monte Carlo result and the CLT approximation are now much closer. What could account for this?</p>
<p>A. We are now computing averages instead of sums.</p>
<p>B. 2,500 Monte Carlo simulations is not better than 1,000.</p>
<p>C. The CLT works better when the sample size is larger. We increased from 1,000 to 2,500.</p>
<p>D. It is not closer. The difference is within rounding error.</p></li>
</ol>

</div>
</div>
<div id="case-study-the-big-short" class="section level2">
<h2><span class="header-section-number">24.4</span> Case study: The Big Short</h2>
<div id="interest-rates-explained-with-chance-model" class="section level3">
<h3><span class="header-section-number">24.4.1</span> Interest rates explained with chance model</h3>
<p>More complex versions of the sampling models we have discussed are also used by banks to decide interest rates. Suppose you run a small bank that has a history of identifying potential homeowners that can be trusted to make payments. In fact, historically, in a given year, only 2% of your customers default, meaning that they don’t pay back the money that you lent them. However, you are aware that if you simply loan money to everybody without interest, you will end up losing money due to this 2%. Although you know 2% of your clients will probably default, you don’t know which ones. Yet by charging everybody just a bit extra in interest, you can make up the losses incurred due to that 2% and also cover your operating costs. You can also make a profit, but if you set the interest rates too high, your clients will go to another bank. We use all these facts and some probability theory to decide what interest rate you should charge.</p>
<p>Suppose your bank will give out 1,000 loans for $180,000 this year. Also, after adding up all costs, suppose your bank loses $200,000 per foreclosure. For simplicity, we assume this includes all operational costs. A sampling model for this scenario can be coded like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
loss_per_foreclosure &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">200000</span>
p &lt;-<span class="st"> </span><span class="fl">0.02</span> 
defaults &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), n, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p), <span class="dt">replace =</span> <span class="ot">TRUE</span>)
<span class="kw">sum</span>(defaults <span class="op">*</span><span class="st"> </span>loss_per_foreclosure)
<span class="co">#&gt; [1] -3600000</span></code></pre></div>
<p>Note that the total loss defined by the final sum is a random variable. Every time you run the above code, you get a different answer. We can easily construct a Monte Carlo simulation to get an idea of the distribution of this random variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10000</span>
losses &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    defaults &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), n, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p), <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
  <span class="kw">sum</span>(defaults <span class="op">*</span><span class="st"> </span>loss_per_foreclosure)
})</code></pre></div>
<p>Here is the distribution of this random variable: <img src="book_files/figure-html/losses-distribution-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>We don’t really need a Monte Carlo simulation though. Using what we have learned, the CLT tells us that because our losses are a sum of independent draws, its distribution is approximately normal with expected value and standard errors given by:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n<span class="op">*</span>(p<span class="op">*</span>loss_per_foreclosure <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p)<span class="op">*</span><span class="dv">0</span>)
<span class="co">#&gt; [1] -4e+06</span>
<span class="kw">sqrt</span>(n)<span class="op">*</span><span class="kw">abs</span>(loss_per_foreclosure)<span class="op">*</span><span class="kw">sqrt</span>(p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p))
<span class="co">#&gt; [1] 885438</span></code></pre></div>
<p>We can now set an interest rate to guarantee that, on average, we break even. Basically, we need to add a quantity <span class="math inline">\(x\)</span> to each loan, which in this case are represented by draws, so that the expected value is 0. If we define <span class="math inline">\(l\)</span> to be the loss per foreclosure, we need:</p>
<p><span class="math display">\[
lp  + x(1-p) = 0
\]</span></p>
<p>which implies <span class="math inline">\(x\)</span> is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span><span class="st"> </span>loss_per_foreclosure<span class="op">*</span>p<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>p)
<span class="co">#&gt; [1] 4082</span></code></pre></div>
<p>or an interest rate of 0.023.</p>
<p>However, we still have a problem. Although this interest rate guarantees that on average we break even, there is a 50% chance that we lose money. If our bank loses money, we have to close it down. We therefore need to pick an interest rate that makes it unlikely for this to happen. At the same time, if the interest rate is too high, our clients will go to another bank so we must be willing to take some risks. So let’s say that we want our chances of losing money to be 1 in 100, what does the <span class="math inline">\(x\)</span> quantity need to be now? This one is a bit harder. We want the sum <span class="math inline">\(S\)</span> to have:</p>
<p><span class="math display">\[\mbox{Pr}(S&lt;0) = 0.01\]</span></p>
<p>We know that <span class="math inline">\(S\)</span> is approximately normal. The expected value of <span class="math inline">\(S\)</span> is</p>
<p><span class="math display">\[\mbox{E}[S] = \{ lp + x(1-p)\}n\]</span></p>
<p>with <span class="math inline">\(n\)</span> the number of draws, which in this case represents loans. The standard error is</p>
<p><span class="math display">\[\mbox{SD}[S] = |x-l| \sqrt{np(1-p)}\]</span>.</p>
<p>Because <span class="math inline">\(x\)</span> is positive and <span class="math inline">\(l\)</span> negative <span class="math inline">\(|x-l|=x-l\)</span>. Note that these are just an application of the formulas shown erlier, but using more compact symbols.</p>
<p>Now we are going to use a mathematical “trick” that is very common in statistics. Weadd and subtract the same quantities to both sides of the event <span class="math inline">\(S&lt;0\)</span> so that the probability does not change and we end up with a standard normal random variable on the left, which will then permit us to write down an equation with only <span class="math inline">\(x\)</span> as an unknown. This “trick” is as follows:</p>
<p>If</p>
<p><span class="math display">\[\mbox{Pr}(S&lt;0) = 0.01\]</span></p>
<p>then <span class="math display">\[
\mbox{Pr}\left(\frac{S - \mbox{E}[S]}{\mbox{SE}[S]} &lt; \frac{ - \mbox{E}[S]}{\mbox{SE}[S]}\right)
\]</span> And remember <span class="math inline">\(\mbox{E}[S]\)</span> and <span class="math inline">\(\mbox{SE}[S]\)</span> are the expected value and standard error of <span class="math inline">\(S\)</span> respectively. All we did above was add and divide by the same quantity on both sides. We did this because now the term on the left is a standard normal random variable, which we will rename <span class="math inline">\(Z\)</span>. Now we fill in the blanks with the actual formula for expected value and standard error:</p>
<p><span class="math display">\[
\mbox{Pr}\left(Z &lt;  \frac{- \{ lp + x(1-p)\}n}{(x-l) \sqrt{np(1-p)}}\right) = 0.01
\]</span></p>
<p>It may look complicated, but remember that <span class="math inline">\(l\)</span>, <span class="math inline">\(p\)</span> and <span class="math inline">\(n\)</span> are all known amounts so eventually we will turn them into numbers.</p>
<p>Now because the term on the left side is a normal random with expected value 0 and standard error 1, it means that the quantity on the left must be equal to:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(<span class="fl">0.01</span>)
<span class="co">#&gt; [1] -2.33</span></code></pre></div>
<p>for the equation to hold true. Remember that <span class="math inline">\(z=\)</span><code>qnorm(0.01)</code> gives us the value of <span class="math inline">\(z\)</span> for which:</p>
<p><span class="math display">\[
\mbox{Pr}(Z \leq z) = 0.01
\]</span></p>
<p>So this means that right side of the complicated equation must be <span class="math inline">\(z\)</span>=<code>qnorm(0.01)</code>.</p>
<p><span class="math display">\[
\frac{- \{ lp + x(1-p)\}n} {(x-l) \sqrt{n p (1-p)}} = z
\]</span></p>
<p>The trick works because we end up with an expression containing <span class="math inline">\(x\)</span> that we know has to be equal to a known quantity <span class="math inline">\(z\)</span>. Solving for <span class="math inline">\(x\)</span> is now simply algebra:</p>
<p><span class="math display">\[ x = - l \frac{ np  - z \sqrt{np(1-p)}}{n(1-p) + z \sqrt{np(1-p)}}\]</span></p>
<p>which is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l &lt;-<span class="st"> </span>loss_per_foreclosure
z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.01</span>)
x &lt;-<span class="st"> </span><span class="op">-</span>l<span class="op">*</span>( n<span class="op">*</span>p <span class="op">-</span><span class="st"> </span>z<span class="op">*</span><span class="kw">sqrt</span>(n<span class="op">*</span>p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)))<span class="op">/</span><span class="st"> </span>( n<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p) <span class="op">+</span><span class="st"> </span>z<span class="op">*</span><span class="kw">sqrt</span>(n<span class="op">*</span>p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)))
x
<span class="co">#&gt; [1] 6249</span></code></pre></div>
<p>Our interest rate now goes up to 0.035. This is still a very competitive interest rate. By choosing this interest rate, we now have an expected profit per loan of:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loss_per_foreclosure<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)
<span class="co">#&gt; [1] 2124</span></code></pre></div>
<p>which is a total expected profit of about:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n<span class="op">*</span>(loss_per_foreclosure<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)) 
<span class="co">#&gt; [1] 2124198</span></code></pre></div>
<p>dollars!</p>
<p>We can run a Monte Carlo simulation to double check our theoretical approximations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">100000</span>
profit &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    draws &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(x, loss_per_foreclosure), n, 
                        <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p), <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
    <span class="kw">sum</span>(draws)
})
<span class="kw">mean</span>(profit)
<span class="co">#&gt; [1] 2127786</span>
<span class="kw">mean</span>(profit<span class="op">&lt;</span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.0124</span></code></pre></div>
</div>
<div id="the-big-short" class="section level3">
<h3><span class="header-section-number">24.4.2</span> The Big Short</h3>
<p>One of your employees points out that since the bank is making 2124 dollars per loan, the bank should give out more loans! Why just <span class="math inline">\(n\)</span>? You explain that finding those <code>n</code> clients was hard. You need a group that is predictable and that keeps the chances of defaults low. He then points out that even if the probability of default is higher, as long as our expected value is positive, you can minimize your chances of losses by increasing <span class="math inline">\(n\)</span> and relying on the law of large numbers.</p>
<p>He claims that even if the default rate is twice as high, say 4%, if we set the rate just a bit higher than:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="fl">0.04</span>
r &lt;-<span class="st"> </span>(<span class="op">-</span><span class="st"> </span>loss_per_foreclosure<span class="op">*</span>p<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>p)) <span class="op">/</span><span class="st"> </span><span class="dv">180000</span>
r
<span class="co">#&gt; [1] 0.0463</span></code></pre></div>
<p>At 5%, we are guaranteed a positive expected value of:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r &lt;-<span class="st"> </span><span class="fl">0.05</span>
x &lt;-<span class="st"> </span>r<span class="op">*</span><span class="dv">180000</span>
loss_per_foreclosure<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p)
<span class="co">#&gt; [1] 640</span></code></pre></div>
<p>and can minimize our chances of losing money by simply increasing <span class="math inline">\(n\)</span> since:</p>
<p><span class="math display">\[
\mbox{Pr}(S &lt; 0) = 
\mbox{Pr}\left(Z &lt; - \frac{\mbox{E}[S]}{\mbox{SE}[S]}\right)
\]</span> with <span class="math inline">\(Z\)</span> a standard normal random variable as shown earlier. If we define <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> to be the expected value and standard deviation of the urn respectively (that is of a single loan), using the formulas above we have: <span class="math inline">\(\mbox{E}[S]= n\mu\)</span> and <span class="math inline">\(\mbox{SE}[S]= \sqrt{n}\sigma\)</span>. So if we define <span class="math inline">\(z\)</span>=<code>qnorm(0.01)</code>, we have: <span class="math display">\[
 - \frac{n\mu}{\sqrt{n}\sigma} = - \frac{\sqrt{n}\mu}{\sigma} = z
\]</span> which implies that if we let:</p>
<p><span class="math display">\[
n \geq z^2 \sigma^2 / \mu^2
\]</span> we are guaranteed to have a probability of less than 0.01. The implication is that, as long as <span class="math inline">\(\mu\)</span> is positive, we can find an <span class="math inline">\(n\)</span> that minimizes the probability of a loss. This is a form of the law of large numbers: when <span class="math inline">\(n\)</span> is large, our average earnings per loan converges to the expected earning <span class="math inline">\(\mu\)</span>.</p>
<p>With <span class="math inline">\(x\)</span> fixed, now we can ask what <span class="math inline">\(n\)</span> do we need for the probability to be 0.01? In our example, if we give out:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.01</span>)
n &lt;-<span class="st"> </span><span class="kw">ceiling</span>((z<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(x<span class="op">-</span>l)<span class="op">^</span><span class="dv">2</span><span class="op">*</span>p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p))<span class="op">/</span>(l<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p))<span class="op">^</span><span class="dv">2</span>)
n
<span class="co">#&gt; [1] 22163</span></code></pre></div>
<p>loans, the probability of losing is about 0.01 and we are expected to earn a total of</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n<span class="op">*</span>(loss_per_foreclosure<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p))
<span class="co">#&gt; [1] 14184320</span></code></pre></div>
<p>dollars! We can confirm this with a Monte Carlo simulation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="fl">0.04</span>
x &lt;-<span class="st"> </span><span class="fl">0.05</span><span class="op">*</span><span class="dv">180000</span>
profit &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    draws &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(x, loss_per_foreclosure), n, 
                        <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p), <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
    <span class="kw">sum</span>(draws)
})
<span class="kw">mean</span>(profit)
<span class="co">#&gt; [1] 14203433</span></code></pre></div>
<p>This seems like a no brainier. As a result, your colleague decides to leave your bank and start his own high risk mortgage company. A few months later, your colleague’s bank has gone bankrupt. A book is written and eventually a movie is made relating the mistake your friend, and many others, made. What happened?</p>
<p>Your colleague’s scheme was mainly based on this mathematical formula: <span class="math display">\[
    \mbox{SE}[(X_1+X_2+\dots+X_n) / n] = \sigma / \sqrt{n}    
\]</span></p>
<p>By making <span class="math inline">\(n\)</span> large, we minimize the standard error of our per-loan profit. However, for this rule to hold, the <span class="math inline">\(X\)</span>s must be independent draws: one person defaulting must be independent of others defaulting. Note that in the case of averaging the <strong>same</strong> event over and over, an extreme example of events that are not independent, we get a standard error that is <span class="math inline">\(\sqrt{n}\)</span> times bigger: <span class="math display">\[
    \mbox{SE}[(X_1+X_1+\dots+X_1) / n] =  \mbox{SE}[n X_1  / n] = \sigma &gt; \sigma / \sqrt{n} 
\]</span></p>
<p>To construct a more realistic simulation than the original one your colleague ran, let’s assume there is a global event that affects everybody with high risk mortgages and changes their probability. We will assume that with 50-50 chance, all the probabilities go up or down slightly to somewhere between 0.03 and 0.05. But it happens to everybody at once, not just one person. These draws are no longer independent.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="fl">0.04</span>
x &lt;-<span class="st"> </span><span class="fl">0.05</span><span class="op">*</span><span class="dv">180000</span>
profit &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    new_p &lt;-<span class="st"> </span><span class="fl">0.04</span> <span class="op">+</span><span class="st"> </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.01</span>, <span class="fl">0.01</span>, <span class="dt">length =</span> <span class="dv">100</span>), <span class="dv">1</span>)
    draws &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(x, loss_per_foreclosure), n, 
                        <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>new_p, new_p), <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
    <span class="kw">sum</span>(draws)
})</code></pre></div>
<p>Note that our expected profit is still large:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(profit)
<span class="co">#&gt; [1] 14202543</span></code></pre></div>
<p>However, the probability of the bank having negative earning shoots up to:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(profit<span class="op">&lt;</span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.344</span></code></pre></div>
<p>Even scarier is that the probability of losing more than 10 million dollars is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(profit <span class="op">&lt;</span><span class="st"> </span><span class="op">-</span><span class="dv">10000000</span>)
<span class="co">#&gt; [1] 0.239</span></code></pre></div>
<p>To understand how this happens look at the distribution:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data.frame</span>(<span class="dt">profit_in_millions=</span>profit<span class="op">/</span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(profit_in_millions)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">binwidth =</span> <span class="dv">5</span>)</code></pre></div>
<p><img src="book_files/figure-html/profit-distribution-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The theory completely breaks down and the random variable has much more variability than expected. The financial meltdown of 2007 was due, among other things, to financial “experts” assuming independence when there was none.</p>
</div>
<div id="exercises-29" class="section level3">
<h3><span class="header-section-number">24.4.3</span> Exercises</h3>
<ol style="list-style-type: decimal">
<li><p>Create a random variable <span class="math inline">\(S\)</span> with the earnings of your bank if you give out 10,000 loans, the default rate is 0.3, and you lose $200,000 in each foreclosure. Hint: use the code we showed in the previous section, but change the parameters.</p></li>
<li><p>Run a Monte Carlo simulation with 10,000 outcomes for <span class="math inline">\(S\)</span>. Make a histogram of the results.</p></li>
<li><p>What is the expected value of <span class="math inline">\(S\)</span>?</p></li>
<li><p>What is the standard error of <span class="math inline">\(S\)</span>?</p></li>
<li><p>Suppose we give out loans for $180,000. What should the interest rate be so that our expected value is 0?</p></li>
<li><p>(Harder) What should the interest rate be so that the chance of losing money is 1 in 20? In math notation, what should the interest rate be so that <span class="math inline">\(\mbox{Pr}(S&lt;0) = 0.05\)</span> ?</p></li>
<li><p>If the bank wants to minimize the probabilities of losing money, which of the following does <strong>not</strong> make interest rates go up?</p>
<p>A. A smaller pool of loans.</p>
<p>B. A larger probability of default.</p>
<p>C. A smaller required probability of losing money.</p>
<p>D. The number of Monte Carlo simulations.</p></li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-statistics-with-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statistical-inference.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rafalab/dsbook/edit/master/prob/intro-to-prob.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
